{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":["turbopack://[next]/internal/font/google/georama_a0fe492d.module.css [app-client] (css module)"],"sourcesContent":["__turbopack_export_value__({\n  \"className\": \"georama_a0fe492d-module__gRNpGq__className\",\n});\n"],"names":[],"mappings":"AAAA;AACA;AACA","ignoreList":[0]}},
    {"offset": {"line": 9, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 15, "column": 0}, "map": {"version":3,"sources":["turbopack://[next]/internal/font/google/georama_a0fe492d.js"],"sourcesContent":["import cssModule from \"@vercel/turbopack-next/internal/font/google/cssmodule.module.css?{%22path%22:%22layout.tsx%22,%22import%22:%22Georama%22,%22arguments%22:[{%22weight%22:%22400%22}],%22variableName%22:%22GeoramaSans%22}\";\nconst fontData = {\n    className: cssModule.className,\n    style: {\n        fontFamily: \"'Georama', 'Georama Fallback'\",\n        fontWeight: 400,\nfontStyle: \"normal\",\n\n    },\n};\n\nif (cssModule.variable != null) {\n    fontData.variable = cssModule.variable;\n}\n\nexport default fontData;\n"],"names":[],"mappings":";;;AAAA;;AACA,MAAM,WAAW;IACb,WAAW,0JAAA,CAAA,UAAS,CAAC,SAAS;IAC9B,OAAO;QACH,YAAY;QACZ,YAAY;QACpB,WAAW;IAEP;AACJ;AAEA,IAAI,0JAAA,CAAA,UAAS,CAAC,QAAQ,IAAI,MAAM;IAC5B,SAAS,QAAQ,GAAG,0JAAA,CAAA,UAAS,CAAC,QAAQ;AAC1C;uCAEe","ignoreList":[0]}},
    {"offset": {"line": 32, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 38, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/src/app/layout.tsx"],"sourcesContent":["import type {Metadata} from \"next\";\nimport {Georama} from \"next/font/google\";\nimport \"./globals.css\";\nimport React from \"react\";\nimport {propsType} from \"../../next-env\";\nimport {navigate} from \"next/dist/client/components/segment-cache/navigation\";\n\nconst GeoramaSans = Georama({\n    weight: \"400\"\n});\n\n\nexport const metadata: Metadata = {\n    title: \"Doxa Innovations\",\n    description: \"Doxa Innovative Software Development PLC is an online creative hub dedicated to helping businesses \" +\n      \"establish a strong and professional brand identity at an affordable price. With a focus on enhancing how businesses \" +\n      \"present themselves to their clients, the studio provides branding solutions that help companies stand out and effectively \" +\n      \"communicate their vision.\",\n    keywords: [\n        'doxa', 'doxa innovations', 'doksa', 'software company', 'ethiopian company',   \"Bee Design Studio\", \"creative design services\",\n        \"digital branding\", \"graphic design\", \"website design\", \"branding solutions\", \"logo design\", \"UI/UX design\", \"digital marketing\",\n        \"illustration services\", \"web development\", \"custom design studio\", \"modern branding\", \"social media design\", \"marketing creatives\",\n        \"visual identity\", \"motion graphics\", \"professional design studio\", \"creative agency\", \"branding agency\",  \"Bee Design Studio\",\n        \"Ethiopian design company\", \"creative design services Ethiopia\", \"digital branding Ethiopia\", \"graphic design Ethiopia\",\n        \"website design Ethiopia\", \"branding solutions Ethiopia\", \"logo design Ethiopia\", \"UI/UX design Ethiopia\", \"Ethiopian digital marketing\",\n        \"illustration services Ethiopia\", \"web development Ethiopia\", \"custom design studio Ethiopia\", \"modern branding Ethiopia\",\n        \"Ethiopian creative agency\", \"social media design Ethiopia\", \"marketing creatives Ethiopia\", \"visual identity Ethiopia\",\n        \"motion graphics Ethiopia\", \"professional design studio Ethiopia\", \"branding agency Ethiopia\", \"Ethiopian design and branding services\"\n    ],\n    authors: {name: 'Doxa Innovations Software Development PLC'},\n    openGraph: {\n        title: \"Doxa Innovations - Creative Design Services\",\n        description:\n            \"Experience cutting-edge design, branding, and web/software development with Doxa Innovations, Ethiopia's premier creative agency.\",\n        url: \"https://beedesign.studio\",\n        siteName: \"Doxa Innovations\",\n        images: [\n            {\n                url: \"https://beedesign.studio/assets/logo.png\",\n                width: 1200,\n                height: 630,\n                alt: \"Doxa Innovations Banner\",\n            },\n        ],\n        locale: \"en_US\",\n        type: \"website\",\n    },\n    twitter: {\n        card: \"summary_large_image\",\n        title: \"Doxa Innovations - Creative Design Services\",\n        description:\n            \"Doxa Innovations delivers creative solutions for your design, branding, and web development needs. Visit us today!\",\n        images: [\"https://beedesign.studio/assets/logo.png\"],\n    },\n};\n\nexport default function RootLayout({\n   children,\n   title = 'Home',\n   description = '',\n   backLink,\n   lgLogoShow = true,\n   logoShow = true\n}: propsType) {\nreturn (\n    <html lang=\"en\">\n    <body\n        className={`${GeoramaSans.className} antialiased`}\n    >\n        <main className=\"h-dvh w-full overflow-hidden font-pj-font\">\n            <div className=\"w-full h-full bg-pj-dark grid grid-rows-12 relative\">\n            {\n                typeof backLink === 'string' && (\n                    <div\n                        className={'fill-pj-primary absolute w-10 h-10 top-0 left-0 z-20 mx-4 md:mx-10 my-5 cursor-pointer hover:fill-pj-secondary'}\n                    >\n                        <svg\n                            onClick={() => {\n                                navigate(backLink);\n                            }}\n                            className=\"fill-inherit\"\n                            xmlns=\"http://www.w3.org/2000/svg\"\n                            viewBox=\"0 0 512 512\"\n                        >\n                            <path\n                                d=\"M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 288 480 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-370.7 0 73.4-73.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-128 128z\"\n                            />\n                        </svg>\n                    </div>\n                \n                )\n            }\n            \n            <div className={`h-full relative z-10 row-span-2 grid grid-flow-col grid-cols-3`}>\n                <div className={`flex justify-center items-start`}>\n                    <img className='w-8/12 md:w-3/12' src={bee2} alt=\"\"/>\n                </div>\n                <div className={`grid justify-items-center mt-5`}>\n                    {logoShow &&\n                        <img className={`${!lgLogoShow && 'lg:hidden'} w-2/4 md:w-1/3 xl:w-1/5`} src={logo}\n                             alt=\"\"/>}\n                    \n                    {\n                        !lgLogoShow &&\n                        <div className={`py-4 text-center w-full`}>\n                            <h1 className='text-2xl sm:text-2xl lg:text-6xl font-bold text-pj-primary text-center'>\n                                {title}\n                            </h1>\n                            <h2 className=\"text-pj-white font-medium \">\n                                {description}\n                            </h2>\n                        </div>\n                    }\n                </div>\n                <div className={`h-full grid justify-end relative`}>\n                    <img\n                        className={'w-3/5 md:w-1/4 absolute z-10 top-0 right-0'}\n                        src={crownSword} alt=\"\"\n                    />\n                </div>\n            </div>\n            <div className={`row-span-10`}>\n                {children}\n            </div>\n            <div className={`absolute z-0 w-full -bottom-2 md:-bottom-16 ml-3 mr-auto`}>\n                <div className={`relative flex sm:w-1/2 md:w-2/5 lg:w-1/3 `}>\n                    <img className='w-1/2 -scale-x-[1]' src={chariot} alt=\"\"/>\n                </div>\n            </div>\n            <div className={`row-span-1 self-end`}>\n                <p className='text-sm mx-auto py-5 bottom-1 md:bottom-6 text-pj-primary w-max z-50'>\n                    Â©{new Date().getFullYear()} Copyright - Bee Design Studio</p>\n            </div>\n        </div>\n        </main>\n    </body>\n    </html>\n);\n}\n"],"names":[],"mappings":";;;;;;AAKA;;;;;AAOO,MAAM,WAAqB;IAC9B,OAAO;IACP,aAAa,wGACX,yHACA,+HACA;IACF,UAAU;QACN;QAAQ;QAAoB;QAAS;QAAoB;QAAuB;QAAqB;QACrG;QAAoB;QAAkB;QAAkB;QAAsB;QAAe;QAAgB;QAC7G;QAAyB;QAAmB;QAAwB;QAAmB;QAAuB;QAC9G;QAAmB;QAAmB;QAA8B;QAAmB;QAAoB;QAC3G;QAA4B;QAAqC;QAA6B;QAC9F;QAA2B;QAA+B;QAAwB;QAAyB;QAC3G;QAAkC;QAA4B;QAAiC;QAC/F;QAA6B;QAAgC;QAAgC;QAC7F;QAA4B;QAAuC;QAA4B;KAClG;IACD,SAAS;QAAC,MAAM;IAA2C;IAC3D,WAAW;QACP,OAAO;QACP,aACI;QACJ,KAAK;QACL,UAAU;QACV,QAAQ;YACJ;gBACI,KAAK;gBACL,OAAO;gBACP,QAAQ;gBACR,KAAK;YACT;SACH;QACD,QAAQ;QACR,MAAM;IACV;IACA,SAAS;QACL,MAAM;QACN,OAAO;QACP,aACI;QACJ,QAAQ;YAAC;SAA2C;IACxD;AACJ;AAEe,SAAS,WAAW,EAChC,QAAQ,EACR,QAAQ,MAAM,EACd,cAAc,EAAE,EAChB,QAAQ,EACR,aAAa,IAAI,EACjB,WAAW,IAAI,EACN;IACZ,qBACI,8OAAC;QAAK,MAAK;kBACX,cAAA,8OAAC;YACG,WAAW,GAAG,2IAAA,CAAA,UAAW,CAAC,SAAS,CAAC,YAAY,CAAC;sBAEjD,cAAA,8OAAC;gBAAK,WAAU;0BACZ,cAAA,8OAAC;oBAAI,WAAU;;wBAEX,OAAO,aAAa,0BAChB,8OAAC;4BACG,WAAW;sCAEX,cAAA,8OAAC;gCACG,SAAS;oCACL,CAAA,GAAA,sLAAA,CAAA,WAAQ,AAAD,EAAE;gCACb;gCACA,WAAU;gCACV,OAAM;gCACN,SAAQ;0CAER,cAAA,8OAAC;oCACG,GAAE;;;;;;;;;;;;;;;;sCAQtB,8OAAC;4BAAI,WAAW,CAAC,8DAA8D,CAAC;;8CAC5E,8OAAC;oCAAI,WAAW,CAAC,+BAA+B,CAAC;8CAC7C,cAAA,8OAAC;wCAAI,WAAU;wCAAmB,KAAK;wCAAM,KAAI;;;;;;;;;;;8CAErD,8OAAC;oCAAI,WAAW,CAAC,8BAA8B,CAAC;;wCAC3C,0BACG,8OAAC;4CAAI,WAAW,GAAG,CAAC,cAAc,YAAY,wBAAwB,CAAC;4CAAE,KAAK;4CACzE,KAAI;;;;;;wCAGT,CAAC,4BACD,8OAAC;4CAAI,WAAW,CAAC,uBAAuB,CAAC;;8DACrC,8OAAC;oDAAG,WAAU;8DACT;;;;;;8DAEL,8OAAC;oDAAG,WAAU;8DACT;;;;;;;;;;;;;;;;;;8CAKjB,8OAAC;oCAAI,WAAW,CAAC,gCAAgC,CAAC;8CAC9C,cAAA,8OAAC;wCACG,WAAW;wCACX,KAAK;wCAAY,KAAI;;;;;;;;;;;;;;;;;sCAIjC,8OAAC;4BAAI,WAAW,CAAC,WAAW,CAAC;sCACxB;;;;;;sCAEL,8OAAC;4BAAI,WAAW,CAAC,wDAAwD,CAAC;sCACtE,cAAA,8OAAC;gCAAI,WAAW,CAAC,yCAAyC,CAAC;0CACvD,cAAA,8OAAC;oCAAI,WAAU;oCAAqB,KAAK;oCAAS,KAAI;;;;;;;;;;;;;;;;sCAG9D,8OAAC;4BAAI,WAAW,CAAC,mBAAmB,CAAC;sCACjC,cAAA,8OAAC;gCAAE,WAAU;;oCAAuE;oCAC9E,IAAI,OAAO,WAAW;oCAAG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAO/C"}},
    {"offset": {"line": 321, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 332, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/server/route-modules/app-page/vendored/rsc/react-jsx-dev-runtime.ts"],"sourcesContent":["module.exports = require('../../module.compiled').vendored[\n  'react-rsc'\n].ReactJsxDevRuntime\n"],"names":["module","exports","require","vendored","ReactJsxDevRuntime"],"mappings":";AAAAA,OAAOC,OAAO,GAAGC,QAAQ,0HAAyBC,QAAQ,CACxD,YACD,CAACC,kBAAkB","ignoreList":[0]}},
    {"offset": {"line": 334, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 339, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/dist/client/components/router-reducer/fetch-server-response.js/proxy.js"],"sourcesContent":["const { createClientModuleProxy } = require(\"react-server-dom-turbopack/server.edge\");\n\n__turbopack_export_namespace__(createClientModuleProxy(\"[project]/node_modules/next/dist/client/components/router-reducer/fetch-server-response.js <module evaluation>\"));\n"],"names":[],"mappings":"AAAA,MAAM,EAAE,uBAAuB,EAAE;AAEjC,+BAA+B,wBAAwB","ignoreList":[0]}},
    {"offset": {"line": 341, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 346, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/dist/client/components/router-reducer/fetch-server-response.js/proxy.js"],"sourcesContent":["const { createClientModuleProxy } = require(\"react-server-dom-turbopack/server.edge\");\n\n__turbopack_export_namespace__(createClientModuleProxy(\"[project]/node_modules/next/dist/client/components/router-reducer/fetch-server-response.js\"));\n"],"names":[],"mappings":"AAAA,MAAM,EAAE,uBAAuB,EAAE;AAEjC,+BAA+B,wBAAwB","ignoreList":[0]}},
    {"offset": {"line": 348, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 354, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/router-reducer/fetch-server-response.ts"],"sourcesContent":["'use client'\n\n// @ts-ignore\n// eslint-disable-next-line import/no-extraneous-dependencies\n// import { createFromReadableStream } from 'react-server-dom-webpack/client'\nconst { createFromReadableStream } = (\n  !!process.env.NEXT_RUNTIME\n    ? // eslint-disable-next-line import/no-extraneous-dependencies\n      require('react-server-dom-webpack/client.edge')\n    : // eslint-disable-next-line import/no-extraneous-dependencies\n      require('react-server-dom-webpack/client')\n) as typeof import('react-server-dom-webpack/client')\n\nimport type {\n  FlightRouterState,\n  NavigationFlightResponse,\n} from '../../../server/app-render/types'\nimport {\n  NEXT_ROUTER_PREFETCH_HEADER,\n  NEXT_ROUTER_SEGMENT_PREFETCH_HEADER,\n  NEXT_ROUTER_STATE_TREE_HEADER,\n  NEXT_RSC_UNION_QUERY,\n  NEXT_URL,\n  RSC_HEADER,\n  RSC_CONTENT_TYPE_HEADER,\n  NEXT_HMR_REFRESH_HEADER,\n  NEXT_DID_POSTPONE_HEADER,\n  NEXT_ROUTER_STALE_TIME_HEADER,\n} from '../app-router-headers'\nimport { callServer } from '../../app-call-server'\nimport { findSourceMapURL } from '../../app-find-source-map-url'\nimport { PrefetchKind } from './router-reducer-types'\nimport { hexHash } from '../../../shared/lib/hash'\nimport {\n  normalizeFlightData,\n  type NormalizedFlightData,\n} from '../../flight-data-helpers'\nimport { getAppBuildId } from '../../app-build-id'\n\nexport interface FetchServerResponseOptions {\n  readonly flightRouterState: FlightRouterState\n  readonly nextUrl: string | null\n  readonly prefetchKind?: PrefetchKind\n  readonly isHmrRefresh?: boolean\n}\n\nexport type FetchServerResponseResult = {\n  flightData: NormalizedFlightData[] | string\n  canonicalUrl: URL | undefined\n  couldBeIntercepted: boolean\n  prerendered: boolean\n  postponed: boolean\n  staleTime: number\n}\n\nexport type RequestHeaders = {\n  [RSC_HEADER]?: '1'\n  [NEXT_ROUTER_STATE_TREE_HEADER]?: string\n  [NEXT_URL]?: string\n  [NEXT_ROUTER_PREFETCH_HEADER]?: '1'\n  [NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]?: string\n  'x-deployment-id'?: string\n  [NEXT_HMR_REFRESH_HEADER]?: '1'\n  // A header that is only added in test mode to assert on fetch priority\n  'Next-Test-Fetch-Priority'?: RequestInit['priority']\n}\n\nexport function urlToUrlWithoutFlightMarker(url: string): URL {\n  const urlWithoutFlightParameters = new URL(url, location.origin)\n  urlWithoutFlightParameters.searchParams.delete(NEXT_RSC_UNION_QUERY)\n  if (process.env.NODE_ENV === 'production') {\n    if (\n      process.env.__NEXT_CONFIG_OUTPUT === 'export' &&\n      urlWithoutFlightParameters.pathname.endsWith('.txt')\n    ) {\n      const { pathname } = urlWithoutFlightParameters\n      const length = pathname.endsWith('/index.txt') ? 10 : 4\n      // Slice off `/index.txt` or `.txt` from the end of the pathname\n      urlWithoutFlightParameters.pathname = pathname.slice(0, -length)\n    }\n  }\n  return urlWithoutFlightParameters\n}\n\nfunction doMpaNavigation(url: string): FetchServerResponseResult {\n  return {\n    flightData: urlToUrlWithoutFlightMarker(url).toString(),\n    canonicalUrl: undefined,\n    couldBeIntercepted: false,\n    prerendered: false,\n    postponed: false,\n    staleTime: -1,\n  }\n}\n\n/**\n * Fetch the flight data for the provided url. Takes in the current router state\n * to decide what to render server-side.\n */\nexport async function fetchServerResponse(\n  url: URL,\n  options: FetchServerResponseOptions\n): Promise<FetchServerResponseResult> {\n  const { flightRouterState, nextUrl, prefetchKind } = options\n\n  const headers: RequestHeaders = {\n    // Enable flight response\n    [RSC_HEADER]: '1',\n    // Provide the current router state\n    [NEXT_ROUTER_STATE_TREE_HEADER]: encodeURIComponent(\n      JSON.stringify(flightRouterState)\n    ),\n  }\n\n  /**\n   * Three cases:\n   * - `prefetchKind` is `undefined`, it means it's a normal navigation, so we want to prefetch the page data fully\n   * - `prefetchKind` is `full` - we want to prefetch the whole page so same as above\n   * - `prefetchKind` is `auto` - if the page is dynamic, prefetch the page data partially, if static prefetch the page data fully\n   */\n  if (prefetchKind === PrefetchKind.AUTO) {\n    headers[NEXT_ROUTER_PREFETCH_HEADER] = '1'\n  }\n\n  if (process.env.NODE_ENV === 'development' && options.isHmrRefresh) {\n    headers[NEXT_HMR_REFRESH_HEADER] = '1'\n  }\n\n  if (nextUrl) {\n    headers[NEXT_URL] = nextUrl\n  }\n\n  try {\n    // When creating a \"temporary\" prefetch (the \"on-demand\" prefetch that gets created on navigation, if one doesn't exist)\n    // we send the request with a \"high\" priority as it's in response to a user interaction that could be blocking a transition.\n    // Otherwise, all other prefetches are sent with a \"low\" priority.\n    // We use \"auto\" for in all other cases to match the existing default, as this function is shared outside of prefetching.\n    const fetchPriority = prefetchKind\n      ? prefetchKind === PrefetchKind.TEMPORARY\n        ? 'high'\n        : 'low'\n      : 'auto'\n\n    const res = await createFetch(url, headers, fetchPriority)\n\n    const responseUrl = urlToUrlWithoutFlightMarker(res.url)\n    const canonicalUrl = res.redirected ? responseUrl : undefined\n\n    const contentType = res.headers.get('content-type') || ''\n    const interception = !!res.headers.get('vary')?.includes(NEXT_URL)\n    const postponed = !!res.headers.get(NEXT_DID_POSTPONE_HEADER)\n    const staleTimeHeader = res.headers.get(NEXT_ROUTER_STALE_TIME_HEADER)\n    const staleTime =\n      staleTimeHeader !== null ? parseInt(staleTimeHeader, 10) : -1\n    let isFlightResponse = contentType.startsWith(RSC_CONTENT_TYPE_HEADER)\n\n    if (process.env.NODE_ENV === 'production') {\n      if (process.env.__NEXT_CONFIG_OUTPUT === 'export') {\n        if (!isFlightResponse) {\n          isFlightResponse = contentType.startsWith('text/plain')\n        }\n      }\n    }\n\n    // If fetch returns something different than flight response handle it like a mpa navigation\n    // If the fetch was not 200, we also handle it like a mpa navigation\n    if (!isFlightResponse || !res.ok || !res.body) {\n      // in case the original URL came with a hash, preserve it before redirecting to the new URL\n      if (url.hash) {\n        responseUrl.hash = url.hash\n      }\n\n      return doMpaNavigation(responseUrl.toString())\n    }\n\n    // We may navigate to a page that requires a different Webpack runtime.\n    // In prod, every page will have the same Webpack runtime.\n    // In dev, the Webpack runtime is minimal for each page.\n    // We need to ensure the Webpack runtime is updated before executing client-side JS of the new page.\n    if (process.env.NODE_ENV !== 'production' && !process.env.TURBOPACK) {\n      await require('../react-dev-overlay/app/hot-reloader-client').waitForWebpackRuntimeHotUpdate()\n    }\n\n    // Handle the `fetch` readable stream that can be unwrapped by `React.use`.\n    const flightStream = postponed\n      ? createUnclosingPrefetchStream(res.body)\n      : res.body\n    const response = await (createFromNextReadableStream(\n      flightStream\n    ) as Promise<NavigationFlightResponse>)\n\n    if (getAppBuildId() !== response.b) {\n      return doMpaNavigation(res.url)\n    }\n\n    return {\n      flightData: normalizeFlightData(response.f),\n      canonicalUrl: canonicalUrl,\n      couldBeIntercepted: interception,\n      prerendered: response.S,\n      postponed,\n      staleTime,\n    }\n  } catch (err) {\n    console.error(\n      `Failed to fetch RSC payload for ${url}. Falling back to browser navigation.`,\n      err\n    )\n    // If fetch fails handle it like a mpa navigation\n    // TODO-APP: Add a test for the case where a CORS request fails, e.g. external url redirect coming from the response.\n    // See https://github.com/vercel/next.js/issues/43605#issuecomment-1451617521 for a reproduction.\n    return {\n      flightData: url.toString(),\n      canonicalUrl: undefined,\n      couldBeIntercepted: false,\n      prerendered: false,\n      postponed: false,\n      staleTime: -1,\n    }\n  }\n}\n\nexport function createFetch(\n  url: URL,\n  headers: RequestHeaders,\n  fetchPriority: 'auto' | 'high' | 'low' | null\n) {\n  const fetchUrl = new URL(url)\n\n  if (process.env.NODE_ENV === 'production') {\n    if (process.env.__NEXT_CONFIG_OUTPUT === 'export') {\n      if (fetchUrl.pathname.endsWith('/')) {\n        fetchUrl.pathname += 'index.txt'\n      } else {\n        fetchUrl.pathname += '.txt'\n      }\n    }\n  }\n\n  // This is used to cache bust CDNs that don't support custom headers. The\n  // result is stored in a search param.\n  // TODO: Given that we have to use a search param anyway, we might as well\n  // _only_ use a search param and not bother with the custom headers.\n  // Add unique cache query to avoid caching conflicts on CDN which don't respect the Vary header\n  const uniqueCacheQuery = hexHash(\n    [\n      headers[NEXT_ROUTER_PREFETCH_HEADER] || '0',\n      headers[NEXT_ROUTER_SEGMENT_PREFETCH_HEADER] || '0',\n      headers[NEXT_ROUTER_STATE_TREE_HEADER],\n      headers[NEXT_URL],\n    ].join(',')\n  )\n\n  fetchUrl.searchParams.set(NEXT_RSC_UNION_QUERY, uniqueCacheQuery)\n\n  if (process.env.__NEXT_TEST_MODE && fetchPriority !== null) {\n    headers['Next-Test-Fetch-Priority'] = fetchPriority\n  }\n\n  if (process.env.NEXT_DEPLOYMENT_ID) {\n    headers['x-deployment-id'] = process.env.NEXT_DEPLOYMENT_ID\n  }\n\n  return fetch(fetchUrl, {\n    // Backwards compat for older browsers. `same-origin` is the default in modern browsers.\n    credentials: 'same-origin',\n    headers,\n    priority: fetchPriority || undefined,\n  })\n}\n\nexport function createFromNextReadableStream(\n  flightStream: ReadableStream<Uint8Array>\n): Promise<unknown> {\n  return createFromReadableStream(flightStream, {\n    callServer,\n    findSourceMapURL,\n  })\n}\n\nfunction createUnclosingPrefetchStream(\n  originalFlightStream: ReadableStream<Uint8Array>\n): ReadableStream<Uint8Array> {\n  // When PPR is enabled, prefetch streams may contain references that never\n  // resolve, because that's how we encode dynamic data access. In the decoded\n  // object returned by the Flight client, these are reified into hanging\n  // promises that suspend during render, which is effectively what we want.\n  // The UI resolves when it switches to the dynamic data stream\n  // (via useDeferredValue(dynamic, static)).\n  //\n  // However, the Flight implementation currently errors if the server closes\n  // the response before all the references are resolved. As a cheat to work\n  // around this, we wrap the original stream in a new stream that never closes,\n  // and therefore doesn't error.\n  const reader = originalFlightStream.getReader()\n  return new ReadableStream({\n    async pull(controller) {\n      while (true) {\n        const { done, value } = await reader.read()\n        if (!done) {\n          // Pass to the target stream and keep consuming the Flight response\n          // from the server.\n          controller.enqueue(value)\n          continue\n        }\n        // The server stream has closed. Exit, but intentionally do not close\n        // the target stream.\n        return\n      }\n    },\n  })\n}\n"],"names":["createFetch","createFromNextReadableStream","fetchServerResponse","urlToUrlWithoutFlightMarker","createFromReadableStream","process","env","NEXT_RUNTIME","require","url","urlWithoutFlightParameters","URL","location","origin","searchParams","delete","NEXT_RSC_UNION_QUERY","NODE_ENV","__NEXT_CONFIG_OUTPUT","pathname","endsWith","length","slice","doMpaNavigation","flightData","toString","canonicalUrl","undefined","couldBeIntercepted","prerendered","postponed","staleTime","options","flightRouterState","nextUrl","prefetchKind","headers","RSC_HEADER","NEXT_ROUTER_STATE_TREE_HEADER","encodeURIComponent","JSON","stringify","PrefetchKind","AUTO","NEXT_ROUTER_PREFETCH_HEADER","isHmrRefresh","NEXT_HMR_REFRESH_HEADER","NEXT_URL","res","fetchPriority","TEMPORARY","responseUrl","redirected","contentType","get","interception","includes","NEXT_DID_POSTPONE_HEADER","staleTimeHeader","NEXT_ROUTER_STALE_TIME_HEADER","parseInt","isFlightResponse","startsWith","RSC_CONTENT_TYPE_HEADER","ok","body","hash","TURBOPACK","waitForWebpackRuntimeHotUpdate","flightStream","createUnclosingPrefetchStream","response","getAppBuildId","b","normalizeFlightData","f","S","err","console","error","fetchUrl","uniqueCacheQuery","hexHash","NEXT_ROUTER_SEGMENT_PREFETCH_HEADER","join","set","__NEXT_TEST_MODE","NEXT_DEPLOYMENT_ID","fetch","credentials","priority","callServer","findSourceMapURL","originalFlightStream","reader","getReader","ReadableStream","pull","controller","done","value","read","enqueue"],"mappings":"","ignoreList":[0]}},
    {"offset": {"line": 358, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 363, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/server/app-render/get-segment-param.tsx"],"sourcesContent":["import { INTERCEPTION_ROUTE_MARKERS } from '../lib/interception-routes'\nimport type { DynamicParamTypes } from './types'\n\n/**\n * Parse dynamic route segment to type of parameter\n */\nexport function getSegmentParam(segment: string): {\n  param: string\n  type: DynamicParamTypes\n} | null {\n  const interceptionMarker = INTERCEPTION_ROUTE_MARKERS.find((marker) =>\n    segment.startsWith(marker)\n  )\n\n  // if an interception marker is part of the path segment, we need to jump ahead\n  // to the relevant portion for param parsing\n  if (interceptionMarker) {\n    segment = segment.slice(interceptionMarker.length)\n  }\n\n  if (segment.startsWith('[[...') && segment.endsWith(']]')) {\n    return {\n      // TODO-APP: Optional catchall does not currently work with parallel routes,\n      // so for now aren't handling a potential interception marker.\n      type: 'optional-catchall',\n      param: segment.slice(5, -2),\n    }\n  }\n\n  if (segment.startsWith('[...') && segment.endsWith(']')) {\n    return {\n      type: interceptionMarker ? 'catchall-intercepted' : 'catchall',\n      param: segment.slice(4, -1),\n    }\n  }\n\n  if (segment.startsWith('[') && segment.endsWith(']')) {\n    return {\n      type: interceptionMarker ? 'dynamic-intercepted' : 'dynamic',\n      param: segment.slice(1, -1),\n    }\n  }\n\n  return null\n}\n"],"names":["getSegmentParam","segment","interceptionMarker","INTERCEPTION_ROUTE_MARKERS","find","marker","startsWith","slice","length","endsWith","type","param"],"mappings":";;;;+BAMgBA,mBAAAA;;;eAAAA;;;oCAN2B;AAMpC,SAASA,gBAAgBC,OAAe;IAI7C,MAAMC,qBAAqBC,oBAAAA,0BAA0B,CAACC,IAAI,CAAC,CAACC,SAC1DJ,QAAQK,UAAU,CAACD;IAGrB,+EAA+E;IAC/E,4CAA4C;IAC5C,IAAIH,oBAAoB;QACtBD,UAAUA,QAAQM,KAAK,CAACL,mBAAmBM,MAAM;IACnD;IAEA,IAAIP,QAAQK,UAAU,CAAC,YAAYL,QAAQQ,QAAQ,CAAC,OAAO;QACzD,OAAO;YACL,4EAA4E;YAC5E,8DAA8D;YAC9DC,MAAM;YACNC,OAAOV,QAAQM,KAAK,CAAC,GAAG,CAAC;QAC3B;IACF;IAEA,IAAIN,QAAQK,UAAU,CAAC,WAAWL,QAAQQ,QAAQ,CAAC,MAAM;QACvD,OAAO;YACLC,MAAMR,qBAAqB,yBAAyB;YACpDS,OAAOV,QAAQM,KAAK,CAAC,GAAG,CAAC;QAC3B;IACF;IAEA,IAAIN,QAAQK,UAAU,CAAC,QAAQL,QAAQQ,QAAQ,CAAC,MAAM;QACpD,OAAO;YACLC,MAAMR,qBAAqB,wBAAwB;YACnDS,OAAOV,QAAQM,KAAK,CAAC,GAAG,CAAC;QAC3B;IACF;IAEA,OAAO;AACT","ignoreList":[0]}},
    {"offset": {"line": 403, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 408, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/match-segments.ts"],"sourcesContent":["import { getSegmentParam } from '../../server/app-render/get-segment-param'\nimport type { Segment } from '../../server/app-render/types'\n\nexport const matchSegment = (\n  existingSegment: Segment,\n  segment: Segment\n): boolean => {\n  // segment is either Array or string\n  if (typeof existingSegment === 'string') {\n    if (typeof segment === 'string') {\n      // Common case: segment is just a string\n      return existingSegment === segment\n    }\n    return false\n  }\n\n  if (typeof segment === 'string') {\n    return false\n  }\n  return existingSegment[0] === segment[0] && existingSegment[1] === segment[1]\n}\n\n/*\n * This function is used to determine if an existing segment can be overridden by the incoming segment.\n */\nexport const canSegmentBeOverridden = (\n  existingSegment: Segment,\n  segment: Segment\n): boolean => {\n  if (Array.isArray(existingSegment) || !Array.isArray(segment)) {\n    return false\n  }\n\n  return getSegmentParam(existingSegment)?.param === segment[0]\n}\n"],"names":["canSegmentBeOverridden","matchSegment","existingSegment","segment","getSegmentParam","Array","isArray","param"],"mappings":";;;;;;;;;;;;;;;IAyBaA,sBAAsB,EAAA;eAAtBA;;IAtBAC,YAAY,EAAA;eAAZA;;;iCAHmB;AAGzB,MAAMA,eAAe,CAC1BC,iBACAC;IAEA,oCAAoC;IACpC,IAAI,OAAOD,oBAAoB,UAAU;QACvC,IAAI,OAAOC,YAAY,UAAU;YAC/B,wCAAwC;YACxC,OAAOD,oBAAoBC;QAC7B;QACA,OAAO;IACT;IAEA,IAAI,OAAOA,YAAY,UAAU;QAC/B,OAAO;IACT;IACA,OAAOD,eAAe,CAAC,EAAE,KAAKC,OAAO,CAAC,EAAE,IAAID,eAAe,CAAC,EAAE,KAAKC,OAAO,CAAC,EAAE;AAC/E;AAKO,MAAMH,yBAAyB,CACpCE,iBACAC;QAMOC;IAJP,IAAIC,MAAMC,OAAO,CAACJ,oBAAoB,CAACG,MAAMC,OAAO,CAACH,UAAU;QAC7D,OAAO;IACT;IAEA,OAAOC,CAAAA,CAAAA,mBAAAA,CAAAA,GAAAA,iBAAAA,eAAe,EAACF,gBAAAA,KAAAA,OAAAA,KAAAA,IAAhBE,iBAAkCG,KAAK,MAAKJ,OAAO,CAAC,EAAE;AAC/D","ignoreList":[0]}},
    {"offset": {"line": 459, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 464, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/router-reducer/create-router-cache-key.ts"],"sourcesContent":["import type { Segment } from '../../../server/app-render/types'\nimport { PAGE_SEGMENT_KEY } from '../../../shared/lib/segment'\n\nexport function createRouterCacheKey(\n  segment: Segment,\n  withoutSearchParameters: boolean = false\n) {\n  // if the segment is an array, it means it's a dynamic segment\n  // for example, ['lang', 'en', 'd']. We need to convert it to a string to store it as a cache node key.\n  if (Array.isArray(segment)) {\n    return `${segment[0]}|${segment[1]}|${segment[2]}`\n  }\n\n  // Page segments might have search parameters, ie __PAGE__?foo=bar\n  // When `withoutSearchParameters` is true, we only want to return the page segment\n  if (withoutSearchParameters && segment.startsWith(PAGE_SEGMENT_KEY)) {\n    return PAGE_SEGMENT_KEY\n  }\n\n  return segment\n}\n"],"names":["createRouterCacheKey","segment","withoutSearchParameters","Array","isArray","startsWith","PAGE_SEGMENT_KEY"],"mappings":";;;;+BAGgBA,wBAAAA;;;eAAAA;;;yBAFiB;AAE1B,SAASA,qBACdC,OAAgB,EAChBC,uBAAwC;IAAxCA,IAAAA,4BAAAA,KAAAA,GAAAA,0BAAmC;IAEnC,8DAA8D;IAC9D,uGAAuG;IACvG,IAAIC,MAAMC,OAAO,CAACH,UAAU;QAC1B,OAAUA,OAAO,CAAC,EAAE,GAAC,MAAGA,OAAO,CAAC,EAAE,GAAC,MAAGA,OAAO,CAAC,EAAE;IAClD;IAEA,kEAAkE;IAClE,kFAAkF;IAClF,IAAIC,2BAA2BD,QAAQI,UAAU,CAACC,SAAAA,gBAAgB,GAAG;QACnE,OAAOA,SAAAA,gBAAgB;IACzB;IAEA,OAAOL;AACT","ignoreList":[0]}},
    {"offset": {"line": 496, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 501, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/router-reducer/ppr-navigations.ts"],"sourcesContent":["import type {\n  CacheNodeSeedData,\n  FlightRouterState,\n  FlightSegmentPath,\n  Segment,\n} from '../../../server/app-render/types'\nimport type {\n  CacheNode,\n  ChildSegmentMap,\n  ReadyCacheNode,\n} from '../../../shared/lib/app-router-context.shared-runtime'\nimport { DEFAULT_SEGMENT_KEY } from '../../../shared/lib/segment'\nimport { matchSegment } from '../match-segments'\nimport { createRouterCacheKey } from './create-router-cache-key'\nimport type { FetchServerResponseResult } from './fetch-server-response'\n\n// This is yet another tree type that is used to track pending promises that\n// need to be fulfilled once the dynamic data is received. The terminal nodes of\n// this tree represent the new Cache Node trees that were created during this\n// request. We can't use the Cache Node tree or Route State tree directly\n// because those include reused nodes, too. This tree is discarded as soon as\n// the navigation response is received.\nexport type Task = {\n  // The router state that corresponds to the tree that this Task represents.\n  route: FlightRouterState\n  // The CacheNode that corresponds to the tree that this Task represents. If\n  // `children` is null (i.e. if this is a terminal task node), then `node`\n  // represents a brand new Cache Node tree, which way or may not need to be\n  // filled with dynamic data from the server.\n  node: CacheNode | null\n  // Whether anything in this tree contains dynamic holes that need to be filled\n  // by the server.\n  needsDynamicRequest: boolean\n  children: Map<string, Task> | null\n}\n\n// Creates a new Cache Node tree (i.e. copy-on-write) that represents the\n// optimistic result of a navigation, using both the current Cache Node tree and\n// data that was prefetched prior to navigation.\n//\n// At the moment we call this function, we haven't yet received the navigation\n// response from the server. It could send back something completely different\n// from the tree that was prefetched â due to rewrites, default routes, parallel\n// routes, etc.\n//\n// But in most cases, it will return the same tree that we prefetched, just with\n// the dynamic holes filled in. So we optimistically assume this will happen,\n// and accept that the real result could be arbitrarily different.\n//\n// We'll reuse anything that was already in the previous tree, since that's what\n// the server does.\n//\n// New segments (ones that don't appear in the old tree) are assigned an\n// unresolved promise. The data for these promises will be fulfilled later, when\n// the navigation response is received.\n//\n// The tree can be rendered immediately after it is created (that's why this is\n// a synchronous function). Any new trees that do not have prefetch data will\n// suspend during rendering, until the dynamic data streams in.\n//\n// Returns a Task object, which contains both the updated Cache Node and a path\n// to the pending subtrees that need to be resolved by the navigation response.\n//\n// A return value of `null` means there were no changes, and the previous tree\n// can be reused without initiating a server request.\nexport function updateCacheNodeOnNavigation(\n  oldCacheNode: CacheNode,\n  oldRouterState: FlightRouterState,\n  newRouterState: FlightRouterState,\n  prefetchData: CacheNodeSeedData | null,\n  prefetchHead: React.ReactNode | null,\n  isPrefetchHeadPartial: boolean\n): Task | null {\n  // Diff the old and new trees to reuse the shared layouts.\n  const oldRouterStateChildren = oldRouterState[1]\n  const newRouterStateChildren = newRouterState[1]\n  const prefetchDataChildren = prefetchData !== null ? prefetchData[2] : null\n\n  const oldParallelRoutes = oldCacheNode.parallelRoutes\n\n  // Clone the current set of segment children, even if they aren't active in\n  // the new tree.\n  // TODO: We currently retain all the inactive segments indefinitely, until\n  // there's an explicit refresh, or a parent layout is lazily refreshed. We\n  // rely on this for popstate navigations, which update the Router State Tree\n  // but do not eagerly perform a data fetch, because they expect the segment\n  // data to already be in the Cache Node tree. For highly static sites that\n  // are mostly read-only, this may happen only rarely, causing memory to\n  // leak. We should figure out a better model for the lifetime of inactive\n  // segments, so we can maintain instant back/forward navigations without\n  // leaking memory indefinitely.\n  const prefetchParallelRoutes = new Map(oldParallelRoutes)\n\n  // As we diff the trees, we may sometimes modify (copy-on-write, not mutate)\n  // the Route Tree that was returned by the server â for example, in the case\n  // of default parallel routes, we preserve the currently active segment. To\n  // avoid mutating the original tree, we clone the router state children along\n  // the return path.\n  let patchedRouterStateChildren: {\n    [parallelRouteKey: string]: FlightRouterState\n  } = {}\n  let taskChildren = null\n\n  // Most navigations require a request to fetch additional data from the\n  // server, either because the data was not already prefetched, or because the\n  // target route contains dynamic data that cannot be prefetched.\n  //\n  // However, if the target route is fully static, and it's already completely\n  // loaded into the segment cache, then we can skip the server request.\n  //\n  // This starts off as `false`, and is set to `true` if any of the child\n  // routes requires a dynamic request.\n  let needsDynamicRequest = false\n\n  for (let parallelRouteKey in newRouterStateChildren) {\n    const newRouterStateChild: FlightRouterState =\n      newRouterStateChildren[parallelRouteKey]\n    const oldRouterStateChild: FlightRouterState | void =\n      oldRouterStateChildren[parallelRouteKey]\n    const oldSegmentMapChild = oldParallelRoutes.get(parallelRouteKey)\n    const prefetchDataChild: CacheNodeSeedData | void | null =\n      prefetchDataChildren !== null\n        ? prefetchDataChildren[parallelRouteKey]\n        : null\n\n    const newSegmentChild = newRouterStateChild[0]\n    const newSegmentKeyChild = createRouterCacheKey(newSegmentChild)\n\n    const oldSegmentChild =\n      oldRouterStateChild !== undefined ? oldRouterStateChild[0] : undefined\n\n    const oldCacheNodeChild =\n      oldSegmentMapChild !== undefined\n        ? oldSegmentMapChild.get(newSegmentKeyChild)\n        : undefined\n\n    let taskChild: Task | null\n    if (newSegmentChild === DEFAULT_SEGMENT_KEY) {\n      // This is another kind of leaf segment â a default route.\n      //\n      // Default routes have special behavior. When there's no matching segment\n      // for a parallel route, Next.js preserves the currently active segment\n      // during a client navigation â but not for initial render. The server\n      // leaves it to the client to account for this. So we need to handle\n      // it here.\n      if (oldRouterStateChild !== undefined) {\n        // Reuse the existing Router State for this segment. We spawn a \"task\"\n        // just to keep track of the updated router state; unlike most, it's\n        // already fulfilled and won't be affected by the dynamic response.\n        taskChild = spawnReusedTask(oldRouterStateChild)\n      } else {\n        // There's no currently active segment. Switch to the \"create\" path.\n        taskChild = createCacheNodeOnNavigation(\n          newRouterStateChild,\n          prefetchDataChild !== undefined ? prefetchDataChild : null,\n          prefetchHead,\n          isPrefetchHeadPartial\n        )\n      }\n    } else if (\n      oldSegmentChild !== undefined &&\n      matchSegment(newSegmentChild, oldSegmentChild)\n    ) {\n      if (\n        oldCacheNodeChild !== undefined &&\n        oldRouterStateChild !== undefined\n      ) {\n        // This segment exists in both the old and new trees. Recursively update\n        // the children.\n        taskChild = updateCacheNodeOnNavigation(\n          oldCacheNodeChild,\n          oldRouterStateChild,\n          newRouterStateChild,\n          prefetchDataChild,\n          prefetchHead,\n          isPrefetchHeadPartial\n        )\n      } else {\n        // Either there's no existing Cache Node for this segment, or this\n        // segment doesn't exist in the old Router State tree. Switch to the\n        // \"create\" path.\n        taskChild = createCacheNodeOnNavigation(\n          newRouterStateChild,\n          prefetchDataChild !== undefined ? prefetchDataChild : null,\n          prefetchHead,\n          isPrefetchHeadPartial\n        )\n      }\n    } else {\n      // This is a new tree. Switch to the \"create\" path.\n      taskChild = createCacheNodeOnNavigation(\n        newRouterStateChild,\n        prefetchDataChild !== undefined ? prefetchDataChild : null,\n        prefetchHead,\n        isPrefetchHeadPartial\n      )\n    }\n\n    if (taskChild !== null) {\n      // Something changed in the child tree. Keep track of the child task.\n      if (taskChildren === null) {\n        taskChildren = new Map()\n      }\n      taskChildren.set(parallelRouteKey, taskChild)\n      const newCacheNodeChild = taskChild.node\n      if (newCacheNodeChild !== null) {\n        const newSegmentMapChild: ChildSegmentMap = new Map(oldSegmentMapChild)\n        newSegmentMapChild.set(newSegmentKeyChild, newCacheNodeChild)\n        prefetchParallelRoutes.set(parallelRouteKey, newSegmentMapChild)\n      }\n\n      if (taskChild.needsDynamicRequest) {\n        needsDynamicRequest = true\n      }\n\n      // The child tree's route state may be different from the prefetched\n      // route sent by the server. We need to clone it as we traverse back up\n      // the tree.\n      patchedRouterStateChildren[parallelRouteKey] = taskChild.route\n    } else {\n      // The child didn't change. We can use the prefetched router state.\n      patchedRouterStateChildren[parallelRouteKey] = newRouterStateChild\n    }\n  }\n\n  if (taskChildren === null) {\n    // No new tasks were spawned.\n    return null\n  }\n\n  const newCacheNode: ReadyCacheNode = {\n    lazyData: null,\n    rsc: oldCacheNode.rsc,\n    // We intentionally aren't updating the prefetchRsc field, since this node\n    // is already part of the current tree, because it would be weird for\n    // prefetch data to be newer than the final data. It probably won't ever be\n    // observable anyway, but it could happen if the segment is unmounted then\n    // mounted again, because LayoutRouter will momentarily switch to rendering\n    // prefetchRsc, via useDeferredValue.\n    prefetchRsc: oldCacheNode.prefetchRsc,\n    head: oldCacheNode.head,\n    prefetchHead: oldCacheNode.prefetchHead,\n    loading: oldCacheNode.loading,\n\n    // Everything is cloned except for the children, which we computed above.\n    parallelRoutes: prefetchParallelRoutes,\n  }\n\n  return {\n    // Return a cloned copy of the router state with updated children.\n    route: patchRouterStateWithNewChildren(\n      newRouterState,\n      patchedRouterStateChildren\n    ),\n    node: newCacheNode,\n    needsDynamicRequest,\n    children: taskChildren,\n  }\n}\n\nfunction createCacheNodeOnNavigation(\n  routerState: FlightRouterState,\n  prefetchData: CacheNodeSeedData | null,\n  possiblyPartialPrefetchHead: React.ReactNode | null,\n  isPrefetchHeadPartial: boolean\n): Task {\n  // Same traversal as updateCacheNodeNavigation, but we switch to this path\n  // once we reach the part of the tree that was not in the previous route. We\n  // don't need to diff against the old tree, we just need to create a new one.\n  if (prefetchData === null) {\n    // There's no prefetch for this segment. Everything from this point will be\n    // requested from the server, even if there are static children below it.\n    // Create a terminal task node that will later be fulfilled by\n    // server response.\n    return spawnPendingTask(\n      routerState,\n      null,\n      possiblyPartialPrefetchHead,\n      isPrefetchHeadPartial\n    )\n  }\n\n  const routerStateChildren = routerState[1]\n  const isPrefetchRscPartial = prefetchData[4]\n\n  // The head is assigned to every leaf segment delivered by the server. Based\n  // on corresponding logic in fill-lazy-items-till-leaf-with-head.ts\n  const isLeafSegment = Object.keys(routerStateChildren).length === 0\n\n  // If prefetch data is available for a segment, and it's fully static (i.e.\n  // does not contain any dynamic holes), we don't need to request it from\n  // the server.\n  if (\n    // Check if the segment data is partial\n    isPrefetchRscPartial ||\n    // Check if the head is partial (only relevant if this is a leaf segment)\n    (isPrefetchHeadPartial && isLeafSegment)\n  ) {\n    // We only have partial data from this segment. Like missing segments, we\n    // must request the full data from the server.\n    return spawnPendingTask(\n      routerState,\n      prefetchData,\n      possiblyPartialPrefetchHead,\n      isPrefetchHeadPartial\n    )\n  }\n\n  // The prefetched segment is fully static, so we don't need to request a new\n  // one from the server. Keep traversing down the tree until we reach something\n  // that requires a dynamic request.\n  const prefetchDataChildren = prefetchData[2]\n  const taskChildren = new Map()\n  const cacheNodeChildren = new Map()\n  let needsDynamicRequest = false\n  for (let parallelRouteKey in routerStateChildren) {\n    const routerStateChild: FlightRouterState =\n      routerStateChildren[parallelRouteKey]\n    const prefetchDataChild: CacheNodeSeedData | void | null =\n      prefetchDataChildren !== null\n        ? prefetchDataChildren[parallelRouteKey]\n        : null\n    const segmentChild = routerStateChild[0]\n    const segmentKeyChild = createRouterCacheKey(segmentChild)\n    const taskChild = createCacheNodeOnNavigation(\n      routerStateChild,\n      prefetchDataChild,\n      possiblyPartialPrefetchHead,\n      isPrefetchHeadPartial\n    )\n    taskChildren.set(parallelRouteKey, taskChild)\n    if (taskChild.needsDynamicRequest) {\n      needsDynamicRequest = true\n    }\n    const newCacheNodeChild = taskChild.node\n    if (newCacheNodeChild !== null) {\n      const newSegmentMapChild: ChildSegmentMap = new Map()\n      newSegmentMapChild.set(segmentKeyChild, newCacheNodeChild)\n      cacheNodeChildren.set(parallelRouteKey, newSegmentMapChild)\n    }\n  }\n\n  const rsc = prefetchData[1]\n  const loading = prefetchData[3]\n  return {\n    route: routerState,\n    node: {\n      lazyData: null,\n      // Since this is a fully static segment, we don't need to use the\n      // `prefetchRsc` field.\n      rsc,\n      prefetchRsc: null,\n      head: isLeafSegment ? possiblyPartialPrefetchHead : null,\n      prefetchHead: null,\n      loading,\n      parallelRoutes: cacheNodeChildren,\n    },\n    needsDynamicRequest,\n    children: taskChildren,\n  }\n}\n\nfunction patchRouterStateWithNewChildren(\n  baseRouterState: FlightRouterState,\n  newChildren: { [parallelRouteKey: string]: FlightRouterState }\n): FlightRouterState {\n  const clone: FlightRouterState = [baseRouterState[0], newChildren]\n  // Based on equivalent logic in apply-router-state-patch-to-tree, but should\n  // confirm whether we need to copy all of these fields. Not sure the server\n  // ever sends, e.g. the refetch marker.\n  if (2 in baseRouterState) {\n    clone[2] = baseRouterState[2]\n  }\n  if (3 in baseRouterState) {\n    clone[3] = baseRouterState[3]\n  }\n  if (4 in baseRouterState) {\n    clone[4] = baseRouterState[4]\n  }\n  return clone\n}\n\nfunction spawnPendingTask(\n  routerState: FlightRouterState,\n  prefetchData: CacheNodeSeedData | null,\n  prefetchHead: React.ReactNode | null,\n  isPrefetchHeadPartial: boolean\n): Task {\n  // Create a task that will later be fulfilled by data from the server.\n  const newTask: Task = {\n    route: routerState,\n\n    // Corresponds to the part of the route that will be rendered on the server.\n    node: createPendingCacheNode(\n      routerState,\n      prefetchData,\n      prefetchHead,\n      isPrefetchHeadPartial\n    ),\n    // Set this to true to indicate that this tree is missing data. This will\n    // be propagated to all the parent tasks.\n    needsDynamicRequest: true,\n    children: null,\n  }\n  return newTask\n}\n\nfunction spawnReusedTask(reusedRouterState: FlightRouterState): Task {\n  // Create a task that reuses an existing segment, e.g. when reusing\n  // the current active segment in place of a default route.\n  return {\n    route: reusedRouterState,\n    node: null,\n    needsDynamicRequest: false,\n    children: null,\n  }\n}\n\n// Writes a dynamic server response into the tree created by\n// updateCacheNodeOnNavigation. All pending promises that were spawned by the\n// navigation will be resolved, either with dynamic data from the server, or\n// `null` to indicate that the data is missing.\n//\n// A `null` value will trigger a lazy fetch during render, which will then patch\n// up the tree using the same mechanism as the non-PPR implementation\n// (serverPatchReducer).\n//\n// Usually, the server will respond with exactly the subset of data that we're\n// waiting for â everything below the nearest shared layout. But technically,\n// the server can return anything it wants.\n//\n// This does _not_ create a new tree; it modifies the existing one in place.\n// Which means it must follow the Suspense rules of cache safety.\nexport function listenForDynamicRequest(\n  task: Task,\n  responsePromise: Promise<FetchServerResponseResult>\n) {\n  responsePromise.then(\n    ({ flightData }: FetchServerResponseResult) => {\n      if (typeof flightData === 'string') {\n        // Happens when navigating to page in `pages` from `app`. We shouldn't\n        // get here because should have already handled this during\n        // the prefetch.\n        return\n      }\n      for (const normalizedFlightData of flightData) {\n        const {\n          segmentPath,\n          tree: serverRouterState,\n          seedData: dynamicData,\n          head: dynamicHead,\n        } = normalizedFlightData\n\n        if (!dynamicData) {\n          // This shouldn't happen. PPR should always send back a response.\n          // However, `FlightDataPath` is a shared type and the pre-PPR handling of\n          // this might return null.\n          continue\n        }\n\n        writeDynamicDataIntoPendingTask(\n          task,\n          segmentPath,\n          serverRouterState,\n          dynamicData,\n          dynamicHead\n        )\n      }\n\n      // Now that we've exhausted all the data we received from the server, if\n      // there are any remaining pending tasks in the tree, abort them now.\n      // If there's any missing data, it will trigger a lazy fetch.\n      abortTask(task, null)\n    },\n    (error: any) => {\n      // This will trigger an error during render\n      abortTask(task, error)\n    }\n  )\n}\n\nfunction writeDynamicDataIntoPendingTask(\n  rootTask: Task,\n  segmentPath: FlightSegmentPath,\n  serverRouterState: FlightRouterState,\n  dynamicData: CacheNodeSeedData,\n  dynamicHead: React.ReactNode\n) {\n  // The data sent by the server represents only a subtree of the app. We need\n  // to find the part of the task tree that matches the server response, and\n  // fulfill it using the dynamic data.\n  //\n  // segmentPath represents the parent path of subtree. It's a repeating pattern\n  // of parallel route key and segment:\n  //\n  //   [string, Segment, string, Segment, string, Segment, ...]\n  //\n  // Iterate through the path and finish any tasks that match this payload.\n  let task = rootTask\n  for (let i = 0; i < segmentPath.length; i += 2) {\n    const parallelRouteKey: string = segmentPath[i]\n    const segment: Segment = segmentPath[i + 1]\n    const taskChildren = task.children\n    if (taskChildren !== null) {\n      const taskChild = taskChildren.get(parallelRouteKey)\n      if (taskChild !== undefined) {\n        const taskSegment = taskChild.route[0]\n        if (matchSegment(segment, taskSegment)) {\n          // Found a match for this task. Keep traversing down the task tree.\n          task = taskChild\n          continue\n        }\n      }\n    }\n    // We didn't find a child task that matches the server data. Exit. We won't\n    // abort the task, though, because a different FlightDataPath may be able to\n    // fulfill it (see loop in listenForDynamicRequest). We only abort tasks\n    // once we've run out of data.\n    return\n  }\n\n  finishTaskUsingDynamicDataPayload(\n    task,\n    serverRouterState,\n    dynamicData,\n    dynamicHead\n  )\n}\n\nfunction finishTaskUsingDynamicDataPayload(\n  task: Task,\n  serverRouterState: FlightRouterState,\n  dynamicData: CacheNodeSeedData,\n  dynamicHead: React.ReactNode\n) {\n  if (!task.needsDynamicRequest) {\n    // Everything in this subtree is already complete. Bail out.\n    return\n  }\n\n  // dynamicData may represent a larger subtree than the task. Before we can\n  // finish the task, we need to line them up.\n  const taskChildren = task.children\n  const taskNode = task.node\n  if (taskChildren === null) {\n    // We've reached the leaf node of the pending task. The server data tree\n    // lines up the pending Cache Node tree. We can now switch to the\n    // normal algorithm.\n    if (taskNode !== null) {\n      finishPendingCacheNode(\n        taskNode,\n        task.route,\n        serverRouterState,\n        dynamicData,\n        dynamicHead\n      )\n      // Set this to false to indicate that this task is now complete.\n      task.needsDynamicRequest = false\n    }\n    return\n  }\n  // The server returned more data than we need to finish the task. Skip over\n  // the extra segments until we reach the leaf task node.\n  const serverChildren = serverRouterState[1]\n  const dynamicDataChildren = dynamicData[2]\n\n  for (const parallelRouteKey in serverRouterState) {\n    const serverRouterStateChild: FlightRouterState =\n      serverChildren[parallelRouteKey]\n    const dynamicDataChild: CacheNodeSeedData | null | void =\n      dynamicDataChildren[parallelRouteKey]\n\n    const taskChild = taskChildren.get(parallelRouteKey)\n    if (taskChild !== undefined) {\n      const taskSegment = taskChild.route[0]\n      if (\n        matchSegment(serverRouterStateChild[0], taskSegment) &&\n        dynamicDataChild !== null &&\n        dynamicDataChild !== undefined\n      ) {\n        // Found a match for this task. Keep traversing down the task tree.\n        return finishTaskUsingDynamicDataPayload(\n          taskChild,\n          serverRouterStateChild,\n          dynamicDataChild,\n          dynamicHead\n        )\n      }\n    }\n    // We didn't find a child task that matches the server data. We won't abort\n    // the task, though, because a different FlightDataPath may be able to\n    // fulfill it (see loop in listenForDynamicRequest). We only abort tasks\n    // once we've run out of data.\n  }\n}\n\nfunction createPendingCacheNode(\n  routerState: FlightRouterState,\n  prefetchData: CacheNodeSeedData | null,\n  prefetchHead: React.ReactNode | null,\n  isPrefetchHeadPartial: boolean\n): ReadyCacheNode {\n  const routerStateChildren = routerState[1]\n  const prefetchDataChildren = prefetchData !== null ? prefetchData[2] : null\n\n  const parallelRoutes = new Map()\n  for (let parallelRouteKey in routerStateChildren) {\n    const routerStateChild: FlightRouterState =\n      routerStateChildren[parallelRouteKey]\n    const prefetchDataChild: CacheNodeSeedData | null | void =\n      prefetchDataChildren !== null\n        ? prefetchDataChildren[parallelRouteKey]\n        : null\n\n    const segmentChild = routerStateChild[0]\n    const segmentKeyChild = createRouterCacheKey(segmentChild)\n\n    const newCacheNodeChild = createPendingCacheNode(\n      routerStateChild,\n      prefetchDataChild === undefined ? null : prefetchDataChild,\n      prefetchHead,\n      isPrefetchHeadPartial\n    )\n\n    const newSegmentMapChild: ChildSegmentMap = new Map()\n    newSegmentMapChild.set(segmentKeyChild, newCacheNodeChild)\n    parallelRoutes.set(parallelRouteKey, newSegmentMapChild)\n  }\n\n  // The head is assigned to every leaf segment delivered by the server. Based\n  // on corresponding logic in fill-lazy-items-till-leaf-with-head.ts\n  const isLeafSegment = parallelRoutes.size === 0\n  const maybePrefetchRsc = prefetchData !== null ? prefetchData[1] : null\n  const maybePrefetchLoading = prefetchData !== null ? prefetchData[3] : null\n  return {\n    lazyData: null,\n    parallelRoutes: parallelRoutes,\n\n    prefetchRsc: maybePrefetchRsc !== undefined ? maybePrefetchRsc : null,\n    prefetchHead: isLeafSegment ? prefetchHead : null,\n\n    // TODO: Technically, a loading boundary could contain dynamic data. We must\n    // have separate `loading` and `prefetchLoading` fields to handle this, like\n    // we do for the segment data and head.\n    loading: maybePrefetchLoading !== undefined ? maybePrefetchLoading : null,\n\n    // Create a deferred promise. This will be fulfilled once the dynamic\n    // response is received from the server.\n    rsc: createDeferredRsc() as React.ReactNode,\n    head: isLeafSegment ? (createDeferredRsc() as React.ReactNode) : null,\n  }\n}\n\nfunction finishPendingCacheNode(\n  cacheNode: CacheNode,\n  taskState: FlightRouterState,\n  serverState: FlightRouterState,\n  dynamicData: CacheNodeSeedData,\n  dynamicHead: React.ReactNode\n): void {\n  // Writes a dynamic response into an existing Cache Node tree. This does _not_\n  // create a new tree, it updates the existing tree in-place. So it must follow\n  // the Suspense rules of cache safety â it can resolve pending promises, but\n  // it cannot overwrite existing data. It can add segments to the tree (because\n  // a missing segment will cause the layout router to suspend).\n  // but it cannot delete them.\n  //\n  // We must resolve every promise in the tree, or else it will suspend\n  // indefinitely. If we did not receive data for a segment, we will resolve its\n  // data promise to `null` to trigger a lazy fetch during render.\n  const taskStateChildren = taskState[1]\n  const serverStateChildren = serverState[1]\n  const dataChildren = dynamicData[2]\n\n  // The router state that we traverse the tree with (taskState) is the same one\n  // that we used to construct the pending Cache Node tree. That way we're sure\n  // to resolve all the pending promises.\n  const parallelRoutes = cacheNode.parallelRoutes\n  for (let parallelRouteKey in taskStateChildren) {\n    const taskStateChild: FlightRouterState =\n      taskStateChildren[parallelRouteKey]\n    const serverStateChild: FlightRouterState | void =\n      serverStateChildren[parallelRouteKey]\n    const dataChild: CacheNodeSeedData | null | void =\n      dataChildren[parallelRouteKey]\n\n    const segmentMapChild = parallelRoutes.get(parallelRouteKey)\n    const taskSegmentChild = taskStateChild[0]\n    const taskSegmentKeyChild = createRouterCacheKey(taskSegmentChild)\n\n    const cacheNodeChild =\n      segmentMapChild !== undefined\n        ? segmentMapChild.get(taskSegmentKeyChild)\n        : undefined\n\n    if (cacheNodeChild !== undefined) {\n      if (\n        serverStateChild !== undefined &&\n        matchSegment(taskSegmentChild, serverStateChild[0])\n      ) {\n        if (dataChild !== undefined && dataChild !== null) {\n          // This is the happy path. Recursively update all the children.\n          finishPendingCacheNode(\n            cacheNodeChild,\n            taskStateChild,\n            serverStateChild,\n            dataChild,\n            dynamicHead\n          )\n        } else {\n          // The server never returned data for this segment. Trigger a lazy\n          // fetch during render. This shouldn't happen because the Route Tree\n          // and the Seed Data tree sent by the server should always be the same\n          // shape when part of the same server response.\n          abortPendingCacheNode(taskStateChild, cacheNodeChild, null)\n        }\n      } else {\n        // The server never returned data for this segment. Trigger a lazy\n        // fetch during render.\n        abortPendingCacheNode(taskStateChild, cacheNodeChild, null)\n      }\n    } else {\n      // The server response matches what was expected to receive, but there's\n      // no matching Cache Node in the task tree. This is a bug in the\n      // implementation because we should have created a node for every\n      // segment in the tree that's associated with this task.\n    }\n  }\n\n  // Use the dynamic data from the server to fulfill the deferred RSC promise\n  // on the Cache Node.\n  const rsc = cacheNode.rsc\n  const dynamicSegmentData = dynamicData[1]\n  if (rsc === null) {\n    // This is a lazy cache node. We can overwrite it. This is only safe\n    // because we know that the LayoutRouter suspends if `rsc` is `null`.\n    cacheNode.rsc = dynamicSegmentData\n  } else if (isDeferredRsc(rsc)) {\n    // This is a deferred RSC promise. We can fulfill it with the data we just\n    // received from the server. If it was already resolved by a different\n    // navigation, then this does nothing because we can't overwrite data.\n    rsc.resolve(dynamicSegmentData)\n  } else {\n    // This is not a deferred RSC promise, nor is it empty, so it must have\n    // been populated by a different navigation. We must not overwrite it.\n  }\n\n  // Check if this is a leaf segment. If so, it will have a `head` property with\n  // a pending promise that needs to be resolved with the dynamic head from\n  // the server.\n  const head = cacheNode.head\n  if (isDeferredRsc(head)) {\n    head.resolve(dynamicHead)\n  }\n}\n\nexport function abortTask(task: Task, error: any): void {\n  const cacheNode = task.node\n  if (cacheNode === null) {\n    // This indicates the task is already complete.\n    return\n  }\n\n  const taskChildren = task.children\n  if (taskChildren === null) {\n    // Reached the leaf task node. This is the root of a pending cache\n    // node tree.\n    abortPendingCacheNode(task.route, cacheNode, error)\n  } else {\n    // This is an intermediate task node. Keep traversing until we reach a\n    // task node with no children. That will be the root of the cache node tree\n    // that needs to be resolved.\n    for (const taskChild of taskChildren.values()) {\n      abortTask(taskChild, error)\n    }\n  }\n\n  // Set this to false to indicate that this task is now complete.\n  task.needsDynamicRequest = false\n}\n\nfunction abortPendingCacheNode(\n  routerState: FlightRouterState,\n  cacheNode: CacheNode,\n  error: any\n): void {\n  // For every pending segment in the tree, resolve its `rsc` promise to `null`\n  // to trigger a lazy fetch during render.\n  //\n  // Or, if an error object is provided, it will error instead.\n  const routerStateChildren = routerState[1]\n  const parallelRoutes = cacheNode.parallelRoutes\n  for (let parallelRouteKey in routerStateChildren) {\n    const routerStateChild: FlightRouterState =\n      routerStateChildren[parallelRouteKey]\n    const segmentMapChild = parallelRoutes.get(parallelRouteKey)\n    if (segmentMapChild === undefined) {\n      // This shouldn't happen because we're traversing the same tree that was\n      // used to construct the cache nodes in the first place.\n      continue\n    }\n    const segmentChild = routerStateChild[0]\n    const segmentKeyChild = createRouterCacheKey(segmentChild)\n    const cacheNodeChild = segmentMapChild.get(segmentKeyChild)\n    if (cacheNodeChild !== undefined) {\n      abortPendingCacheNode(routerStateChild, cacheNodeChild, error)\n    } else {\n      // This shouldn't happen because we're traversing the same tree that was\n      // used to construct the cache nodes in the first place.\n    }\n  }\n  const rsc = cacheNode.rsc\n  if (isDeferredRsc(rsc)) {\n    if (error === null) {\n      // This will trigger a lazy fetch during render.\n      rsc.resolve(null)\n    } else {\n      // This will trigger an error during rendering.\n      rsc.reject(error)\n    }\n  }\n\n  // Check if this is a leaf segment. If so, it will have a `head` property with\n  // a pending promise that needs to be resolved. If an error was provided, we\n  // will not resolve it with an error, since this is rendered at the root of\n  // the app. We want the segment to error, not the entire app.\n  const head = cacheNode.head\n  if (isDeferredRsc(head)) {\n    head.resolve(null)\n  }\n}\n\nexport function updateCacheNodeOnPopstateRestoration(\n  oldCacheNode: CacheNode,\n  routerState: FlightRouterState\n) {\n  // A popstate navigation reads data from the local cache. It does not issue\n  // new network requests (unless the cache entries have been evicted). So, we\n  // update the cache to drop the prefetch data for any segment whose dynamic\n  // data was already received. This prevents an unnecessary flash back to PPR\n  // state during a back/forward navigation.\n  //\n  // This function clones the entire cache node tree and sets the `prefetchRsc`\n  // field to `null` to prevent it from being rendered. We can't mutate the node\n  // in place because this is a concurrent data structure.\n\n  const routerStateChildren = routerState[1]\n  const oldParallelRoutes = oldCacheNode.parallelRoutes\n  const newParallelRoutes = new Map(oldParallelRoutes)\n  for (let parallelRouteKey in routerStateChildren) {\n    const routerStateChild: FlightRouterState =\n      routerStateChildren[parallelRouteKey]\n    const segmentChild = routerStateChild[0]\n    const segmentKeyChild = createRouterCacheKey(segmentChild)\n    const oldSegmentMapChild = oldParallelRoutes.get(parallelRouteKey)\n    if (oldSegmentMapChild !== undefined) {\n      const oldCacheNodeChild = oldSegmentMapChild.get(segmentKeyChild)\n      if (oldCacheNodeChild !== undefined) {\n        const newCacheNodeChild = updateCacheNodeOnPopstateRestoration(\n          oldCacheNodeChild,\n          routerStateChild\n        )\n        const newSegmentMapChild = new Map(oldSegmentMapChild)\n        newSegmentMapChild.set(segmentKeyChild, newCacheNodeChild)\n        newParallelRoutes.set(parallelRouteKey, newSegmentMapChild)\n      }\n    }\n  }\n\n  // Only show prefetched data if the dynamic data is still pending.\n  //\n  // Tehnically, what we're actually checking is whether the dynamic network\n  // response was received. But since it's a streaming response, this does not\n  // mean that all the dynamic data has fully streamed in. It just means that\n  // _some_ of the dynamic data was received. But as a heuristic, we assume that\n  // the rest dynamic data will stream in quickly, so it's still better to skip\n  // the prefetch state.\n  const rsc = oldCacheNode.rsc\n  const shouldUsePrefetch = isDeferredRsc(rsc) && rsc.status === 'pending'\n\n  return {\n    lazyData: null,\n    rsc,\n    head: oldCacheNode.head,\n\n    prefetchHead: shouldUsePrefetch ? oldCacheNode.prefetchHead : null,\n    prefetchRsc: shouldUsePrefetch ? oldCacheNode.prefetchRsc : null,\n    loading: oldCacheNode.loading,\n\n    // These are the cloned children we computed above\n    parallelRoutes: newParallelRoutes,\n  }\n}\n\nconst DEFERRED = Symbol()\n\ntype PendingDeferredRsc = Promise<React.ReactNode> & {\n  status: 'pending'\n  resolve: (value: React.ReactNode) => void\n  reject: (error: any) => void\n  tag: Symbol\n}\n\ntype FulfilledDeferredRsc = Promise<React.ReactNode> & {\n  status: 'fulfilled'\n  value: React.ReactNode\n  resolve: (value: React.ReactNode) => void\n  reject: (error: any) => void\n  tag: Symbol\n}\n\ntype RejectedDeferredRsc = Promise<React.ReactNode> & {\n  status: 'rejected'\n  reason: any\n  resolve: (value: React.ReactNode) => void\n  reject: (error: any) => void\n  tag: Symbol\n}\n\ntype DeferredRsc =\n  | PendingDeferredRsc\n  | FulfilledDeferredRsc\n  | RejectedDeferredRsc\n\n// This type exists to distinguish a DeferredRsc from a Flight promise. It's a\n// compromise to avoid adding an extra field on every Cache Node, which would be\n// awkward because the pre-PPR parts of codebase would need to account for it,\n// too. We can remove it once type Cache Node type is more settled.\nfunction isDeferredRsc(value: any): value is DeferredRsc {\n  return value && value.tag === DEFERRED\n}\n\nfunction createDeferredRsc(): PendingDeferredRsc {\n  let resolve: any\n  let reject: any\n  const pendingRsc = new Promise<React.ReactNode>((res, rej) => {\n    resolve = res\n    reject = rej\n  }) as PendingDeferredRsc\n  pendingRsc.status = 'pending'\n  pendingRsc.resolve = (value: React.ReactNode) => {\n    if (pendingRsc.status === 'pending') {\n      const fulfilledRsc: FulfilledDeferredRsc = pendingRsc as any\n      fulfilledRsc.status = 'fulfilled'\n      fulfilledRsc.value = value\n      resolve(value)\n    }\n  }\n  pendingRsc.reject = (error: any) => {\n    if (pendingRsc.status === 'pending') {\n      const rejectedRsc: RejectedDeferredRsc = pendingRsc as any\n      rejectedRsc.status = 'rejected'\n      rejectedRsc.reason = error\n      reject(error)\n    }\n  }\n  pendingRsc.tag = DEFERRED\n  return pendingRsc\n}\n"],"names":["abortTask","listenForDynamicRequest","updateCacheNodeOnNavigation","updateCacheNodeOnPopstateRestoration","oldCacheNode","oldRouterState","newRouterState","prefetchData","prefetchHead","isPrefetchHeadPartial","oldRouterStateChildren","newRouterStateChildren","prefetchDataChildren","oldParallelRoutes","parallelRoutes","prefetchParallelRoutes","Map","patchedRouterStateChildren","taskChildren","needsDynamicRequest","parallelRouteKey","newRouterStateChild","oldRouterStateChild","oldSegmentMapChild","get","prefetchDataChild","newSegmentChild","newSegmentKeyChild","createRouterCacheKey","oldSegmentChild","undefined","oldCacheNodeChild","taskChild","DEFAULT_SEGMENT_KEY","spawnReusedTask","createCacheNodeOnNavigation","matchSegment","set","newCacheNodeChild","node","newSegmentMapChild","route","newCacheNode","lazyData","rsc","prefetchRsc","head","loading","patchRouterStateWithNewChildren","children","routerState","possiblyPartialPrefetchHead","spawnPendingTask","routerStateChildren","isPrefetchRscPartial","isLeafSegment","Object","keys","length","cacheNodeChildren","routerStateChild","segmentChild","segmentKeyChild","baseRouterState","newChildren","clone","newTask","createPendingCacheNode","reusedRouterState","task","responsePromise","then","flightData","normalizedFlightData","segmentPath","tree","serverRouterState","seedData","dynamicData","dynamicHead","writeDynamicDataIntoPendingTask","error","rootTask","i","segment","taskSegment","finishTaskUsingDynamicDataPayload","taskNode","finishPendingCacheNode","serverChildren","dynamicDataChildren","serverRouterStateChild","dynamicDataChild","size","maybePrefetchRsc","maybePrefetchLoading","createDeferredRsc","cacheNode","taskState","serverState","taskStateChildren","serverStateChildren","dataChildren","taskStateChild","serverStateChild","dataChild","segmentMapChild","taskSegmentChild","taskSegmentKeyChild","cacheNodeChild","abortPendingCacheNode","dynamicSegmentData","isDeferredRsc","resolve","values","reject","newParallelRoutes","shouldUsePrefetch","status","DEFERRED","Symbol","value","tag","pendingRsc","Promise","res","rej","fulfilledRsc","rejectedRsc","reason"],"mappings":";;;;;;;;;;;;;;;;;IAovBgBA,SAAS,EAAA;eAATA;;IAnUAC,uBAAuB,EAAA;eAAvBA;;IAhXAC,2BAA2B,EAAA;eAA3BA;;IA+vBAC,oCAAoC,EAAA;eAApCA;;;yBArzBoB;+BACP;sCACQ;AAoD9B,SAASD,4BACdE,YAAuB,EACvBC,cAAiC,EACjCC,cAAiC,EACjCC,YAAsC,EACtCC,YAAoC,EACpCC,qBAA8B;IAE9B,0DAA0D;IAC1D,MAAMC,yBAAyBL,cAAc,CAAC,EAAE;IAChD,MAAMM,yBAAyBL,cAAc,CAAC,EAAE;IAChD,MAAMM,uBAAuBL,iBAAiB,OAAOA,YAAY,CAAC,EAAE,GAAG;IAEvE,MAAMM,oBAAoBT,aAAaU,cAAc;IAErD,2EAA2E;IAC3E,gBAAgB;IAChB,0EAA0E;IAC1E,0EAA0E;IAC1E,4EAA4E;IAC5E,2EAA2E;IAC3E,0EAA0E;IAC1E,uEAAuE;IACvE,yEAAyE;IACzE,wEAAwE;IACxE,+BAA+B;IAC/B,MAAMC,yBAAyB,IAAIC,IAAIH;IAEvC,4EAA4E;IAC5E,4EAA4E;IAC5E,2EAA2E;IAC3E,6EAA6E;IAC7E,mBAAmB;IACnB,IAAII,6BAEA,CAAC;IACL,IAAIC,eAAe;IAEnB,uEAAuE;IACvE,6EAA6E;IAC7E,gEAAgE;IAChE,EAAE;IACF,4EAA4E;IAC5E,sEAAsE;IACtE,EAAE;IACF,uEAAuE;IACvE,qCAAqC;IACrC,IAAIC,sBAAsB;IAE1B,IAAK,IAAIC,oBAAoBT,uBAAwB;QACnD,MAAMU,sBACJV,sBAAsB,CAACS,iBAAiB;QAC1C,MAAME,sBACJZ,sBAAsB,CAACU,iBAAiB;QAC1C,MAAMG,qBAAqBV,kBAAkBW,GAAG,CAACJ;QACjD,MAAMK,oBACJb,yBAAyB,OACrBA,oBAAoB,CAACQ,iBAAiB,GACtC;QAEN,MAAMM,kBAAkBL,mBAAmB,CAAC,EAAE;QAC9C,MAAMM,qBAAqBC,CAAAA,GAAAA,sBAAAA,oBAAoB,EAACF;QAEhD,MAAMG,kBACJP,wBAAwBQ,YAAYR,mBAAmB,CAAC,EAAE,GAAGQ;QAE/D,MAAMC,oBACJR,uBAAuBO,YACnBP,mBAAmBC,GAAG,CAACG,sBACvBG;QAEN,IAAIE;QACJ,IAAIN,oBAAoBO,SAAAA,mBAAmB,EAAE;YAC3C,0DAA0D;YAC1D,EAAE;YACF,yEAAyE;YACzE,uEAAuE;YACvE,sEAAsE;YACtE,oEAAoE;YACpE,WAAW;YACX,IAAIX,wBAAwBQ,WAAW;gBACrC,sEAAsE;gBACtE,oEAAoE;gBACpE,mEAAmE;gBACnEE,YAAYE,gBAAgBZ;YAC9B,OAAO;gBACL,oEAAoE;gBACpEU,YAAYG,4BACVd,qBACAI,sBAAsBK,YAAYL,oBAAoB,MACtDjB,cACAC;YAEJ;QACF,OAAO,IACLoB,oBAAoBC,aACpBM,CAAAA,GAAAA,eAAAA,YAAY,EAACV,iBAAiBG,kBAC9B;YACA,IACEE,sBAAsBD,aACtBR,wBAAwBQ,WACxB;gBACA,wEAAwE;gBACxE,gBAAgB;gBAChBE,YAAY9B,4BACV6B,mBACAT,qBACAD,qBACAI,mBACAjB,cACAC;YAEJ,OAAO;gBACL,kEAAkE;gBAClE,oEAAoE;gBACpE,iBAAiB;gBACjBuB,YAAYG,4BACVd,qBACAI,sBAAsBK,YAAYL,oBAAoB,MACtDjB,cACAC;YAEJ;QACF,OAAO;YACL,mDAAmD;YACnDuB,YAAYG,4BACVd,qBACAI,sBAAsBK,YAAYL,oBAAoB,MACtDjB,cACAC;QAEJ;QAEA,IAAIuB,cAAc,MAAM;YACtB,qEAAqE;YACrE,IAAId,iBAAiB,MAAM;gBACzBA,eAAe,IAAIF;YACrB;YACAE,aAAamB,GAAG,CAACjB,kBAAkBY;YACnC,MAAMM,oBAAoBN,UAAUO,IAAI;YACxC,IAAID,sBAAsB,MAAM;gBAC9B,MAAME,qBAAsC,IAAIxB,IAAIO;gBACpDiB,mBAAmBH,GAAG,CAACV,oBAAoBW;gBAC3CvB,uBAAuBsB,GAAG,CAACjB,kBAAkBoB;YAC/C;YAEA,IAAIR,UAAUb,mBAAmB,EAAE;gBACjCA,sBAAsB;YACxB;YAEA,oEAAoE;YACpE,uEAAuE;YACvE,YAAY;YACZF,0BAA0B,CAACG,iBAAiB,GAAGY,UAAUS,KAAK;QAChE,OAAO;YACL,mEAAmE;YACnExB,0BAA0B,CAACG,iBAAiB,GAAGC;QACjD;IACF;IAEA,IAAIH,iBAAiB,MAAM;QACzB,6BAA6B;QAC7B,OAAO;IACT;IAEA,MAAMwB,eAA+B;QACnCC,UAAU;QACVC,KAAKxC,aAAawC,GAAG;QACrB,0EAA0E;QAC1E,qEAAqE;QACrE,2EAA2E;QAC3E,0EAA0E;QAC1E,2EAA2E;QAC3E,qCAAqC;QACrCC,aAAazC,aAAayC,WAAW;QACrCC,MAAM1C,aAAa0C,IAAI;QACvBtC,cAAcJ,aAAaI,YAAY;QACvCuC,SAAS3C,aAAa2C,OAAO;QAE7B,yEAAyE;QACzEjC,gBAAgBC;IAClB;IAEA,OAAO;QACL,kEAAkE;QAClE0B,OAAOO,gCACL1C,gBACAW;QAEFsB,MAAMG;QACNvB;QACA8B,UAAU/B;IACZ;AACF;AAEA,SAASiB,4BACPe,WAA8B,EAC9B3C,YAAsC,EACtC4C,2BAAmD,EACnD1C,qBAA8B;IAE9B,0EAA0E;IAC1E,4EAA4E;IAC5E,6EAA6E;IAC7E,IAAIF,iBAAiB,MAAM;QACzB,2EAA2E;QAC3E,yEAAyE;QACzE,8DAA8D;QAC9D,mBAAmB;QACnB,OAAO6C,iBACLF,aACA,MACAC,6BACA1C;IAEJ;IAEA,MAAM4C,sBAAsBH,WAAW,CAAC,EAAE;IAC1C,MAAMI,uBAAuB/C,YAAY,CAAC,EAAE;IAE5C,4EAA4E;IAC5E,mEAAmE;IACnE,MAAMgD,gBAAgBC,OAAOC,IAAI,CAACJ,qBAAqBK,MAAM,KAAK;IAElE,2EAA2E;IAC3E,wEAAwE;IACxE,cAAc;IACd,IACE,AACAJ,wBACA,eAFuC,0DAEkC;IACxE7C,yBAAyB8C,eAC1B;QACA,yEAAyE;QACzE,8CAA8C;QAC9C,OAAOH,iBACLF,aACA3C,cACA4C,6BACA1C;IAEJ;IAEA,4EAA4E;IAC5E,8EAA8E;IAC9E,mCAAmC;IACnC,MAAMG,uBAAuBL,YAAY,CAAC,EAAE;IAC5C,MAAMW,eAAe,IAAIF;IACzB,MAAM2C,oBAAoB,IAAI3C;IAC9B,IAAIG,sBAAsB;IAC1B,IAAK,IAAIC,oBAAoBiC,oBAAqB;QAChD,MAAMO,mBACJP,mBAAmB,CAACjC,iBAAiB;QACvC,MAAMK,oBACJb,yBAAyB,OACrBA,oBAAoB,CAACQ,iBAAiB,GACtC;QACN,MAAMyC,eAAeD,gBAAgB,CAAC,EAAE;QACxC,MAAME,kBAAkBlC,CAAAA,GAAAA,sBAAAA,oBAAoB,EAACiC;QAC7C,MAAM7B,YAAYG,4BAChByB,kBACAnC,mBACA0B,6BACA1C;QAEFS,aAAamB,GAAG,CAACjB,kBAAkBY;QACnC,IAAIA,UAAUb,mBAAmB,EAAE;YACjCA,sBAAsB;QACxB;QACA,MAAMmB,oBAAoBN,UAAUO,IAAI;QACxC,IAAID,sBAAsB,MAAM;YAC9B,MAAME,qBAAsC,IAAIxB;YAChDwB,mBAAmBH,GAAG,CAACyB,iBAAiBxB;YACxCqB,kBAAkBtB,GAAG,CAACjB,kBAAkBoB;QAC1C;IACF;IAEA,MAAMI,MAAMrC,YAAY,CAAC,EAAE;IAC3B,MAAMwC,UAAUxC,YAAY,CAAC,EAAE;IAC/B,OAAO;QACLkC,OAAOS;QACPX,MAAM;YACJI,UAAU;YACV,iEAAiE;YACjE,uBAAuB;YACvBC;YACAC,aAAa;YACbC,MAAMS,gBAAgBJ,8BAA8B;YACpD3C,cAAc;YACduC;YACAjC,gBAAgB6C;QAClB;QACAxC;QACA8B,UAAU/B;IACZ;AACF;AAEA,SAAS8B,gCACPe,eAAkC,EAClCC,WAA8D;IAE9D,MAAMC,QAA2B;QAACF,eAAe,CAAC,EAAE;QAAEC;KAAY;IAClE,4EAA4E;IAC5E,2EAA2E;IAC3E,uCAAuC;IACvC,IAAI,KAAKD,iBAAiB;QACxBE,KAAK,CAAC,EAAE,GAAGF,eAAe,CAAC,EAAE;IAC/B;IACA,IAAI,KAAKA,iBAAiB;QACxBE,KAAK,CAAC,EAAE,GAAGF,eAAe,CAAC,EAAE;IAC/B;IACA,IAAI,KAAKA,iBAAiB;QACxBE,KAAK,CAAC,EAAE,GAAGF,eAAe,CAAC,EAAE;IAC/B;IACA,OAAOE;AACT;AAEA,SAASb,iBACPF,WAA8B,EAC9B3C,YAAsC,EACtCC,YAAoC,EACpCC,qBAA8B;IAE9B,sEAAsE;IACtE,MAAMyD,UAAgB;QACpBzB,OAAOS;QAEP,4EAA4E;QAC5EX,MAAM4B,uBACJjB,aACA3C,cACAC,cACAC;QAEF,yEAAyE;QACzE,yCAAyC;QACzCU,qBAAqB;QACrB8B,UAAU;IACZ;IACA,OAAOiB;AACT;AAEA,SAAShC,gBAAgBkC,iBAAoC;IAC3D,mEAAmE;IACnE,0DAA0D;IAC1D,OAAO;QACL3B,OAAO2B;QACP7B,MAAM;QACNpB,qBAAqB;QACrB8B,UAAU;IACZ;AACF;AAiBO,SAAShD,wBACdoE,IAAU,EACVC,eAAmD;IAEnDA,gBAAgBC,IAAI,CAClB,CAAA;YAAC,EAAEC,UAAU,EAA6B,GAAA;QACxC,IAAI,OAAOA,eAAe,UAAU;YAClC,sEAAsE;YACtE,2DAA2D;YAC3D,gBAAgB;YAChB;QACF;QACA,KAAK,MAAMC,wBAAwBD,WAAY;YAC7C,MAAM,EACJE,WAAW,EACXC,MAAMC,iBAAiB,EACvBC,UAAUC,WAAW,EACrBhC,MAAMiC,WAAW,EAClB,GAAGN;YAEJ,IAAI,CAACK,aAAa;gBAIhB;YACF;YAEAE,gCACEX,MACAK,aACAE,mBACAE,aACAC;QAEJ;QAEA,wEAAwE;QACxE,qEAAqE;QACrE,6DAA6D;QAC7D/E,UAAUqE,MAAM;IAClB,GACA,CAACY;QACC,2CAA2C;QAC3CjF,UAAUqE,MAAMY;IAClB;AAEJ;AAEA,SAASD,gCACPE,QAAc,EACdR,WAA8B,EAC9BE,iBAAoC,EACpCE,WAA8B,EAC9BC,WAA4B;IAE5B,4EAA4E;IAC5E,0EAA0E;IAC1E,qCAAqC;IACrC,EAAE;IACF,8EAA8E;IAC9E,qCAAqC;IACrC,EAAE;IACF,6DAA6D;IAC7D,EAAE;IACF,yEAAyE;IACzE,IAAIV,OAAOa;IACX,IAAK,IAAIC,IAAI,GAAGA,IAAIT,YAAYhB,MAAM,EAAEyB,KAAK,EAAG;QAC9C,MAAM/D,mBAA2BsD,WAAW,CAACS,EAAE;QAC/C,MAAMC,UAAmBV,WAAW,CAACS,IAAI,EAAE;QAC3C,MAAMjE,eAAemD,KAAKpB,QAAQ;QAClC,IAAI/B,iBAAiB,MAAM;YACzB,MAAMc,YAAYd,aAAaM,GAAG,CAACJ;YACnC,IAAIY,cAAcF,WAAW;gBAC3B,MAAMuD,cAAcrD,UAAUS,KAAK,CAAC,EAAE;gBACtC,IAAIL,CAAAA,GAAAA,eAAAA,YAAY,EAACgD,SAASC,cAAc;oBACtC,mEAAmE;oBACnEhB,OAAOrC;oBACP;gBACF;YACF;QACF;QACA,2EAA2E;QAC3E,4EAA4E;QAC5E,wEAAwE;QACxE,8BAA8B;QAC9B;IACF;IAEAsD,kCACEjB,MACAO,mBACAE,aACAC;AAEJ;AAEA,SAASO,kCACPjB,IAAU,EACVO,iBAAoC,EACpCE,WAA8B,EAC9BC,WAA4B;IAE5B,IAAI,CAACV,KAAKlD,mBAAmB,EAAE;QAC7B,4DAA4D;QAC5D;IACF;IAEA,0EAA0E;IAC1E,4CAA4C;IAC5C,MAAMD,eAAemD,KAAKpB,QAAQ;IAClC,MAAMsC,WAAWlB,KAAK9B,IAAI;IAC1B,IAAIrB,iBAAiB,MAAM;QACzB,wEAAwE;QACxE,iEAAiE;QACjE,oBAAoB;QACpB,IAAIqE,aAAa,MAAM;YACrBC,uBACED,UACAlB,KAAK5B,KAAK,EACVmC,mBACAE,aACAC;YAEF,gEAAgE;YAChEV,KAAKlD,mBAAmB,GAAG;QAC7B;QACA;IACF;IACA,2EAA2E;IAC3E,wDAAwD;IACxD,MAAMsE,iBAAiBb,iBAAiB,CAAC,EAAE;IAC3C,MAAMc,sBAAsBZ,WAAW,CAAC,EAAE;IAE1C,IAAK,MAAM1D,oBAAoBwD,kBAAmB;QAChD,MAAMe,yBACJF,cAAc,CAACrE,iBAAiB;QAClC,MAAMwE,mBACJF,mBAAmB,CAACtE,iBAAiB;QAEvC,MAAMY,YAAYd,aAAaM,GAAG,CAACJ;QACnC,IAAIY,cAAcF,WAAW;YAC3B,MAAMuD,cAAcrD,UAAUS,KAAK,CAAC,EAAE;YACtC,IACEL,CAAAA,GAAAA,eAAAA,YAAY,EAACuD,sBAAsB,CAAC,EAAE,EAAEN,gBACxCO,qBAAqB,QACrBA,qBAAqB9D,WACrB;gBACA,mEAAmE;gBACnE,OAAOwD,kCACLtD,WACA2D,wBACAC,kBACAb;YAEJ;QACF;IACA,2EAA2E;IAC3E,sEAAsE;IACtE,wEAAwE;IACxE,8BAA8B;IAChC;AACF;AAEA,SAASZ,uBACPjB,WAA8B,EAC9B3C,YAAsC,EACtCC,YAAoC,EACpCC,qBAA8B;IAE9B,MAAM4C,sBAAsBH,WAAW,CAAC,EAAE;IAC1C,MAAMtC,uBAAuBL,iBAAiB,OAAOA,YAAY,CAAC,EAAE,GAAG;IAEvE,MAAMO,iBAAiB,IAAIE;IAC3B,IAAK,IAAII,oBAAoBiC,oBAAqB;QAChD,MAAMO,mBACJP,mBAAmB,CAACjC,iBAAiB;QACvC,MAAMK,oBACJb,yBAAyB,OACrBA,oBAAoB,CAACQ,iBAAiB,GACtC;QAEN,MAAMyC,eAAeD,gBAAgB,CAAC,EAAE;QACxC,MAAME,kBAAkBlC,CAAAA,GAAAA,sBAAAA,oBAAoB,EAACiC;QAE7C,MAAMvB,oBAAoB6B,uBACxBP,kBACAnC,sBAAsBK,YAAY,OAAOL,mBACzCjB,cACAC;QAGF,MAAM+B,qBAAsC,IAAIxB;QAChDwB,mBAAmBH,GAAG,CAACyB,iBAAiBxB;QACxCxB,eAAeuB,GAAG,CAACjB,kBAAkBoB;IACvC;IAEA,4EAA4E;IAC5E,mEAAmE;IACnE,MAAMe,gBAAgBzC,eAAe+E,IAAI,KAAK;IAC9C,MAAMC,mBAAmBvF,iBAAiB,OAAOA,YAAY,CAAC,EAAE,GAAG;IACnE,MAAMwF,uBAAuBxF,iBAAiB,OAAOA,YAAY,CAAC,EAAE,GAAG;IACvE,OAAO;QACLoC,UAAU;QACV7B,gBAAgBA;QAEhB+B,aAAaiD,qBAAqBhE,YAAYgE,mBAAmB;QACjEtF,cAAc+C,gBAAgB/C,eAAe;QAE7C,4EAA4E;QAC5E,4EAA4E;QAC5E,uCAAuC;QACvCuC,SAASgD,yBAAyBjE,YAAYiE,uBAAuB;QAErE,qEAAqE;QACrE,wCAAwC;QACxCnD,KAAKoD;QACLlD,MAAMS,gBAAiByC,sBAA0C;IACnE;AACF;AAEA,SAASR,uBACPS,SAAoB,EACpBC,SAA4B,EAC5BC,WAA8B,EAC9BrB,WAA8B,EAC9BC,WAA4B;IAE5B,8EAA8E;IAC9E,8EAA8E;IAC9E,4EAA4E;IAC5E,8EAA8E;IAC9E,8DAA8D;IAC9D,6BAA6B;IAC7B,EAAE;IACF,qEAAqE;IACrE,8EAA8E;IAC9E,gEAAgE;IAChE,MAAMqB,oBAAoBF,SAAS,CAAC,EAAE;IACtC,MAAMG,sBAAsBF,WAAW,CAAC,EAAE;IAC1C,MAAMG,eAAexB,WAAW,CAAC,EAAE;IAEnC,8EAA8E;IAC9E,6EAA6E;IAC7E,uCAAuC;IACvC,MAAMhE,iBAAiBmF,UAAUnF,cAAc;IAC/C,IAAK,IAAIM,oBAAoBgF,kBAAmB;QAC9C,MAAMG,iBACJH,iBAAiB,CAAChF,iBAAiB;QACrC,MAAMoF,mBACJH,mBAAmB,CAACjF,iBAAiB;QACvC,MAAMqF,YACJH,YAAY,CAAClF,iBAAiB;QAEhC,MAAMsF,kBAAkB5F,eAAeU,GAAG,CAACJ;QAC3C,MAAMuF,mBAAmBJ,cAAc,CAAC,EAAE;QAC1C,MAAMK,sBAAsBhF,CAAAA,GAAAA,sBAAAA,oBAAoB,EAAC+E;QAEjD,MAAME,iBACJH,oBAAoB5E,YAChB4E,gBAAgBlF,GAAG,CAACoF,uBACpB9E;QAEN,IAAI+E,mBAAmB/E,WAAW;YAChC,IACE0E,qBAAqB1E,aACrBM,CAAAA,GAAAA,eAAAA,YAAY,EAACuE,kBAAkBH,gBAAgB,CAAC,EAAE,GAClD;gBACA,IAAIC,cAAc3E,aAAa2E,cAAc,MAAM;oBACjD,+DAA+D;oBAC/DjB,uBACEqB,gBACAN,gBACAC,kBACAC,WACA1B;gBAEJ,OAAO;oBACL,kEAAkE;oBAClE,oEAAoE;oBACpE,sEAAsE;oBACtE,+CAA+C;oBAC/C+B,sBAAsBP,gBAAgBM,gBAAgB;gBACxD;YACF,OAAO;gBACL,kEAAkE;gBAClE,uBAAuB;gBACvBC,sBAAsBP,gBAAgBM,gBAAgB;YACxD;QACF,OAAO;QACL,wEAAwE;QACxE,gEAAgE;QAChE,iEAAiE;QACjE,wDAAwD;QAC1D;IACF;IAEA,2EAA2E;IAC3E,qBAAqB;IACrB,MAAMjE,MAAMqD,UAAUrD,GAAG;IACzB,MAAMmE,qBAAqBjC,WAAW,CAAC,EAAE;IACzC,IAAIlC,QAAQ,MAAM;QAChB,oEAAoE;QACpE,qEAAqE;QACrEqD,UAAUrD,GAAG,GAAGmE;IAClB,OAAO,IAAIC,cAAcpE,MAAM;QAC7B,0EAA0E;QAC1E,sEAAsE;QACtE,sEAAsE;QACtEA,IAAIqE,OAAO,CAACF;IACd,OAAO;IACL,uEAAuE;IACvE,sEAAsE;IACxE;IAEA,8EAA8E;IAC9E,yEAAyE;IACzE,cAAc;IACd,MAAMjE,OAAOmD,UAAUnD,IAAI;IAC3B,IAAIkE,cAAclE,OAAO;QACvBA,KAAKmE,OAAO,CAAClC;IACf;AACF;AAEO,SAAS/E,UAAUqE,IAAU,EAAEY,KAAU;IAC9C,MAAMgB,YAAY5B,KAAK9B,IAAI;IAC3B,IAAI0D,cAAc,MAAM;QACtB,+CAA+C;QAC/C;IACF;IAEA,MAAM/E,eAAemD,KAAKpB,QAAQ;IAClC,IAAI/B,iBAAiB,MAAM;QACzB,kEAAkE;QAClE,aAAa;QACb4F,sBAAsBzC,KAAK5B,KAAK,EAAEwD,WAAWhB;IAC/C,OAAO;QACL,sEAAsE;QACtE,2EAA2E;QAC3E,6BAA6B;QAC7B,KAAK,MAAMjD,aAAad,aAAagG,MAAM,GAAI;YAC7ClH,UAAUgC,WAAWiD;QACvB;IACF;IAEA,gEAAgE;IAChEZ,KAAKlD,mBAAmB,GAAG;AAC7B;AAEA,SAAS2F,sBACP5D,WAA8B,EAC9B+C,SAAoB,EACpBhB,KAAU;IAEV,6EAA6E;IAC7E,yCAAyC;IACzC,EAAE;IACF,6DAA6D;IAC7D,MAAM5B,sBAAsBH,WAAW,CAAC,EAAE;IAC1C,MAAMpC,iBAAiBmF,UAAUnF,cAAc;IAC/C,IAAK,IAAIM,oBAAoBiC,oBAAqB;QAChD,MAAMO,mBACJP,mBAAmB,CAACjC,iBAAiB;QACvC,MAAMsF,kBAAkB5F,eAAeU,GAAG,CAACJ;QAC3C,IAAIsF,oBAAoB5E,WAAW;YAGjC;QACF;QACA,MAAM+B,eAAeD,gBAAgB,CAAC,EAAE;QACxC,MAAME,kBAAkBlC,CAAAA,GAAAA,sBAAAA,oBAAoB,EAACiC;QAC7C,MAAMgD,iBAAiBH,gBAAgBlF,GAAG,CAACsC;QAC3C,IAAI+C,mBAAmB/E,WAAW;YAChCgF,sBAAsBlD,kBAAkBiD,gBAAgB5B;QAC1D,OAAO;QACL,wEAAwE;QACxE,wDAAwD;QAC1D;IACF;IACA,MAAMrC,MAAMqD,UAAUrD,GAAG;IACzB,IAAIoE,cAAcpE,MAAM;QACtB,IAAIqC,UAAU,MAAM;YAClB,gDAAgD;YAChDrC,IAAIqE,OAAO,CAAC;QACd,OAAO;YACL,+CAA+C;YAC/CrE,IAAIuE,MAAM,CAAClC;QACb;IACF;IAEA,8EAA8E;IAC9E,4EAA4E;IAC5E,2EAA2E;IAC3E,6DAA6D;IAC7D,MAAMnC,OAAOmD,UAAUnD,IAAI;IAC3B,IAAIkE,cAAclE,OAAO;QACvBA,KAAKmE,OAAO,CAAC;IACf;AACF;AAEO,SAAS9G,qCACdC,YAAuB,EACvB8C,WAA8B;IAE9B,2EAA2E;IAC3E,4EAA4E;IAC5E,2EAA2E;IAC3E,4EAA4E;IAC5E,0CAA0C;IAC1C,EAAE;IACF,6EAA6E;IAC7E,8EAA8E;IAC9E,wDAAwD;IAExD,MAAMG,sBAAsBH,WAAW,CAAC,EAAE;IAC1C,MAAMrC,oBAAoBT,aAAaU,cAAc;IACrD,MAAMsG,oBAAoB,IAAIpG,IAAIH;IAClC,IAAK,IAAIO,oBAAoBiC,oBAAqB;QAChD,MAAMO,mBACJP,mBAAmB,CAACjC,iBAAiB;QACvC,MAAMyC,eAAeD,gBAAgB,CAAC,EAAE;QACxC,MAAME,kBAAkBlC,CAAAA,GAAAA,sBAAAA,oBAAoB,EAACiC;QAC7C,MAAMtC,qBAAqBV,kBAAkBW,GAAG,CAACJ;QACjD,IAAIG,uBAAuBO,WAAW;YACpC,MAAMC,oBAAoBR,mBAAmBC,GAAG,CAACsC;YACjD,IAAI/B,sBAAsBD,WAAW;gBACnC,MAAMQ,oBAAoBnC,qCACxB4B,mBACA6B;gBAEF,MAAMpB,qBAAqB,IAAIxB,IAAIO;gBACnCiB,mBAAmBH,GAAG,CAACyB,iBAAiBxB;gBACxC8E,kBAAkB/E,GAAG,CAACjB,kBAAkBoB;YAC1C;QACF;IACF;IAEA,kEAAkE;IAClE,EAAE;IACF,0EAA0E;IAC1E,4EAA4E;IAC5E,2EAA2E;IAC3E,8EAA8E;IAC9E,6EAA6E;IAC7E,sBAAsB;IACtB,MAAMI,MAAMxC,aAAawC,GAAG;IAC5B,MAAMyE,oBAAoBL,cAAcpE,QAAQA,IAAI0E,MAAM,KAAK;IAE/D,OAAO;QACL3E,UAAU;QACVC;QACAE,MAAM1C,aAAa0C,IAAI;QAEvBtC,cAAc6G,oBAAoBjH,aAAaI,YAAY,GAAG;QAC9DqC,aAAawE,oBAAoBjH,aAAayC,WAAW,GAAG;QAC5DE,SAAS3C,aAAa2C,OAAO;QAE7B,kDAAkD;QAClDjC,gBAAgBsG;IAClB;AACF;AAEA,MAAMG,WAAWC;AA8BjB,8EAA8E;AAC9E,gFAAgF;AAChF,8EAA8E;AAC9E,mEAAmE;AACnE,SAASR,cAAcS,KAAU;IAC/B,OAAOA,SAASA,MAAMC,GAAG,KAAKH;AAChC;AAEA,SAASvB;IACP,IAAIiB;IACJ,IAAIE;IACJ,MAAMQ,aAAa,IAAIC,QAAyB,CAACC,KAAKC;QACpDb,UAAUY;QACVV,SAASW;IACX;IACAH,WAAWL,MAAM,GAAG;IACpBK,WAAWV,OAAO,GAAG,CAACQ;QACpB,IAAIE,WAAWL,MAAM,KAAK,WAAW;YACnC,MAAMS,eAAqCJ;YAC3CI,aAAaT,MAAM,GAAG;YACtBS,aAAaN,KAAK,GAAGA;YACrBR,QAAQQ;QACV;IACF;IACAE,WAAWR,MAAM,GAAG,CAAClC;QACnB,IAAI0C,WAAWL,MAAM,KAAK,WAAW;YACnC,MAAMU,cAAmCL;YACzCK,YAAYV,MAAM,GAAG;YACrBU,YAAYC,MAAM,GAAGhD;YACrBkC,OAAOlC;QACT;IACF;IACA0C,WAAWD,GAAG,GAAGH;IACjB,OAAOI;AACT","ignoreList":[0]}},
    {"offset": {"line": 1138, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1143, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/router-reducer/create-href-from-url.ts"],"sourcesContent":["export function createHrefFromUrl(\n  url: Pick<URL, 'pathname' | 'search' | 'hash'>,\n  includeHash: boolean = true\n): string {\n  return url.pathname + url.search + (includeHash ? url.hash : '')\n}\n"],"names":["createHrefFromUrl","url","includeHash","pathname","search","hash"],"mappings":";;;;+BAAgBA,qBAAAA;;;eAAAA;;;AAAT,SAASA,kBACdC,GAA8C,EAC9CC,WAA2B;IAA3BA,IAAAA,gBAAAA,KAAAA,GAAAA,cAAuB;IAEvB,OAAOD,IAAIE,QAAQ,GAAGF,IAAIG,MAAM,GAAIF,CAAAA,cAAcD,IAAII,IAAI,GAAG,EAAC;AAChE","ignoreList":[0]}},
    {"offset": {"line": 1164, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1169, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/scheduler.ts"],"sourcesContent":["import type { TreePrefetch } from '../../../server/app-render/collect-segment-data'\nimport {\n  requestRouteCacheEntryFromCache,\n  requestSegmentEntryFromCache,\n  EntryStatus,\n  type FulfilledRouteCacheEntry,\n  type RouteCacheEntry,\n} from './cache'\nimport type { RouteCacheKey } from './cache-key'\n\nconst scheduleMicrotask =\n  typeof queueMicrotask === 'function'\n    ? queueMicrotask\n    : (fn: () => unknown) =>\n        Promise.resolve()\n          .then(fn)\n          .catch((error) =>\n            setTimeout(() => {\n              throw error\n            })\n          )\n\nexport type PrefetchTask = {\n  key: RouteCacheKey\n\n  /**\n   * sortId is an incrementing counter\n   *\n   * Newer prefetches are prioritized over older ones, so that as new links\n   * enter the viewport, they are not starved by older links that are no\n   * longer relevant. In the future, we can add additional prioritization\n   * heuristics, like removing prefetches once a link leaves the viewport.\n   *\n   * The sortId is assigned when the prefetch is initiated, and reassigned if\n   * the same URL is prefetched again (effectively bumping it to the top of\n   * the queue).\n   *\n   * TODO: We can add additional fields here to indicate what kind of prefetch\n   * it is. For example, was it initiated by a link? Or was it an imperative\n   * call? If it was initiated by a link, we can remove it from the queue when\n   * the link leaves the viewport, but if it was an imperative call, then we\n   * should keep it in the queue until it's fulfilled.\n   *\n   * We can also add priority levels. For example, hovering over a link could\n   * increase the priority of its prefetch.\n   */\n  sortId: number\n\n  /**\n   * True if the prefetch is blocked by network data. We remove tasks from the\n   * queue once they are blocked, and add them back when they receive data.\n   *\n   * isBlocked also indicates whether the task is currently in the queue; tasks\n   * are removed from the queue when they are blocked. Use this to avoid\n   * queueing the same task multiple times.\n   */\n  isBlocked: boolean\n\n  /**\n   * The index of the task in the heap's backing array. Used to efficiently\n   * change the priority of a task by re-sifting it, which requires knowing\n   * where it is in the array. This is only used internally by the heap\n   * algorithm. The naive alternative is indexOf every time a task is queued,\n   * which has O(n) complexity.\n   */\n  _heapIndex: number\n}\n\nconst enum PrefetchTaskExitStatus {\n  /**\n   * The task yielded because there are too many requests in progress.\n   */\n  InProgress,\n\n  /**\n   * The task is blocked. It needs more data before it can proceed.\n   *\n   * Currently the only reason this happens is we're still waiting to receive a\n   * route tree from the server, because we can't start prefetching the segments\n   * until we know what to prefetch.\n   */\n  Blocked,\n\n  /**\n   * There's nothing left to prefetch.\n   */\n  Done,\n}\n\nconst taskHeap: Array<PrefetchTask> = []\n\n// This is intentionally low so that when a navigation happens, the browser's\n// internal network queue is not already saturated with prefetch requests.\nconst MAX_CONCURRENT_PREFETCH_REQUESTS = 3\nlet inProgressRequests = 0\n\nlet sortIdCounter = 0\nlet didScheduleMicrotask = false\n\n/**\n * Initiates a prefetch task for the given URL. If a prefetch for the same URL\n * is already in progress, this will bump it to the top of the queue.\n *\n * This is not a user-facing function. By the time this is called, the href is\n * expected to be validated and normalized.\n *\n * @param key The RouteCacheKey to prefetch.\n */\nexport function schedulePrefetchTask(key: RouteCacheKey): void {\n  // Spawn a new prefetch task\n  const task: PrefetchTask = {\n    key,\n    sortId: sortIdCounter++,\n    isBlocked: false,\n    _heapIndex: -1,\n  }\n  heapPush(taskHeap, task)\n\n  // Schedule an async task to process the queue.\n  //\n  // The main reason we process the queue in an async task is for batching.\n  // It's common for a single JS task/event to trigger multiple prefetches.\n  // By deferring to a microtask, we only process the queue once per JS task.\n  // If they have different priorities, it also ensures they are processed in\n  // the optimal order.\n  ensureWorkIsScheduled()\n}\n\nfunction ensureWorkIsScheduled() {\n  if (didScheduleMicrotask || !hasNetworkBandwidth()) {\n    // Either we already scheduled a task to process the queue, or there are\n    // too many concurrent requests in progress. In the latter case, the\n    // queue will resume processing once more bandwidth is available.\n    return\n  }\n  didScheduleMicrotask = true\n  scheduleMicrotask(processQueueInMicrotask)\n}\n\n/**\n * Checks if we've exceeded the maximum number of concurrent prefetch requests,\n * to avoid saturating the browser's internal network queue. This is a\n * cooperative limit â prefetch tasks should check this before issuing\n * new requests.\n */\nfunction hasNetworkBandwidth(): boolean {\n  // TODO: Also check if there's an in-progress navigation. We should never\n  // add prefetch requests to the network queue if an actual navigation is\n  // taking place, to ensure there's sufficient bandwidth for render-blocking\n  // data and resources.\n  return inProgressRequests < MAX_CONCURRENT_PREFETCH_REQUESTS\n}\n\n/**\n * Notifies the scheduler of an in-progress prefetch request. This is used to\n * control network bandwidth by limiting the number of concurrent requests.\n *\n * @param promise A promise that resolves when the request has finished.\n */\nexport function trackPrefetchRequestBandwidth(\n  promiseForServerData: Promise<unknown>\n) {\n  inProgressRequests++\n  promiseForServerData.then(\n    onPrefetchRequestCompletion,\n    onPrefetchRequestCompletion\n  )\n}\n\nconst noop = () => {}\n\nexport function spawnPrefetchSubtask(promise: Promise<any>) {\n  // When the scheduler spawns an async task, we don't await its result\n  // directly. Instead, the async task writes its result directly into the\n  // cache, then pings the scheduler to continue.\n  //\n  // This function only exists to prevent warnings about unhandled promises.\n  promise.then(noop, noop)\n}\n\nfunction onPrefetchRequestCompletion(): void {\n  inProgressRequests--\n\n  // Notify the scheduler that we have more bandwidth, and can continue\n  // processing tasks.\n  ensureWorkIsScheduled()\n}\n\n/**\n * Notify the scheduler that we've received new data for an in-progress\n * prefetch. The corresponding task will be added back to the queue (unless the\n * task has been canceled in the meantime).\n */\nexport function pingPrefetchTask(task: PrefetchTask) {\n  // \"Ping\" a prefetch that's already in progress to notify it of new data.\n  if (!task.isBlocked) {\n    // Prefetch is already queued.\n    return\n  }\n  // Unblock the task and requeue it.\n  task.isBlocked = false\n  heapPush(taskHeap, task)\n  ensureWorkIsScheduled()\n}\n\nfunction processQueueInMicrotask() {\n  didScheduleMicrotask = false\n\n  // We aim to minimize how often we read the current time. Since nearly all\n  // functions in the prefetch scheduler are synchronous, we can read the time\n  // once and pass it as an argument wherever it's needed.\n  const now = Date.now()\n\n  // Process the task queue until we run out of network bandwidth.\n  let task = heapPeek(taskHeap)\n  while (task !== null && hasNetworkBandwidth()) {\n    const route = requestRouteCacheEntryFromCache(now, task)\n    const exitStatus = pingRouteTree(now, task, route)\n    switch (exitStatus) {\n      case PrefetchTaskExitStatus.InProgress:\n        // The task yielded because there are too many requests in progress.\n        // Stop processing tasks until we have more bandwidth.\n        return\n      case PrefetchTaskExitStatus.Blocked:\n        // The task is blocked. It needs more data before it can proceed.\n        // Keep the task out of the queue until the server responds.\n        task.isBlocked = true\n\n        // Continue to the next task\n        heapPop(taskHeap)\n        task = heapPeek(taskHeap)\n        continue\n      case PrefetchTaskExitStatus.Done:\n        // The prefetch is complete. Continue to the next task.\n        heapPop(taskHeap)\n        task = heapPeek(taskHeap)\n        continue\n      default: {\n        const _exhaustiveCheck: never = exitStatus\n        return\n      }\n    }\n  }\n}\n\nfunction pingRouteTree(\n  now: number,\n  task: PrefetchTask,\n  route: RouteCacheEntry\n): PrefetchTaskExitStatus {\n  switch (route.status) {\n    case EntryStatus.Pending: {\n      // Still pending. We can't start prefetching the segments until the route\n      // tree has loaded.\n      const blockedTasks = route.blockedTasks\n      if (blockedTasks === null) {\n        route.blockedTasks = new Set([task])\n      } else {\n        blockedTasks.add(task)\n      }\n      return PrefetchTaskExitStatus.Blocked\n    }\n    case EntryStatus.Rejected: {\n      // Route tree failed to load. Treat as a 404.\n      return PrefetchTaskExitStatus.Done\n    }\n    case EntryStatus.Fulfilled: {\n      // Recursively fill in the segment tree.\n      if (!hasNetworkBandwidth()) {\n        // Stop prefetching segments until there's more bandwidth.\n        return PrefetchTaskExitStatus.InProgress\n      }\n      const tree = route.tree\n      requestSegmentEntryFromCache(now, task, route, tree.path, '')\n      return pingSegmentTree(now, task, route, tree)\n    }\n    default: {\n      const _exhaustiveCheck: never = route\n      return PrefetchTaskExitStatus.Done\n    }\n  }\n}\n\nfunction pingSegmentTree(\n  now: number,\n  task: PrefetchTask,\n  route: FulfilledRouteCacheEntry,\n  tree: TreePrefetch\n): PrefetchTaskExitStatus.InProgress | PrefetchTaskExitStatus.Done {\n  if (tree.slots !== null) {\n    // Recursively ping the children.\n    for (const parallelRouteKey in tree.slots) {\n      const childTree = tree.slots[parallelRouteKey]\n      if (!hasNetworkBandwidth()) {\n        // Stop prefetching segments until there's more bandwidth.\n        return PrefetchTaskExitStatus.InProgress\n      } else {\n        const childPath = childTree.path\n        const childToken = childTree.token\n        requestSegmentEntryFromCache(now, task, route, childPath, childToken)\n      }\n      const childExitStatus = pingSegmentTree(now, task, route, childTree)\n      if (childExitStatus === PrefetchTaskExitStatus.InProgress) {\n        // Child yielded without finishing.\n        return PrefetchTaskExitStatus.InProgress\n      }\n    }\n  }\n  // This segment and all its children have finished prefetching.\n  return PrefetchTaskExitStatus.Done\n}\n\n// -----------------------------------------------------------------------------\n// The remainider of the module is a MinHeap implementation. Try not to put any\n// logic below here unless it's related to the heap algorithm. We can extract\n// this to a separate module if/when we need multiple kinds of heaps.\n// -----------------------------------------------------------------------------\n\nfunction compareQueuePriority(a: PrefetchTask, b: PrefetchTask) {\n  // Since the queue is a MinHeap, this should return a positive number if b is\n  // higher priority than a, and a negative number if a is higher priority\n  // than b.\n  //\n  // sortId is an incrementing counter assigned to prefetches. We want to\n  // process the newest prefetches first.\n  return b.sortId - a.sortId\n}\n\nfunction heapPush(heap: Array<PrefetchTask>, node: PrefetchTask): void {\n  const index = heap.length\n  heap.push(node)\n  node._heapIndex = index\n  heapSiftUp(heap, node, index)\n}\n\nfunction heapPeek(heap: Array<PrefetchTask>): PrefetchTask | null {\n  return heap.length === 0 ? null : heap[0]\n}\n\nfunction heapPop(heap: Array<PrefetchTask>): PrefetchTask | null {\n  if (heap.length === 0) {\n    return null\n  }\n  const first = heap[0]\n  first._heapIndex = -1\n  const last = heap.pop() as PrefetchTask\n  if (last !== first) {\n    heap[0] = last\n    last._heapIndex = 0\n    heapSiftDown(heap, last, 0)\n  }\n  return first\n}\n\n// Not currently used, but will be once we add the ability to update a\n// task's priority.\n// function heapSift(heap: Array<PrefetchTask>, node: PrefetchTask) {\n//   const index = node._heapIndex\n//   if (index !== -1) {\n//     const parentIndex = (index - 1) >>> 1\n//     const parent = heap[parentIndex]\n//     if (compareQueuePriority(parent, node) > 0) {\n//       // The parent is larger. Sift up.\n//       heapSiftUp(heap, node, index)\n//     } else {\n//       // The parent is smaller (or equal). Sift down.\n//       heapSiftDown(heap, node, index)\n//     }\n//   }\n// }\n\nfunction heapSiftUp(\n  heap: Array<PrefetchTask>,\n  node: PrefetchTask,\n  i: number\n): void {\n  let index = i\n  while (index > 0) {\n    const parentIndex = (index - 1) >>> 1\n    const parent = heap[parentIndex]\n    if (compareQueuePriority(parent, node) > 0) {\n      // The parent is larger. Swap positions.\n      heap[parentIndex] = node\n      node._heapIndex = parentIndex\n      heap[index] = parent\n      parent._heapIndex = index\n\n      index = parentIndex\n    } else {\n      // The parent is smaller. Exit.\n      return\n    }\n  }\n}\n\nfunction heapSiftDown(\n  heap: Array<PrefetchTask>,\n  node: PrefetchTask,\n  i: number\n): void {\n  let index = i\n  const length = heap.length\n  const halfLength = length >>> 1\n  while (index < halfLength) {\n    const leftIndex = (index + 1) * 2 - 1\n    const left = heap[leftIndex]\n    const rightIndex = leftIndex + 1\n    const right = heap[rightIndex]\n\n    // If the left or right node is smaller, swap with the smaller of those.\n    if (compareQueuePriority(left, node) < 0) {\n      if (rightIndex < length && compareQueuePriority(right, left) < 0) {\n        heap[index] = right\n        right._heapIndex = index\n        heap[rightIndex] = node\n        node._heapIndex = rightIndex\n\n        index = rightIndex\n      } else {\n        heap[index] = left\n        left._heapIndex = index\n        heap[leftIndex] = node\n        node._heapIndex = leftIndex\n\n        index = leftIndex\n      }\n    } else if (rightIndex < length && compareQueuePriority(right, node) < 0) {\n      heap[index] = right\n      right._heapIndex = index\n      heap[rightIndex] = node\n      node._heapIndex = rightIndex\n\n      index = rightIndex\n    } else {\n      // Neither child is smaller. Exit.\n      return\n    }\n  }\n}\n"],"names":["pingPrefetchTask","schedulePrefetchTask","spawnPrefetchSubtask","trackPrefetchRequestBandwidth","scheduleMicrotask","queueMicrotask","fn","Promise","resolve","then","catch","error","setTimeout","taskHeap","MAX_CONCURRENT_PREFETCH_REQUESTS","inProgressRequests","sortIdCounter","didScheduleMicrotask","key","task","sortId","isBlocked","_heapIndex","heapPush","ensureWorkIsScheduled","hasNetworkBandwidth","processQueueInMicrotask","promiseForServerData","onPrefetchRequestCompletion","noop","promise","now","Date","heapPeek","route","requestRouteCacheEntryFromCache","exitStatus","pingRouteTree","heapPop","_exhaustiveCheck","status","EntryStatus","Pending","blockedTasks","Set","add","Rejected","Fulfilled","tree","requestSegmentEntryFromCache","path","pingSegmentTree","slots","parallelRouteKey","childTree","childPath","childToken","token","childExitStatus","compareQueuePriority","a","b","heap","node","index","length","push","heapSiftUp","first","last","pop","heapSiftDown","i","parentIndex","parent","halfLength","leftIndex","left","rightIndex","right"],"mappings":";;;;;;;;;;;;;;;;;IAiMgBA,gBAAgB,EAAA;eAAhBA;;IArFAC,oBAAoB,EAAA;eAApBA;;IA+DAC,oBAAoB,EAAA;eAApBA;;IAZAC,6BAA6B,EAAA;eAA7BA;;;uBAxJT;AAGP,MAAMC,oBACJ,OAAOC,mBAAmB,aACtBA,iBACA,CAACC,KACCC,QAAQC,OAAO,GACZC,IAAI,CAACH,IACLI,KAAK,CAAC,CAACC,QACNC,WAAW;YACT,MAAMD;QACR;AAsEZ,MAAME,WAAgC,EAAE;AAExC,6EAA6E;AAC7E,0EAA0E;AAC1E,MAAMC,mCAAmC;AACzC,IAAIC,qBAAqB;AAEzB,IAAIC,gBAAgB;AACpB,IAAIC,uBAAuB;AAWpB,SAAShB,qBAAqBiB,GAAkB;IACrD,4BAA4B;IAC5B,MAAMC,OAAqB;QACzBD;QACAE,QAAQJ;QACRK,WAAW;QACXC,YAAY,CAAC;IACf;IACAC,SAASV,UAAUM;IAEnB,+CAA+C;IAC/C,EAAE;IACF,yEAAyE;IACzE,yEAAyE;IACzE,2EAA2E;IAC3E,2EAA2E;IAC3E,qBAAqB;IACrBK;AACF;AAEA,SAASA;IACP,IAAIP,wBAAwB,CAACQ,uBAAuB;QAClD,wEAAwE;QACxE,oEAAoE;QACpE,iEAAiE;QACjE;IACF;IACAR,uBAAuB;IACvBb,kBAAkBsB;AACpB;AAEA;;;;;CAKC,GACD,SAASD;IACP,yEAAyE;IACzE,wEAAwE;IACxE,2EAA2E;IAC3E,sBAAsB;IACtB,OAAOV,qBAAqBD;AAC9B;AAQO,SAASX,8BACdwB,oBAAsC;IAEtCZ;IACAY,qBAAqBlB,IAAI,CACvBmB,6BACAA;AAEJ;AAEA,MAAMC,OAAO,KAAO;AAEb,SAAS3B,qBAAqB4B,OAAqB;IACxD,qEAAqE;IACrE,wEAAwE;IACxE,+CAA+C;IAC/C,EAAE;IACF,0EAA0E;IAC1EA,QAAQrB,IAAI,CAACoB,MAAMA;AACrB;AAEA,SAASD;IACPb;IAEA,qEAAqE;IACrE,oBAAoB;IACpBS;AACF;AAOO,SAASxB,iBAAiBmB,IAAkB;IACjD,yEAAyE;IACzE,IAAI,CAACA,KAAKE,SAAS,EAAE;QACnB,8BAA8B;QAC9B;IACF;IACA,mCAAmC;IACnCF,KAAKE,SAAS,GAAG;IACjBE,SAASV,UAAUM;IACnBK;AACF;AAEA,SAASE;IACPT,uBAAuB;IAEvB,0EAA0E;IAC1E,4EAA4E;IAC5E,wDAAwD;IACxD,MAAMc,MAAMC,KAAKD,GAAG;IAEpB,gEAAgE;IAChE,IAAIZ,OAAOc,SAASpB;IACpB,MAAOM,SAAS,QAAQM,sBAAuB;QAC7C,MAAMS,QAAQC,CAAAA,GAAAA,OAAAA,+BAA+B,EAACJ,KAAKZ;QACnD,MAAMiB,aAAaC,cAAcN,KAAKZ,MAAMe;QAC5C,OAAQE;YACN,KAAA;gBACE,oEAAoE;gBACpE,sDAAsD;gBACtD;YACF,KAAA;gBACE,iEAAiE;gBACjE,4DAA4D;gBAC5DjB,KAAKE,SAAS,GAAG;gBAEjB,4BAA4B;gBAC5BiB,QAAQzB;gBACRM,OAAOc,SAASpB;gBAChB;YACF,KAAA;gBACE,uDAAuD;gBACvDyB,QAAQzB;gBACRM,OAAOc,SAASpB;gBAChB;YACF;gBAAS;oBACP,MAAM0B,mBAA0BH;oBAChC;gBACF;QACF;IACF;AACF;AAEA,SAASC,cACPN,GAAW,EACXZ,IAAkB,EAClBe,KAAsB;IAEtB,OAAQA,MAAMM,MAAM;QAClB,KAAKC,OAAAA,WAAW,CAACC,OAAO;YAAE;gBACxB,yEAAyE;gBACzE,mBAAmB;gBACnB,MAAMC,eAAeT,MAAMS,YAAY;gBACvC,IAAIA,iBAAiB,MAAM;oBACzBT,MAAMS,YAAY,GAAG,IAAIC,IAAI;wBAACzB;qBAAK;gBACrC,OAAO;oBACLwB,aAAaE,GAAG,CAAC1B;gBACnB;gBACA,OAAA;YACF;QACA,KAAKsB,OAAAA,WAAW,CAACK,QAAQ;YAAE;gBACzB,6CAA6C;gBAC7C,OAAA;YACF;QACA,KAAKL,OAAAA,WAAW,CAACM,SAAS;YAAE;gBAC1B,wCAAwC;gBACxC,IAAI,CAACtB,uBAAuB;oBAC1B,0DAA0D;oBAC1D,OAAA;gBACF;gBACA,MAAMuB,OAAOd,MAAMc,IAAI;gBACvBC,CAAAA,GAAAA,OAAAA,4BAA4B,EAAClB,KAAKZ,MAAMe,OAAOc,KAAKE,IAAI,EAAE;gBAC1D,OAAOC,gBAAgBpB,KAAKZ,MAAMe,OAAOc;YAC3C;QACA;YAAS;gBACP,MAAMT,mBAA0BL;gBAChC,OAAA;YACF;IACF;AACF;AAEA,SAASiB,gBACPpB,GAAW,EACXZ,IAAkB,EAClBe,KAA+B,EAC/Bc,IAAkB;IAElB,IAAIA,KAAKI,KAAK,KAAK,MAAM;QACvB,iCAAiC;QACjC,IAAK,MAAMC,oBAAoBL,KAAKI,KAAK,CAAE;YACzC,MAAME,YAAYN,KAAKI,KAAK,CAACC,iBAAiB;YAC9C,IAAI,CAAC5B,uBAAuB;gBAC1B,0DAA0D;gBAC1D,OAAA;YACF,OAAO;gBACL,MAAM8B,YAAYD,UAAUJ,IAAI;gBAChC,MAAMM,aAAaF,UAAUG,KAAK;gBAClCR,CAAAA,GAAAA,OAAAA,4BAA4B,EAAClB,KAAKZ,MAAMe,OAAOqB,WAAWC;YAC5D;YACA,MAAME,kBAAkBP,gBAAgBpB,KAAKZ,MAAMe,OAAOoB;YAC1D,IAAII,oBAAAA,GAAuD;gBACzD,mCAAmC;gBACnC,OAAA;YACF;QACF;IACF;IACA,+DAA+D;IAC/D,OAAA;AACF;AAEA,gFAAgF;AAChF,+EAA+E;AAC/E,6EAA6E;AAC7E,qEAAqE;AACrE,gFAAgF;AAEhF,SAASC,qBAAqBC,CAAe,EAAEC,CAAe;IAC5D,6EAA6E;IAC7E,wEAAwE;IACxE,UAAU;IACV,EAAE;IACF,uEAAuE;IACvE,uCAAuC;IACvC,OAAOA,EAAEzC,MAAM,GAAGwC,EAAExC,MAAM;AAC5B;AAEA,SAASG,SAASuC,IAAyB,EAAEC,IAAkB;IAC7D,MAAMC,QAAQF,KAAKG,MAAM;IACzBH,KAAKI,IAAI,CAACH;IACVA,KAAKzC,UAAU,GAAG0C;IAClBG,WAAWL,MAAMC,MAAMC;AACzB;AAEA,SAAS/B,SAAS6B,IAAyB;IACzC,OAAOA,KAAKG,MAAM,KAAK,IAAI,OAAOH,IAAI,CAAC,EAAE;AAC3C;AAEA,SAASxB,QAAQwB,IAAyB;IACxC,IAAIA,KAAKG,MAAM,KAAK,GAAG;QACrB,OAAO;IACT;IACA,MAAMG,QAAQN,IAAI,CAAC,EAAE;IACrBM,MAAM9C,UAAU,GAAG,CAAC;IACpB,MAAM+C,OAAOP,KAAKQ,GAAG;IACrB,IAAID,SAASD,OAAO;QAClBN,IAAI,CAAC,EAAE,GAAGO;QACVA,KAAK/C,UAAU,GAAG;QAClBiD,aAAaT,MAAMO,MAAM;IAC3B;IACA,OAAOD;AACT;AAEA,sEAAsE;AACtE,mBAAmB;AACnB,qEAAqE;AACrE,kCAAkC;AAClC,wBAAwB;AACxB,4CAA4C;AAC5C,uCAAuC;AACvC,oDAAoD;AACpD,0CAA0C;AAC1C,sCAAsC;AACtC,eAAe;AACf,wDAAwD;AACxD,wCAAwC;AACxC,QAAQ;AACR,MAAM;AACN,IAAI;AAEJ,SAASD,WACPL,IAAyB,EACzBC,IAAkB,EAClBS,CAAS;IAET,IAAIR,QAAQQ;IACZ,MAAOR,QAAQ,EAAG;QAChB,MAAMS,cAAeT,QAAQ,MAAO;QACpC,MAAMU,SAASZ,IAAI,CAACW,YAAY;QAChC,IAAId,qBAAqBe,QAAQX,QAAQ,GAAG;YAC1C,wCAAwC;YACxCD,IAAI,CAACW,YAAY,GAAGV;YACpBA,KAAKzC,UAAU,GAAGmD;YAClBX,IAAI,CAACE,MAAM,GAAGU;YACdA,OAAOpD,UAAU,GAAG0C;YAEpBA,QAAQS;QACV,OAAO;YACL,+BAA+B;YAC/B;QACF;IACF;AACF;AAEA,SAASF,aACPT,IAAyB,EACzBC,IAAkB,EAClBS,CAAS;IAET,IAAIR,QAAQQ;IACZ,MAAMP,SAASH,KAAKG,MAAM;IAC1B,MAAMU,aAAaV,WAAW;IAC9B,MAAOD,QAAQW,WAAY;QACzB,MAAMC,YAAaZ,CAAAA,QAAQ,CAAA,IAAK,IAAI;QACpC,MAAMa,OAAOf,IAAI,CAACc,UAAU;QAC5B,MAAME,aAAaF,YAAY;QAC/B,MAAMG,QAAQjB,IAAI,CAACgB,WAAW;QAE9B,wEAAwE;QACxE,IAAInB,qBAAqBkB,MAAMd,QAAQ,GAAG;YACxC,IAAIe,aAAab,UAAUN,qBAAqBoB,OAAOF,QAAQ,GAAG;gBAChEf,IAAI,CAACE,MAAM,GAAGe;gBACdA,MAAMzD,UAAU,GAAG0C;gBACnBF,IAAI,CAACgB,WAAW,GAAGf;gBACnBA,KAAKzC,UAAU,GAAGwD;gBAElBd,QAAQc;YACV,OAAO;gBACLhB,IAAI,CAACE,MAAM,GAAGa;gBACdA,KAAKvD,UAAU,GAAG0C;gBAClBF,IAAI,CAACc,UAAU,GAAGb;gBAClBA,KAAKzC,UAAU,GAAGsD;gBAElBZ,QAAQY;YACV;QACF,OAAO,IAAIE,aAAab,UAAUN,qBAAqBoB,OAAOhB,QAAQ,GAAG;YACvED,IAAI,CAACE,MAAM,GAAGe;YACdA,MAAMzD,UAAU,GAAG0C;YACnBF,IAAI,CAACgB,WAAW,GAAGf;YACnBA,KAAKzC,UAAU,GAAGwD;YAElBd,QAAQc;QACV,OAAO;YACL,kCAAkC;YAClC;QACF;IACF;AACF","ignoreList":[0]}},
    {"offset": {"line": 1493, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1498, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/app-build-id.ts"],"sourcesContent":["// This gets assigned as a side-effect during app initialization. Because it\n// represents the build used to create the JS bundle, it should never change\n// after being set, so we store it in a global variable.\n//\n// When performing RSC requests, if the incoming data has a different build ID,\n// we perform an MPA navigation/refresh to load the updated build and ensure\n// that the client and server in sync.\n\n// Starts as an empty string. In practice, because setAppBuildId is called\n// during initialization before hydration starts, this will always get\n// reassigned to the actual build ID before it's ever needed by a navigation.\n// If for some reasons it didn't, due to a bug or race condition, then on\n// navigation the build comparision would fail and trigger an MPA navigation.\nlet globalBuildId: string = ''\n\nexport function setAppBuildId(buildId: string) {\n  globalBuildId = buildId\n}\n\nexport function getAppBuildId(): string {\n  return globalBuildId\n}\n"],"names":["getAppBuildId","setAppBuildId","globalBuildId","buildId"],"mappings":"AAAA,4EAA4E;AAC5E,4EAA4E;AAC5E,wDAAwD;AACxD,EAAE;AACF,+EAA+E;AAC/E,4EAA4E;AAC5E,sCAAsC;AAEtC,0EAA0E;AAC1E,sEAAsE;AACtE,6EAA6E;AAC7E,yEAAyE;AACzE,6EAA6E;;;;;;;;;;;;;;;;IAO7DA,aAAa,EAAA;eAAbA;;IAJAC,aAAa,EAAA;eAAbA;;;AAFhB,IAAIC,gBAAwB;AAErB,SAASD,cAAcE,OAAe;IAC3CD,gBAAgBC;AAClB;AAEO,SAASH;IACd,OAAOE;AACT","ignoreList":[0]}},
    {"offset": {"line": 1546, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1551, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/tuple-map.ts"],"sourcesContent":["// Utility type. Prefix<[A, B, C, D]> matches [A], [A, B], [A, B, C] etc.\nexport type Prefix<T extends any[]> = T extends [infer First, ...infer Rest]\n  ? [] | [First] | [First, ...Prefix<Rest>]\n  : []\n\nexport type TupleMap<Keypath extends Array<any>, V> = {\n  set(keys: Prefix<Keypath>, value: V): void\n  get(keys: Prefix<Keypath>): V | null\n  delete(keys: Prefix<Keypath>): void\n}\n\n/**\n * Creates a map whose keys are tuples. Tuples are compared per-element. This\n * is useful when a key has multiple parts, but you don't want to concatenate\n * them into a single string value.\n *\n * In the Segment Cache, we use this to store cache entries by both their href\n * and their Next-URL.\n *\n * Example:\n *   map.set(['https://localhost', 'foo/bar/baz'], 'yay');\n *   map.get(['https://localhost', 'foo/bar/baz']); // returns 'yay'\n */\nexport function createTupleMap<Keypath extends Array<any>, V>(): TupleMap<\n  Keypath,\n  V\n> {\n  type MapEntryShared = {\n    parent: MapEntry | null\n    key: any\n    map: Map<any, MapEntry> | null\n  }\n\n  type EmptyMapEntry = MapEntryShared & {\n    value: null\n    hasValue: false\n  }\n\n  type FullMapEntry = MapEntryShared & {\n    value: V\n    hasValue: true\n  }\n\n  type MapEntry = EmptyMapEntry | FullMapEntry\n\n  let rootEntry: MapEntry = {\n    parent: null,\n    key: null,\n    hasValue: false,\n    value: null,\n    map: null,\n  }\n\n  // To optimize successive lookups, we cache the last accessed keypath.\n  // Although it's not encoded in the type, these are both null or\n  // both non-null. It uses object equality, so to take advantage of this\n  // optimization, you must pass the same array instance to each successive\n  // method call, and you must also not mutate the array between calls.\n  let lastAccessedEntry: MapEntry | null = null\n  let lastAccessedKeys: Prefix<Keypath> | null = null\n\n  function getOrCreateEntry(keys: Prefix<Keypath>): MapEntry {\n    if (lastAccessedKeys === keys) {\n      return lastAccessedEntry!\n    }\n\n    // Go through each level of keys until we find the entry that matches,\n    // or create a new one if it doesn't already exist.\n    let entry = rootEntry\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i]\n      let map = entry.map\n      if (map !== null) {\n        const existingEntry = map.get(key)\n        if (existingEntry !== undefined) {\n          // Found a match. Keep going.\n          entry = existingEntry\n          continue\n        }\n      } else {\n        map = new Map()\n        entry.map = map\n      }\n      // No entry exists yet at this level. Create a new one.\n      const newEntry: MapEntry = {\n        parent: entry,\n        key,\n        value: null,\n        hasValue: false,\n        map: null,\n      }\n      map.set(key, newEntry)\n      entry = newEntry\n    }\n\n    lastAccessedKeys = keys\n    lastAccessedEntry = entry\n\n    return entry\n  }\n\n  function getEntryIfExists(keys: Prefix<Keypath>): MapEntry | null {\n    if (lastAccessedKeys === keys) {\n      return lastAccessedEntry\n    }\n\n    // Go through each level of keys until we find the entry that matches, or\n    // return null if no match exists.\n    let entry = rootEntry\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i]\n      let map = entry.map\n      if (map !== null) {\n        const existingEntry = map.get(key)\n        if (existingEntry !== undefined) {\n          // Found a match. Keep going.\n          entry = existingEntry\n          continue\n        }\n      }\n      // No entry exists at this level.\n      return null\n    }\n\n    lastAccessedKeys = keys\n    lastAccessedEntry = entry\n\n    return entry\n  }\n\n  function set(keys: Prefix<Keypath>, value: V): void {\n    const entry = getOrCreateEntry(keys)\n    entry.hasValue = true\n    entry.value = value\n  }\n\n  function get(keys: Prefix<Keypath>): V | null {\n    const entry = getEntryIfExists(keys)\n    if (entry === null || !entry.hasValue) {\n      return null\n    }\n    return entry.value\n  }\n\n  function deleteEntry(keys: Prefix<Keypath>): void {\n    const entry = getEntryIfExists(keys)\n    if (entry === null || !entry.hasValue) {\n      return\n    }\n\n    // Found a match. Delete it from the cache.\n    const deletedEntry: EmptyMapEntry = entry as any\n    deletedEntry.hasValue = false\n    deletedEntry.value = null\n\n    // Check if we can garbage collect the entry.\n    if (deletedEntry.map === null) {\n      // Since this entry has no value, and also no child entries, we can\n      // garbage collect it. Remove it from its parent, and keep garbage\n      // collecting the parents until we reach a non-empty entry.\n\n      // Unlike a `set` operation, these are no longer valid because the entry\n      // itself is being modified, not just the value it contains.\n      lastAccessedEntry = null\n      lastAccessedKeys = null\n\n      let parent = deletedEntry.parent\n      let key = deletedEntry.key\n      while (parent !== null) {\n        const parentMap = parent.map\n        if (parentMap !== null) {\n          parentMap.delete(key)\n          if (parentMap.size === 0) {\n            // We just removed the last entry in the parent map.\n            parent.map = null\n            if (parent.value === null) {\n              // The parent node has no child entries, nor does it have a value\n              // on itself. It can be garbage collected. Keep going.\n              key = parent.key\n              parent = parent.parent\n              continue\n            }\n          }\n        }\n        // The parent is not empty. Stop garbage collecting.\n        break\n      }\n    }\n  }\n\n  return {\n    set,\n    get,\n    delete: deleteEntry,\n  }\n}\n"],"names":["createTupleMap","rootEntry","parent","key","hasValue","value","map","lastAccessedEntry","lastAccessedKeys","getOrCreateEntry","keys","entry","i","length","existingEntry","get","undefined","Map","newEntry","set","getEntryIfExists","deleteEntry","deletedEntry","parentMap","delete","size"],"mappings":"AAAA,yEAAyE;;;;;+BAuBzDA,kBAAAA;;;eAAAA;;;AAAT,SAASA;IAsBd,IAAIC,YAAsB;QACxBC,QAAQ;QACRC,KAAK;QACLC,UAAU;QACVC,OAAO;QACPC,KAAK;IACP;IAEA,sEAAsE;IACtE,gEAAgE;IAChE,uEAAuE;IACvE,yEAAyE;IACzE,qEAAqE;IACrE,IAAIC,oBAAqC;IACzC,IAAIC,mBAA2C;IAE/C,SAASC,iBAAiBC,IAAqB;QAC7C,IAAIF,qBAAqBE,MAAM;YAC7B,OAAOH;QACT;QAEA,sEAAsE;QACtE,mDAAmD;QACnD,IAAII,QAAQV;QACZ,IAAK,IAAIW,IAAI,GAAGA,IAAIF,KAAKG,MAAM,EAAED,IAAK;YACpC,MAAMT,MAAMO,IAAI,CAACE,EAAE;YACnB,IAAIN,MAAMK,MAAML,GAAG;YACnB,IAAIA,QAAQ,MAAM;gBAChB,MAAMQ,gBAAgBR,IAAIS,GAAG,CAACZ;gBAC9B,IAAIW,kBAAkBE,WAAW;oBAC/B,6BAA6B;oBAC7BL,QAAQG;oBACR;gBACF;YACF,OAAO;gBACLR,MAAM,IAAIW;gBACVN,MAAML,GAAG,GAAGA;YACd;YACA,uDAAuD;YACvD,MAAMY,WAAqB;gBACzBhB,QAAQS;gBACRR;gBACAE,OAAO;gBACPD,UAAU;gBACVE,KAAK;YACP;YACAA,IAAIa,GAAG,CAAChB,KAAKe;YACbP,QAAQO;QACV;QAEAV,mBAAmBE;QACnBH,oBAAoBI;QAEpB,OAAOA;IACT;IAEA,SAASS,iBAAiBV,IAAqB;QAC7C,IAAIF,qBAAqBE,MAAM;YAC7B,OAAOH;QACT;QAEA,yEAAyE;QACzE,kCAAkC;QAClC,IAAII,QAAQV;QACZ,IAAK,IAAIW,IAAI,GAAGA,IAAIF,KAAKG,MAAM,EAAED,IAAK;YACpC,MAAMT,MAAMO,IAAI,CAACE,EAAE;YACnB,IAAIN,MAAMK,MAAML,GAAG;YACnB,IAAIA,QAAQ,MAAM;gBAChB,MAAMQ,gBAAgBR,IAAIS,GAAG,CAACZ;gBAC9B,IAAIW,kBAAkBE,WAAW;oBAC/B,6BAA6B;oBAC7BL,QAAQG;oBACR;gBACF;YACF;YACA,iCAAiC;YACjC,OAAO;QACT;QAEAN,mBAAmBE;QACnBH,oBAAoBI;QAEpB,OAAOA;IACT;IAEA,SAASQ,IAAIT,IAAqB,EAAEL,KAAQ;QAC1C,MAAMM,QAAQF,iBAAiBC;QAC/BC,MAAMP,QAAQ,GAAG;QACjBO,MAAMN,KAAK,GAAGA;IAChB;IAEA,SAASU,IAAIL,IAAqB;QAChC,MAAMC,QAAQS,iBAAiBV;QAC/B,IAAIC,UAAU,QAAQ,CAACA,MAAMP,QAAQ,EAAE;YACrC,OAAO;QACT;QACA,OAAOO,MAAMN,KAAK;IACpB;IAEA,SAASgB,YAAYX,IAAqB;QACxC,MAAMC,QAAQS,iBAAiBV;QAC/B,IAAIC,UAAU,QAAQ,CAACA,MAAMP,QAAQ,EAAE;YACrC;QACF;QAEA,2CAA2C;QAC3C,MAAMkB,eAA8BX;QACpCW,aAAalB,QAAQ,GAAG;QACxBkB,aAAajB,KAAK,GAAG;QAErB,6CAA6C;QAC7C,IAAIiB,aAAahB,GAAG,KAAK,MAAM;YAC7B,mEAAmE;YACnE,kEAAkE;YAClE,2DAA2D;YAE3D,wEAAwE;YACxE,4DAA4D;YAC5DC,oBAAoB;YACpBC,mBAAmB;YAEnB,IAAIN,SAASoB,aAAapB,MAAM;YAChC,IAAIC,MAAMmB,aAAanB,GAAG;YAC1B,MAAOD,WAAW,KAAM;gBACtB,MAAMqB,YAAYrB,OAAOI,GAAG;gBAC5B,IAAIiB,cAAc,MAAM;oBACtBA,UAAUC,MAAM,CAACrB;oBACjB,IAAIoB,UAAUE,IAAI,KAAK,GAAG;wBACxB,oDAAoD;wBACpDvB,OAAOI,GAAG,GAAG;wBACb,IAAIJ,OAAOG,KAAK,KAAK,MAAM;4BACzB,iEAAiE;4BACjE,sDAAsD;4BACtDF,MAAMD,OAAOC,GAAG;4BAChBD,SAASA,OAAOA,MAAM;4BACtB;wBACF;oBACF;gBACF;gBAEA;YACF;QACF;IACF;IAEA,OAAO;QACLiB;QACAJ;QACAS,QAAQH;IACV;AACF","ignoreList":[0]}},
    {"offset": {"line": 1703, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1708, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/lru.ts"],"sourcesContent":["export type LRU<T extends LRUNode> = {\n  put(node: T): void\n  delete(node: T): void\n  updateSize(node: T, size: number): void\n}\n\n// Doubly-linked list\ntype LRUNode<T = any> = {\n  // Although it's not encoded in the type, these are both null if the node is\n  // not in the LRU; both non-null if it is.\n  prev: T | null\n  next: T | null\n  size: number\n}\n\n// Rather than create an internal LRU node, the passed-in type must conform\n// the LRUNode interface. This is just a memory optimization to avoid creating\n// another object; we only use this for Segment Cache entries so it doesn't need\n// to be general purpose.\nexport function createLRU<T extends LRUNode>(\n  // From the LRU's perspective, the size unit is arbitrary, but for our\n  // purposes this is the byte size.\n  maxLruSize: number,\n  onEviction: (node: T) => void\n): LRU<T> {\n  let head: T | null = null\n  let didScheduleCleanup: boolean = false\n  let lruSize: number = 0\n\n  function put(node: T) {\n    if (head === node) {\n      // Already at the head\n      return\n    }\n    const prev = node.prev\n    const next = node.next\n    if (next === null || prev === null) {\n      // This is an insertion\n      lruSize += node.size\n      // Whenever we add an entry, we need to check if we've exceeded the\n      // max size. We don't evict entries immediately; they're evicted later in\n      // an asynchronous task.\n      ensureCleanupIsScheduled()\n    } else {\n      // This is a move. Remove from its current position.\n      prev.next = next\n      next.prev = prev\n    }\n\n    // Move to the front of the list\n    if (head === null) {\n      // This is the first entry\n      node.prev = node\n      node.next = node\n    } else {\n      // Add to the front of the list\n      const tail = head.prev\n      node.prev = tail\n      tail.next = node\n      node.next = head\n      head.prev = node\n    }\n    head = node\n  }\n\n  function updateSize(node: T, newNodeSize: number) {\n    // This is a separate function so that we can resize the entry after it's\n    // already been inserted.\n    if (node.next === null) {\n      // No longer part of LRU.\n      return\n    }\n    const prevNodeSize = node.size\n    node.size = newNodeSize\n    lruSize = lruSize - prevNodeSize + newNodeSize\n    ensureCleanupIsScheduled()\n  }\n\n  function deleteNode(deleted: T) {\n    const next = deleted.next\n    const prev = deleted.prev\n    if (next !== null && prev !== null) {\n      lruSize -= deleted.size\n\n      deleted.next = null\n      deleted.prev = null\n\n      // Remove from the list\n      if (head === deleted) {\n        // Update the head\n        if (next === head) {\n          // This was the last entry\n          head = null\n        } else {\n          head = next\n        }\n      } else {\n        prev.next = next\n        next.prev = prev\n      }\n    } else {\n      // Already deleted\n    }\n  }\n\n  function ensureCleanupIsScheduled() {\n    if (didScheduleCleanup || lruSize <= maxLruSize) {\n      return\n    }\n    didScheduleCleanup = true\n    requestCleanupCallback(cleanup)\n  }\n\n  function cleanup() {\n    didScheduleCleanup = false\n\n    // Evict entries until we're at 90% capacity. We can assume this won't\n    // infinite loop because even if `maxLruSize` were 0, eventually\n    // `deleteNode` sets `head` to `null` when we run out entries.\n    const ninetyPercentMax = maxLruSize * 0.9\n    while (lruSize > ninetyPercentMax && head !== null) {\n      const tail = head.prev\n      deleteNode(tail)\n      onEviction(tail)\n    }\n  }\n\n  return {\n    put,\n    delete: deleteNode,\n    updateSize,\n  }\n}\n\nconst requestCleanupCallback =\n  typeof requestIdleCallback === 'function'\n    ? requestIdleCallback\n    : (cb: () => void) => setTimeout(cb, 0)\n"],"names":["createLRU","maxLruSize","onEviction","head","didScheduleCleanup","lruSize","put","node","prev","next","size","ensureCleanupIsScheduled","tail","updateSize","newNodeSize","prevNodeSize","deleteNode","deleted","requestCleanupCallback","cleanup","ninetyPercentMax","delete","requestIdleCallback","cb","setTimeout"],"mappings":";;;;+BAmBgBA,aAAAA;;;eAAAA;;;AAAT,SAASA,UACd,AACA,kCAAkC,oCADoC;AAEtEC,UAAkB,EAClBC,UAA6B;IAE7B,IAAIC,OAAiB;IACrB,IAAIC,qBAA8B;IAClC,IAAIC,UAAkB;IAEtB,SAASC,IAAIC,IAAO;QAClB,IAAIJ,SAASI,MAAM;YACjB,sBAAsB;YACtB;QACF;QACA,MAAMC,OAAOD,KAAKC,IAAI;QACtB,MAAMC,OAAOF,KAAKE,IAAI;QACtB,IAAIA,SAAS,QAAQD,SAAS,MAAM;YAClC,uBAAuB;YACvBH,WAAWE,KAAKG,IAAI;YACpB,mEAAmE;YACnE,yEAAyE;YACzE,wBAAwB;YACxBC;QACF,OAAO;YACL,oDAAoD;YACpDH,KAAKC,IAAI,GAAGA;YACZA,KAAKD,IAAI,GAAGA;QACd;QAEA,gCAAgC;QAChC,IAAIL,SAAS,MAAM;YACjB,0BAA0B;YAC1BI,KAAKC,IAAI,GAAGD;YACZA,KAAKE,IAAI,GAAGF;QACd,OAAO;YACL,+BAA+B;YAC/B,MAAMK,OAAOT,KAAKK,IAAI;YACtBD,KAAKC,IAAI,GAAGI;YACZA,KAAKH,IAAI,GAAGF;YACZA,KAAKE,IAAI,GAAGN;YACZA,KAAKK,IAAI,GAAGD;QACd;QACAJ,OAAOI;IACT;IAEA,SAASM,WAAWN,IAAO,EAAEO,WAAmB;QAC9C,yEAAyE;QACzE,yBAAyB;QACzB,IAAIP,KAAKE,IAAI,KAAK,MAAM;YACtB,yBAAyB;YACzB;QACF;QACA,MAAMM,eAAeR,KAAKG,IAAI;QAC9BH,KAAKG,IAAI,GAAGI;QACZT,UAAUA,UAAUU,eAAeD;QACnCH;IACF;IAEA,SAASK,WAAWC,OAAU;QAC5B,MAAMR,OAAOQ,QAAQR,IAAI;QACzB,MAAMD,OAAOS,QAAQT,IAAI;QACzB,IAAIC,SAAS,QAAQD,SAAS,MAAM;YAClCH,WAAWY,QAAQP,IAAI;YAEvBO,QAAQR,IAAI,GAAG;YACfQ,QAAQT,IAAI,GAAG;YAEf,uBAAuB;YACvB,IAAIL,SAASc,SAAS;gBACpB,kBAAkB;gBAClB,IAAIR,SAASN,MAAM;oBACjB,0BAA0B;oBAC1BA,OAAO;gBACT,OAAO;oBACLA,OAAOM;gBACT;YACF,OAAO;gBACLD,KAAKC,IAAI,GAAGA;gBACZA,KAAKD,IAAI,GAAGA;YACd;QACF,OAAO;QACL,kBAAkB;QACpB;IACF;IAEA,SAASG;QACP,IAAIP,sBAAsBC,WAAWJ,YAAY;YAC/C;QACF;QACAG,qBAAqB;QACrBc,uBAAuBC;IACzB;IAEA,SAASA;QACPf,qBAAqB;QAErB,sEAAsE;QACtE,gEAAgE;QAChE,8DAA8D;QAC9D,MAAMgB,mBAAmBnB,aAAa;QACtC,MAAOI,UAAUe,oBAAoBjB,SAAS,KAAM;YAClD,MAAMS,OAAOT,KAAKK,IAAI;YACtBQ,WAAWJ;YACXV,WAAWU;QACb;IACF;IAEA,OAAO;QACLN;QACAe,QAAQL;QACRH;IACF;AACF;AAEA,MAAMK,yBACJ,OAAOI,wBAAwB,aAC3BA,sBACA,CAACC,KAAmBC,WAAWD,IAAI","ignoreList":[0]}},
    {"offset": {"line": 1826, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1831, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/cache.ts"],"sourcesContent":["import type {\n  TreePrefetch,\n  RootTreePrefetch,\n  SegmentPrefetch,\n} from '../../../server/app-render/collect-segment-data'\nimport type { LoadingModuleData } from '../../../shared/lib/app-router-context.shared-runtime'\nimport {\n  NEXT_ROUTER_PREFETCH_HEADER,\n  NEXT_ROUTER_SEGMENT_PREFETCH_HEADER,\n  NEXT_URL,\n  RSC_CONTENT_TYPE_HEADER,\n  RSC_HEADER,\n} from '../app-router-headers'\nimport {\n  createFetch,\n  createFromNextReadableStream,\n  urlToUrlWithoutFlightMarker,\n  type RequestHeaders,\n} from '../router-reducer/fetch-server-response'\nimport {\n  trackPrefetchRequestBandwidth,\n  pingPrefetchTask,\n  type PrefetchTask,\n  spawnPrefetchSubtask,\n} from './scheduler'\nimport { getAppBuildId } from '../../app-build-id'\nimport { createHrefFromUrl } from '../router-reducer/create-href-from-url'\nimport type {\n  NormalizedHref,\n  NormalizedNextUrl,\n  RouteCacheKey,\n} from './cache-key'\nimport { createTupleMap, type TupleMap, type Prefix } from './tuple-map'\nimport { createLRU, type LRU } from './lru'\n\n// A note on async/await when working in the prefetch cache:\n//\n// Most async operations in the prefetch cache should *not* use async/await,\n// Instead, spawn a subtask that writes the results to a cache entry, and attach\n// a \"ping\" listener to notify the prefetch queue to try again.\n//\n// The reason is we need to be able to access the segment cache and traverse its\n// data structures synchronously. For example, if there's a synchronous update\n// we can take an immediate snapshot of the cache to produce something we can\n// render. Limiting the use of async/await also makes it easier to avoid race\n// conditions, which is especially important because is cache is mutable.\n//\n// Another reason is that while we're performing async work, it's possible for\n// existing entries to become stale, or for Link prefetches to be removed from\n// the queue. For optimal scheduling, we need to be able to \"cancel\" subtasks\n// that are no longer needed. So, when a segment is received from the server, we\n// restart from the root of the tree that's being prefetched, to confirm all the\n// parent segments are still cached. If the segment is no longer reachable from\n// the root, then it's effectively canceled. This is similar to the design of\n// Rust Futures, or React Suspense.\n\ntype RouteCacheEntryShared = {\n  staleAt: number\n  // This is false only if we're certain the route cannot be intercepted. It's\n  // true in all other cases, including on initialization when we haven't yet\n  // received a response from the server.\n  couldBeIntercepted: boolean\n\n  // LRU-related fields\n  keypath: null | Prefix<RouteCacheKeypath>\n  next: null | RouteCacheEntry\n  prev: null | RouteCacheEntry\n  size: number\n}\n\nexport const enum EntryStatus {\n  Pending,\n  Rejected,\n  Fulfilled,\n}\n\ntype PendingRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Pending\n  blockedTasks: Set<PrefetchTask> | null\n  canonicalUrl: null\n  tree: null\n  head: null\n  isHeadPartial: true\n}\n\ntype RejectedRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Rejected\n  blockedTasks: Set<PrefetchTask> | null\n  canonicalUrl: null\n  tree: null\n  head: null\n  isHeadPartial: true\n}\n\nexport type FulfilledRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Fulfilled\n  blockedTasks: null\n  canonicalUrl: string\n  tree: TreePrefetch\n  head: React.ReactNode | null\n  isHeadPartial: boolean\n}\n\nexport type RouteCacheEntry =\n  | PendingRouteCacheEntry\n  | FulfilledRouteCacheEntry\n  | RejectedRouteCacheEntry\n\ntype SegmentCacheEntryShared = {\n  staleAt: number\n\n  // LRU-related fields\n  key: null | string\n  next: null | RouteCacheEntry\n  prev: null | RouteCacheEntry\n  size: number\n}\n\ntype PendingSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Pending\n  rsc: null\n  loading: null\n  isPartial: true\n  promise: null | PromiseWithResolvers<FulfilledSegmentCacheEntry | null>\n}\n\ntype RejectedSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Rejected\n  rsc: null\n  loading: null\n  isPartial: true\n  promise: null\n}\n\ntype FulfilledSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Fulfilled\n  rsc: React.ReactNode | null\n  loading: LoadingModuleData | Promise<LoadingModuleData>\n  isPartial: boolean\n  promise: null\n}\n\nexport type SegmentCacheEntry =\n  | PendingSegmentCacheEntry\n  | RejectedSegmentCacheEntry\n  | FulfilledSegmentCacheEntry\n\n// Route cache entries vary on multiple keys: the href and the Next-Url. Each of\n// these parts needs to be included in the internal cache key. Rather than\n// concatenate the keys into a single key, we use a multi-level map, where the\n// first level is keyed by href, the second level is keyed by Next-Url, and so\n// on (if were to add more levels).\ntype RouteCacheKeypath = [NormalizedHref, NormalizedNextUrl]\nconst routeCacheMap: TupleMap<RouteCacheKeypath, RouteCacheEntry> =\n  createTupleMap()\n\n// We use an LRU for memory management. We must update this whenever we add or\n// remove a new cache entry, or when an entry changes size.\n// TODO: I chose the max size somewhat arbitrarily. Consider setting this based\n// on navigator.deviceMemory, or some other heuristic. We should make this\n// customizable via the Next.js config, too.\nconst maxRouteLruSize = 10 * 1024 * 1024 // 10 MB\nconst routeCacheLru = createLRU<RouteCacheEntry>(\n  maxRouteLruSize,\n  onRouteLRUEviction\n)\n\n// TODO: We may eventually store segment entries in a tuple map, too, to\n// account for search params.\nconst segmentCacheMap = new Map<string, SegmentCacheEntry>()\n// NOTE: Segments and Route entries are managed by separate LRUs. We could\n// combine them into a single LRU, but because they are separate types, we'd\n// need to wrap each one in an extra LRU node (to maintain monomorphism, at the\n// cost of additional memory).\nconst maxSegmentLruSize = 50 * 1024 * 1024 // 50 MB\nconst segmentCacheLru = createLRU<SegmentCacheEntry>(\n  maxSegmentLruSize,\n  onSegmentLRUEviction\n)\n\nexport function readExactRouteCacheEntry(\n  now: number,\n  href: NormalizedHref,\n  nextUrl: NormalizedNextUrl | null\n): RouteCacheEntry | null {\n  const keypath: Prefix<RouteCacheKeypath> =\n    nextUrl === null ? [href] : [href, nextUrl]\n  const existingEntry = routeCacheMap.get(keypath)\n  if (existingEntry !== null) {\n    // Check if the entry is stale\n    if (existingEntry.staleAt > now) {\n      // Reuse the existing entry.\n\n      // Since this is an access, move the entry to the front of the LRU.\n      routeCacheLru.put(existingEntry)\n\n      return existingEntry\n    } else {\n      // Evict the stale entry from the cache.\n      deleteRouteFromCache(existingEntry, keypath)\n    }\n  }\n  return null\n}\n\nexport function readRouteCacheEntry(\n  now: number,\n  key: RouteCacheKey\n): RouteCacheEntry | null {\n  // First check if there's a non-intercepted entry. Most routes cannot be\n  // intercepted, so this is the common case.\n  const nonInterceptedEntry = readExactRouteCacheEntry(now, key.href, null)\n  if (nonInterceptedEntry !== null && !nonInterceptedEntry.couldBeIntercepted) {\n    // Found a match, and the route cannot be intercepted. We can reuse it.\n    return nonInterceptedEntry\n  }\n  // There was no match. Check again but include the Next-Url this time.\n  return readExactRouteCacheEntry(now, key.href, key.nextUrl)\n}\n\nexport function readSegmentCacheEntry(\n  now: number,\n  path: string\n): SegmentCacheEntry | null {\n  const existingEntry = segmentCacheMap.get(path)\n  if (existingEntry !== undefined) {\n    // Check if the entry is stale\n    if (existingEntry.staleAt > now) {\n      // Reuse the existing entry.\n\n      // Since this is an access, move the entry to the front of the LRU.\n      segmentCacheLru.put(existingEntry)\n\n      return existingEntry\n    } else {\n      // Evict the stale entry from the cache.\n      deleteSegmentFromCache(existingEntry, path)\n    }\n  }\n  return null\n}\n\nexport function waitForSegmentCacheEntry(\n  pendingEntry: PendingSegmentCacheEntry\n): Promise<FulfilledSegmentCacheEntry | null> {\n  // Because the entry is pending, there's already a in-progress request.\n  // Attach a promise to the entry that will resolve when the server responds.\n  let promiseWithResolvers = pendingEntry.promise\n  if (promiseWithResolvers === null) {\n    promiseWithResolvers = pendingEntry.promise =\n      createPromiseWithResolvers<FulfilledSegmentCacheEntry | null>()\n  } else {\n    // There's already a promise we can use\n  }\n  return promiseWithResolvers.promise\n}\n\n/**\n * Reads the route cache for a matching entry *and* spawns a request if there's\n * no match. Because this may issue a network request, it should only be called\n * from within the context of a prefetch task.\n */\nexport function requestRouteCacheEntryFromCache(\n  now: number,\n  task: PrefetchTask\n): RouteCacheEntry {\n  const key = task.key\n  // First check if there's a non-intercepted entry. Most routes cannot be\n  // intercepted, so this is the common case.\n  const nonInterceptedEntry = readExactRouteCacheEntry(now, key.href, null)\n  if (nonInterceptedEntry !== null && !nonInterceptedEntry.couldBeIntercepted) {\n    // Found a match, and the route cannot be intercepted. We can reuse it.\n    return nonInterceptedEntry\n  }\n  // There was no match. Check again but include the Next-Url this time.\n  const exactEntry = readExactRouteCacheEntry(now, key.href, key.nextUrl)\n  if (exactEntry !== null) {\n    return exactEntry\n  }\n  // Create a pending entry and spawn a request for its data.\n  const pendingEntry: PendingRouteCacheEntry = {\n    canonicalUrl: null,\n    status: EntryStatus.Pending,\n    blockedTasks: null,\n    tree: null,\n    head: null,\n    isHeadPartial: true,\n    // If the request takes longer than a minute, a subsequent request should\n    // retry instead of waiting for this one.\n    //\n    // When the response is received, this value will be replaced by a new value\n    // based on the stale time sent from the server.\n    staleAt: now + 60 * 1000,\n    // This is initialized to true because we don't know yet whether the route\n    // could be intercepted. It's only set to false once we receive a response\n    // from the server.\n    couldBeIntercepted: true,\n\n    // LRU-related fields\n    keypath: null,\n    next: null,\n    prev: null,\n    size: 0,\n  }\n  spawnPrefetchSubtask(fetchRouteOnCacheMiss(pendingEntry, task))\n  const keypath: Prefix<RouteCacheKeypath> =\n    key.nextUrl === null ? [key.href] : [key.href, key.nextUrl]\n  routeCacheMap.set(keypath, pendingEntry)\n  // Stash the keypath on the entry so we know how to remove it from the map\n  // if it gets evicted from the LRU.\n  pendingEntry.keypath = keypath\n  routeCacheLru.put(pendingEntry)\n  return pendingEntry\n}\n\n/**\n * Reads the route cache for a matching entry *and* spawns a request if there's\n * no match. Because this may issue a network request, it should only be called\n * from within the context of a prefetch task.\n */\nexport function requestSegmentEntryFromCache(\n  now: number,\n  task: PrefetchTask,\n  route: FulfilledRouteCacheEntry,\n  path: string,\n  accessToken: string\n): SegmentCacheEntry {\n  const existingEntry = readSegmentCacheEntry(now, path)\n  if (existingEntry !== null) {\n    return existingEntry\n  }\n  // Create a pending entry and spawn a request for its data.\n  const pendingEntry: PendingSegmentCacheEntry = {\n    status: EntryStatus.Pending,\n    rsc: null,\n    loading: null,\n    staleAt: route.staleAt,\n    isPartial: true,\n    promise: null,\n\n    // LRU-related fields\n    key: null,\n    next: null,\n    prev: null,\n    size: 0,\n  }\n  spawnPrefetchSubtask(\n    fetchSegmentEntryOnCacheMiss(\n      route,\n      pendingEntry,\n      task.key,\n      path,\n      accessToken\n    )\n  )\n  segmentCacheMap.set(path, pendingEntry)\n  // Stash the keypath on the entry so we know how to remove it from the map\n  // if it gets evicted from the LRU.\n  pendingEntry.key = path\n  segmentCacheLru.put(pendingEntry)\n  return pendingEntry\n}\n\nfunction deleteRouteFromCache(\n  entry: RouteCacheEntry,\n  keypath: Prefix<RouteCacheKeypath>\n): void {\n  pingBlockedTasks(entry)\n  routeCacheMap.delete(keypath)\n  routeCacheLru.delete(entry)\n}\n\nfunction deleteSegmentFromCache(entry: SegmentCacheEntry, key: string): void {\n  cancelEntryListeners(entry)\n  segmentCacheMap.delete(key)\n  segmentCacheLru.delete(entry)\n}\n\nfunction onRouteLRUEviction(entry: RouteCacheEntry): void {\n  // The LRU evicted this entry. Remove it from the map.\n  const keypath = entry.keypath\n  if (keypath !== null) {\n    entry.keypath = null\n    pingBlockedTasks(entry)\n    routeCacheMap.delete(keypath)\n  }\n}\n\nfunction onSegmentLRUEviction(entry: SegmentCacheEntry): void {\n  // The LRU evicted this entry. Remove it from the map.\n  const key = entry.key\n  if (key !== null) {\n    entry.key = null\n    cancelEntryListeners(entry)\n    segmentCacheMap.delete(key)\n  }\n}\n\nfunction cancelEntryListeners(entry: SegmentCacheEntry): void {\n  if (entry.status === EntryStatus.Pending && entry.promise !== null) {\n    // There were listeners for this entry. Resolve them with `null` to indicate\n    // that the prefetch failed. It's up to the listener to decide how to handle\n    // this case.\n    // NOTE: We don't currently propagate the reason the prefetch was canceled\n    // but we could by accepting a `reason` argument.\n    entry.promise.resolve(null)\n    entry.promise = null\n  }\n}\n\nfunction pingBlockedTasks(entry: {\n  blockedTasks: Set<PrefetchTask> | null\n}): void {\n  const blockedTasks = entry.blockedTasks\n  if (blockedTasks !== null) {\n    for (const task of blockedTasks) {\n      pingPrefetchTask(task)\n    }\n    entry.blockedTasks = null\n  }\n}\n\nfunction fulfillRouteCacheEntry(\n  entry: PendingRouteCacheEntry,\n  tree: TreePrefetch,\n  head: React.ReactNode,\n  isHeadPartial: boolean,\n  staleAt: number,\n  couldBeIntercepted: boolean,\n  canonicalUrl: string\n): FulfilledRouteCacheEntry {\n  const fulfilledEntry: FulfilledRouteCacheEntry = entry as any\n  fulfilledEntry.status = EntryStatus.Fulfilled\n  fulfilledEntry.tree = tree\n  fulfilledEntry.head = head\n  fulfilledEntry.isHeadPartial = isHeadPartial\n  fulfilledEntry.staleAt = staleAt\n  fulfilledEntry.couldBeIntercepted = couldBeIntercepted\n  fulfilledEntry.canonicalUrl = canonicalUrl\n  pingBlockedTasks(entry)\n  return fulfilledEntry\n}\n\nfunction fulfillSegmentCacheEntry(\n  segmentCacheEntry: PendingSegmentCacheEntry,\n  rsc: React.ReactNode,\n  loading: LoadingModuleData | Promise<LoadingModuleData>,\n  staleAt: number,\n  isPartial: boolean\n) {\n  const fulfilledEntry: FulfilledSegmentCacheEntry = segmentCacheEntry as any\n  fulfilledEntry.status = EntryStatus.Fulfilled\n  fulfilledEntry.rsc = rsc\n  fulfilledEntry.loading = loading\n  fulfilledEntry.staleAt = staleAt\n  fulfilledEntry.isPartial = isPartial\n  // Resolve any listeners that were waiting for this data.\n  if (segmentCacheEntry.promise !== null) {\n    segmentCacheEntry.promise.resolve(fulfilledEntry)\n    // Free the promise for garbage collection.\n    fulfilledEntry.promise = null\n  }\n}\n\nfunction rejectRouteCacheEntry(\n  entry: PendingRouteCacheEntry,\n  staleAt: number\n): void {\n  const rejectedEntry: RejectedRouteCacheEntry = entry as any\n  rejectedEntry.status = EntryStatus.Rejected\n  rejectedEntry.staleAt = staleAt\n  pingBlockedTasks(entry)\n}\n\nfunction rejectSegmentCacheEntry(\n  entry: PendingSegmentCacheEntry,\n  staleAt: number\n): void {\n  const rejectedEntry: RejectedSegmentCacheEntry = entry as any\n  rejectedEntry.status = EntryStatus.Rejected\n  rejectedEntry.staleAt = staleAt\n  if (entry.promise !== null) {\n    // NOTE: We don't currently propagate the reason the prefetch was canceled\n    // but we could by accepting a `reason` argument.\n    entry.promise.resolve(null)\n    entry.promise = null\n  }\n}\n\nasync function fetchRouteOnCacheMiss(\n  entry: PendingRouteCacheEntry,\n  task: PrefetchTask\n): Promise<void> {\n  // This function is allowed to use async/await because it contains the actual\n  // fetch that gets issued on a cache miss. Notice though that it does not\n  // return anything; it writes the result to the cache entry directly, then\n  // pings the scheduler to unblock the corresponding prefetch task.\n  const key = task.key\n  const href = key.href\n  const nextUrl = key.nextUrl\n  try {\n    const response = await fetchSegmentPrefetchResponse(href, '/_tree', nextUrl)\n    if (\n      !response ||\n      !response.ok ||\n      // 204 is a Cache miss. Though theoretically this shouldn't happen when\n      // PPR is enabled, because we always respond to route tree requests, even\n      // if it needs to be blockingly generated on demand.\n      response.status === 204 ||\n      !response.body\n    ) {\n      // Server responded with an error, or with a miss. We should still cache\n      // the response, but we can try again after 10 seconds.\n      rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n      return\n    }\n    const prefetchStream = createPrefetchResponseStream(\n      response.body,\n      routeCacheLru,\n      entry\n    )\n    const serverData: RootTreePrefetch = await (createFromNextReadableStream(\n      prefetchStream\n    ) as Promise<RootTreePrefetch>)\n    if (serverData.buildId !== getAppBuildId()) {\n      // The server build does not match the client. Treat as a 404. During\n      // an actual navigation, the router will trigger an MPA navigation.\n      // TODO: Consider moving the build ID to a response header so we can check\n      // it before decoding the response, and so there's one way of checking\n      // across all response types.\n      rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n      return\n    }\n\n    // This is a bit convoluted but it's taken from router-reducer and\n    // fetch-server-response\n    const canonicalUrl = response.redirected\n      ? createHrefFromUrl(urlToUrlWithoutFlightMarker(response.url))\n      : href\n\n    // Check whether the response varies based on the Next-Url header.\n    const varyHeader = response.headers.get('vary')\n    const couldBeIntercepted =\n      varyHeader !== null && varyHeader.includes(NEXT_URL)\n\n    fulfillRouteCacheEntry(\n      entry,\n      serverData.tree,\n      serverData.head,\n      serverData.isHeadPartial,\n      Date.now() + serverData.staleTime,\n      couldBeIntercepted,\n      canonicalUrl\n    )\n\n    if (!couldBeIntercepted && nextUrl !== null) {\n      // This route will never be intercepted. So we can use this entry for all\n      // requests to this route, regardless of the Next-Url header. This works\n      // because when reading the cache we always check for a valid\n      // non-intercepted entry first.\n      //\n      // Re-key the entry. Since we're in an async task, we must first confirm\n      // that the entry hasn't been concurrently modified by a different task.\n      const currentKeypath: Prefix<RouteCacheKeypath> = [href, nextUrl]\n      const expectedEntry = routeCacheMap.get(currentKeypath)\n      if (expectedEntry === entry) {\n        routeCacheMap.delete(currentKeypath)\n        const newKeypath: Prefix<RouteCacheKeypath> = [href]\n        routeCacheMap.set(newKeypath, entry)\n        // We don't need to update the LRU because the entry is already in it.\n        // But since we changed the keypath, we do need to update that, so we\n        // know how to remove it from the map if it gets evicted from the LRU.\n        entry.keypath = newKeypath\n      } else {\n        // Something else modified this entry already. Since the re-keying is\n        // just a performance optimization, we can safely skip it.\n      }\n    }\n  } catch (error) {\n    // Either the connection itself failed, or something bad happened while\n    // decoding the response.\n    rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n  }\n}\n\nasync function fetchSegmentEntryOnCacheMiss(\n  route: FulfilledRouteCacheEntry,\n  segmentCacheEntry: PendingSegmentCacheEntry,\n  routeKey: RouteCacheKey,\n  segmentPath: string,\n  accessToken: string | null\n): Promise<void> {\n  // This function is allowed to use async/await because it contains the actual\n  // fetch that gets issued on a cache miss. Notice though that it does not\n  // return anything; it writes the result to the cache entry directly.\n  //\n  // Segment fetches are non-blocking so we don't need to ping the scheduler\n  // on completion.\n  const href = routeKey.href\n  try {\n    const response = await fetchSegmentPrefetchResponse(\n      href,\n      accessToken === '' ? segmentPath : `${segmentPath}.${accessToken}`,\n      routeKey.nextUrl\n    )\n    if (\n      !response ||\n      !response.ok ||\n      response.status === 204 || // Cache miss\n      !response.body\n    ) {\n      // Server responded with an error, or with a miss. We should still cache\n      // the response, but we can try again after 10 seconds.\n      rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n      return\n    }\n    // Wrap the original stream in a new stream that never closes. That way the\n    // Flight client doesn't error if there's a hanging promise.\n    const prefetchStream = createPrefetchResponseStream(\n      response.body,\n      segmentCacheLru,\n      segmentCacheEntry\n    )\n    const serverData = await (createFromNextReadableStream(\n      prefetchStream\n    ) as Promise<SegmentPrefetch>)\n    if (serverData.buildId !== getAppBuildId()) {\n      // The server build does not match the client. Treat as a 404. During\n      // an actual navigation, the router will trigger an MPA navigation.\n      // TODO: Consider moving the build ID to a response header so we can check\n      // it before decoding the response, and so there's one way of checking\n      // across all response types.\n      rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n      return\n    }\n    fulfillSegmentCacheEntry(\n      segmentCacheEntry,\n      serverData.rsc,\n      serverData.loading,\n      // TODO: The server does not currently provide per-segment stale time.\n      // So we use the stale time of the route.\n      route.staleAt,\n      serverData.isPartial\n    )\n  } catch (error) {\n    // Either the connection itself failed, or something bad happened while\n    // decoding the response.\n    rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n  }\n}\n\nasync function fetchSegmentPrefetchResponse(\n  href: NormalizedHref,\n  segmentPath: string,\n  nextUrl: NormalizedNextUrl | null\n): Promise<Response | null> {\n  const headers: RequestHeaders = {\n    [RSC_HEADER]: '1',\n    [NEXT_ROUTER_PREFETCH_HEADER]: '1',\n    [NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]: segmentPath,\n  }\n  if (nextUrl !== null) {\n    headers[NEXT_URL] = nextUrl\n  }\n  const fetchPriority = 'low'\n  const responsePromise = createFetch(new URL(href), headers, fetchPriority)\n  trackPrefetchRequestBandwidth(responsePromise)\n  const response = await responsePromise\n  const contentType = response.headers.get('content-type')\n  const isFlightResponse =\n    contentType && contentType.startsWith(RSC_CONTENT_TYPE_HEADER)\n  if (!response.ok || !isFlightResponse) {\n    return null\n  }\n  return response\n}\n\nfunction createPrefetchResponseStream<\n  T extends RouteCacheEntry | SegmentCacheEntry,\n>(\n  originalFlightStream: ReadableStream<Uint8Array>,\n  lru: LRU<T>,\n  lruEntry: T\n): ReadableStream<Uint8Array> {\n  // When PPR is enabled, prefetch streams may contain references that never\n  // resolve, because that's how we encode dynamic data access. In the decoded\n  // object returned by the Flight client, these are reified into hanging\n  // promises that suspend during render, which is effectively what we want.\n  // The UI resolves when it switches to the dynamic data stream\n  // (via useDeferredValue(dynamic, static)).\n  //\n  // However, the Flight implementation currently errors if the server closes\n  // the response before all the references are resolved. As a cheat to work\n  // around this, we wrap the original stream in a new stream that never closes,\n  // and therefore doesn't error.\n  //\n  // While processing the original stream, we also incrementally update the size\n  // of the cache entry in the LRU.\n  let totalByteLength = 0\n  const reader = originalFlightStream.getReader()\n  return new ReadableStream({\n    async pull(controller) {\n      while (true) {\n        const { done, value } = await reader.read()\n        if (!done) {\n          // Pass to the target stream and keep consuming the Flight response\n          // from the server.\n          controller.enqueue(value)\n\n          // Incrementally update the size of the cache entry in the LRU.\n          // NOTE: Since prefetch responses are delivered in a single chunk,\n          // it's not really necessary to do this streamingly, but I'm doing it\n          // anyway in case this changes in the future.\n          totalByteLength += value.byteLength\n          lru.updateSize(lruEntry, totalByteLength)\n\n          continue\n        }\n        // The server stream has closed. Exit, but intentionally do not close\n        // the target stream.\n        return\n      }\n    },\n  })\n}\n\nfunction createPromiseWithResolvers<T>(): PromiseWithResolvers<T> {\n  // Shim of Stage 4 Promise.withResolvers proposal\n  let resolve: (value: T | PromiseLike<T>) => void\n  let reject: (reason: any) => void\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res\n    reject = rej\n  })\n  return { resolve: resolve!, reject: reject!, promise }\n}\n"],"names":["EntryStatus","readExactRouteCacheEntry","readRouteCacheEntry","readSegmentCacheEntry","requestRouteCacheEntryFromCache","requestSegmentEntryFromCache","waitForSegmentCacheEntry","routeCacheMap","createTupleMap","maxRouteLruSize","routeCacheLru","createLRU","onRouteLRUEviction","segmentCacheMap","Map","maxSegmentLruSize","segmentCacheLru","onSegmentLRUEviction","now","href","nextUrl","keypath","existingEntry","get","staleAt","put","deleteRouteFromCache","key","nonInterceptedEntry","couldBeIntercepted","path","undefined","deleteSegmentFromCache","pendingEntry","promiseWithResolvers","promise","createPromiseWithResolvers","task","exactEntry","canonicalUrl","status","blockedTasks","tree","head","isHeadPartial","next","prev","size","spawnPrefetchSubtask","fetchRouteOnCacheMiss","set","route","accessToken","rsc","loading","isPartial","fetchSegmentEntryOnCacheMiss","entry","pingBlockedTasks","delete","cancelEntryListeners","resolve","pingPrefetchTask","fulfillRouteCacheEntry","fulfilledEntry","fulfillSegmentCacheEntry","segmentCacheEntry","rejectRouteCacheEntry","rejectedEntry","rejectSegmentCacheEntry","response","fetchSegmentPrefetchResponse","ok","body","Date","prefetchStream","createPrefetchResponseStream","serverData","createFromNextReadableStream","buildId","getAppBuildId","redirected","createHrefFromUrl","urlToUrlWithoutFlightMarker","url","varyHeader","headers","includes","NEXT_URL","staleTime","currentKeypath","expectedEntry","newKeypath","error","routeKey","segmentPath","RSC_HEADER","NEXT_ROUTER_PREFETCH_HEADER","NEXT_ROUTER_SEGMENT_PREFETCH_HEADER","fetchPriority","responsePromise","createFetch","URL","trackPrefetchRequestBandwidth","contentType","isFlightResponse","startsWith","RSC_CONTENT_TYPE_HEADER","originalFlightStream","lru","lruEntry","totalByteLength","reader","getReader","ReadableStream","pull","controller","done","value","read","enqueue","byteLength","updateSize","reject","Promise","res","rej"],"mappings":";;;;;;;;;;;;;;;;;;;;IAsEkBA,WAAW,EAAA;eAAXA;;IA8GFC,wBAAwB,EAAA;eAAxBA;;IAyBAC,mBAAmB,EAAA;eAAnBA;;IAeAC,qBAAqB,EAAA;eAArBA;;IA0CAC,+BAA+B,EAAA;eAA/BA;;IA0DAC,4BAA4B,EAAA;eAA5BA;;IA9EAC,wBAAwB,EAAA;eAAxBA;;;kCAtOT;qCAMA;2BAMA;4BACuB;mCACI;0BAMyB;qBACvB;AAqC7B,IAAWN,cAAAA,WAAAA,GAAAA,SAAAA,WAAAA;;;;WAAAA;;AAmFlB,MAAMO,gBACJC,CAAAA,GAAAA,UAAAA,cAAc;AAEhB,8EAA8E;AAC9E,2DAA2D;AAC3D,+EAA+E;AAC/E,0EAA0E;AAC1E,4CAA4C;AAC5C,MAAMC,kBAAkB,KAAK,OAAO,KAAK,QAAQ;;AACjD,MAAMC,gBAAgBC,CAAAA,GAAAA,KAAAA,SAAS,EAC7BF,iBACAG;AAGF,wEAAwE;AACxE,6BAA6B;AAC7B,MAAMC,kBAAkB,IAAIC;AAC5B,0EAA0E;AAC1E,4EAA4E;AAC5E,+EAA+E;AAC/E,8BAA8B;AAC9B,MAAMC,oBAAoB,KAAK,OAAO,KAAK,QAAQ;;AACnD,MAAMC,kBAAkBL,CAAAA,GAAAA,KAAAA,SAAS,EAC/BI,mBACAE;AAGK,SAAShB,yBACdiB,GAAW,EACXC,IAAoB,EACpBC,OAAiC;IAEjC,MAAMC,UACJD,YAAY,OAAO;QAACD;KAAK,GAAG;QAACA;QAAMC;KAAQ;IAC7C,MAAME,gBAAgBf,cAAcgB,GAAG,CAACF;IACxC,IAAIC,kBAAkB,MAAM;QAC1B,8BAA8B;QAC9B,IAAIA,cAAcE,OAAO,GAAGN,KAAK;YAC/B,4BAA4B;YAE5B,mEAAmE;YACnER,cAAce,GAAG,CAACH;YAElB,OAAOA;QACT,OAAO;YACL,wCAAwC;YACxCI,qBAAqBJ,eAAeD;QACtC;IACF;IACA,OAAO;AACT;AAEO,SAASnB,oBACdgB,GAAW,EACXS,GAAkB;IAElB,wEAAwE;IACxE,2CAA2C;IAC3C,MAAMC,sBAAsB3B,yBAAyBiB,KAAKS,IAAIR,IAAI,EAAE;IACpE,IAAIS,wBAAwB,QAAQ,CAACA,oBAAoBC,kBAAkB,EAAE;QAC3E,uEAAuE;QACvE,OAAOD;IACT;IACA,sEAAsE;IACtE,OAAO3B,yBAAyBiB,KAAKS,IAAIR,IAAI,EAAEQ,IAAIP,OAAO;AAC5D;AAEO,SAASjB,sBACde,GAAW,EACXY,IAAY;IAEZ,MAAMR,gBAAgBT,gBAAgBU,GAAG,CAACO;IAC1C,IAAIR,kBAAkBS,WAAW;QAC/B,8BAA8B;QAC9B,IAAIT,cAAcE,OAAO,GAAGN,KAAK;YAC/B,4BAA4B;YAE5B,mEAAmE;YACnEF,gBAAgBS,GAAG,CAACH;YAEpB,OAAOA;QACT,OAAO;YACL,wCAAwC;YACxCU,uBAAuBV,eAAeQ;QACxC;IACF;IACA,OAAO;AACT;AAEO,SAASxB,yBACd2B,YAAsC;IAEtC,uEAAuE;IACvE,4EAA4E;IAC5E,IAAIC,uBAAuBD,aAAaE,OAAO;IAC/C,IAAID,yBAAyB,MAAM;QACjCA,uBAAuBD,aAAaE,OAAO,GACzCC;IACJ,OAAO;IACL,uCAAuC;IACzC;IACA,OAAOF,qBAAqBC,OAAO;AACrC;AAOO,SAAS/B,gCACdc,GAAW,EACXmB,IAAkB;IAElB,MAAMV,MAAMU,KAAKV,GAAG;IACpB,wEAAwE;IACxE,2CAA2C;IAC3C,MAAMC,sBAAsB3B,yBAAyBiB,KAAKS,IAAIR,IAAI,EAAE;IACpE,IAAIS,wBAAwB,QAAQ,CAACA,oBAAoBC,kBAAkB,EAAE;QAC3E,uEAAuE;QACvE,OAAOD;IACT;IACA,sEAAsE;IACtE,MAAMU,aAAarC,yBAAyBiB,KAAKS,IAAIR,IAAI,EAAEQ,IAAIP,OAAO;IACtE,IAAIkB,eAAe,MAAM;QACvB,OAAOA;IACT;IACA,2DAA2D;IAC3D,MAAML,eAAuC;QAC3CM,cAAc;QACdC,MAAM,EAAA;QACNC,cAAc;QACdC,MAAM;QACNC,MAAM;QACNC,eAAe;QACf,yEAAyE;QACzE,yCAAyC;QACzC,EAAE;QACF,4EAA4E;QAC5E,gDAAgD;QAChDpB,SAASN,MAAM,KAAK;QACpB,0EAA0E;QAC1E,0EAA0E;QAC1E,mBAAmB;QACnBW,oBAAoB;QAEpB,qBAAqB;QACrBR,SAAS;QACTwB,MAAM;QACNC,MAAM;QACNC,MAAM;IACR;IACAC,CAAAA,GAAAA,WAAAA,oBAAoB,EAACC,sBAAsBhB,cAAcI;IACzD,MAAMhB,UACJM,IAAIP,OAAO,KAAK,OAAO;QAACO,IAAIR,IAAI;KAAC,GAAG;QAACQ,IAAIR,IAAI;QAAEQ,IAAIP,OAAO;KAAC;IAC7Db,cAAc2C,GAAG,CAAC7B,SAASY;IAC3B,0EAA0E;IAC1E,mCAAmC;IACnCA,aAAaZ,OAAO,GAAGA;IACvBX,cAAce,GAAG,CAACQ;IAClB,OAAOA;AACT;AAOO,SAAS5B,6BACda,GAAW,EACXmB,IAAkB,EAClBc,KAA+B,EAC/BrB,IAAY,EACZsB,WAAmB;IAEnB,MAAM9B,gBAAgBnB,sBAAsBe,KAAKY;IACjD,IAAIR,kBAAkB,MAAM;QAC1B,OAAOA;IACT;IACA,2DAA2D;IAC3D,MAAMW,eAAyC;QAC7CO,MAAM,EAAA;QACNa,KAAK;QACLC,SAAS;QACT9B,SAAS2B,MAAM3B,OAAO;QACtB+B,WAAW;QACXpB,SAAS;QAET,qBAAqB;QACrBR,KAAK;QACLkB,MAAM;QACNC,MAAM;QACNC,MAAM;IACR;IACAC,CAAAA,GAAAA,WAAAA,oBAAoB,EAClBQ,6BACEL,OACAlB,cACAI,KAAKV,GAAG,EACRG,MACAsB;IAGJvC,gBAAgBqC,GAAG,CAACpB,MAAMG;IAC1B,0EAA0E;IAC1E,mCAAmC;IACnCA,aAAaN,GAAG,GAAGG;IACnBd,gBAAgBS,GAAG,CAACQ;IACpB,OAAOA;AACT;AAEA,SAASP,qBACP+B,KAAsB,EACtBpC,OAAkC;IAElCqC,iBAAiBD;IACjBlD,cAAcoD,MAAM,CAACtC;IACrBX,cAAciD,MAAM,CAACF;AACvB;AAEA,SAASzB,uBAAuByB,KAAwB,EAAE9B,GAAW;IACnEiC,qBAAqBH;IACrB5C,gBAAgB8C,MAAM,CAAChC;IACvBX,gBAAgB2C,MAAM,CAACF;AACzB;AAEA,SAAS7C,mBAAmB6C,KAAsB;IAChD,sDAAsD;IACtD,MAAMpC,UAAUoC,MAAMpC,OAAO;IAC7B,IAAIA,YAAY,MAAM;QACpBoC,MAAMpC,OAAO,GAAG;QAChBqC,iBAAiBD;QACjBlD,cAAcoD,MAAM,CAACtC;IACvB;AACF;AAEA,SAASJ,qBAAqBwC,KAAwB;IACpD,sDAAsD;IACtD,MAAM9B,MAAM8B,MAAM9B,GAAG;IACrB,IAAIA,QAAQ,MAAM;QAChB8B,MAAM9B,GAAG,GAAG;QACZiC,qBAAqBH;QACrB5C,gBAAgB8C,MAAM,CAAChC;IACzB;AACF;AAEA,SAASiC,qBAAqBH,KAAwB;IACpD,IAAIA,MAAMjB,MAAM,KAAA,KAA4BiB,MAAMtB,OAAO,KAAK,MAAM;QAClE,4EAA4E;QAC5E,4EAA4E;QAC5E,aAAa;QACb,0EAA0E;QAC1E,iDAAiD;QACjDsB,MAAMtB,OAAO,CAAC0B,OAAO,CAAC;QACtBJ,MAAMtB,OAAO,GAAG;IAClB;AACF;AAEA,SAASuB,iBAAiBD,KAEzB;IACC,MAAMhB,eAAegB,MAAMhB,YAAY;IACvC,IAAIA,iBAAiB,MAAM;QACzB,KAAK,MAAMJ,QAAQI,aAAc;YAC/BqB,CAAAA,GAAAA,WAAAA,gBAAgB,EAACzB;QACnB;QACAoB,MAAMhB,YAAY,GAAG;IACvB;AACF;AAEA,SAASsB,uBACPN,KAA6B,EAC7Bf,IAAkB,EAClBC,IAAqB,EACrBC,aAAsB,EACtBpB,OAAe,EACfK,kBAA2B,EAC3BU,YAAoB;IAEpB,MAAMyB,iBAA2CP;IACjDO,eAAexB,MAAM,GAAA;IACrBwB,eAAetB,IAAI,GAAGA;IACtBsB,eAAerB,IAAI,GAAGA;IACtBqB,eAAepB,aAAa,GAAGA;IAC/BoB,eAAexC,OAAO,GAAGA;IACzBwC,eAAenC,kBAAkB,GAAGA;IACpCmC,eAAezB,YAAY,GAAGA;IAC9BmB,iBAAiBD;IACjB,OAAOO;AACT;AAEA,SAASC,yBACPC,iBAA2C,EAC3Cb,GAAoB,EACpBC,OAAuD,EACvD9B,OAAe,EACf+B,SAAkB;IAElB,MAAMS,iBAA6CE;IACnDF,eAAexB,MAAM,GAAA;IACrBwB,eAAeX,GAAG,GAAGA;IACrBW,eAAeV,OAAO,GAAGA;IACzBU,eAAexC,OAAO,GAAGA;IACzBwC,eAAeT,SAAS,GAAGA;IAC3B,yDAAyD;IACzD,IAAIW,kBAAkB/B,OAAO,KAAK,MAAM;QACtC+B,kBAAkB/B,OAAO,CAAC0B,OAAO,CAACG;QAClC,2CAA2C;QAC3CA,eAAe7B,OAAO,GAAG;IAC3B;AACF;AAEA,SAASgC,sBACPV,KAA6B,EAC7BjC,OAAe;IAEf,MAAM4C,gBAAyCX;IAC/CW,cAAc5B,MAAM,GAAA;IACpB4B,cAAc5C,OAAO,GAAGA;IACxBkC,iBAAiBD;AACnB;AAEA,SAASY,wBACPZ,KAA+B,EAC/BjC,OAAe;IAEf,MAAM4C,gBAA2CX;IACjDW,cAAc5B,MAAM,GAAA;IACpB4B,cAAc5C,OAAO,GAAGA;IACxB,IAAIiC,MAAMtB,OAAO,KAAK,MAAM;QAC1B,0EAA0E;QAC1E,iDAAiD;QACjDsB,MAAMtB,OAAO,CAAC0B,OAAO,CAAC;QACtBJ,MAAMtB,OAAO,GAAG;IAClB;AACF;AAEA,eAAec,sBACbQ,KAA6B,EAC7BpB,IAAkB;IAElB,6EAA6E;IAC7E,yEAAyE;IACzE,0EAA0E;IAC1E,kEAAkE;IAClE,MAAMV,MAAMU,KAAKV,GAAG;IACpB,MAAMR,OAAOQ,IAAIR,IAAI;IACrB,MAAMC,UAAUO,IAAIP,OAAO;IAC3B,IAAI;QACF,MAAMkD,WAAW,MAAMC,6BAA6BpD,MAAM,UAAUC;QACpE,IACE,CAACkD,YACD,CAACA,SAASE,EAAE,IACZ,uEAAuE;QACvE,yEAAyE;QACzE,oDAAoD;QACpDF,SAAS9B,MAAM,KAAK,OACpB,CAAC8B,SAASG,IAAI,EACd;YACA,wEAAwE;YACxE,uDAAuD;YACvDN,sBAAsBV,OAAOiB,KAAKxD,GAAG,KAAK,KAAK;YAC/C;QACF;QACA,MAAMyD,iBAAiBC,6BACrBN,SAASG,IAAI,EACb/D,eACA+C;QAEF,MAAMoB,aAA+B,MAAOC,CAAAA,GAAAA,qBAAAA,4BAA4B,EACtEH;QAEF,IAAIE,WAAWE,OAAO,KAAKC,CAAAA,GAAAA,YAAAA,aAAa,KAAI;YAC1C,qEAAqE;YACrE,mEAAmE;YACnE,0EAA0E;YAC1E,sEAAsE;YACtE,6BAA6B;YAC7Bb,sBAAsBV,OAAOiB,KAAKxD,GAAG,KAAK,KAAK;YAC/C;QACF;QAEA,kEAAkE;QAClE,wBAAwB;QACxB,MAAMqB,eAAe+B,SAASW,UAAU,GACpCC,CAAAA,GAAAA,mBAAAA,iBAAiB,EAACC,CAAAA,GAAAA,qBAAAA,2BAA2B,EAACb,SAASc,GAAG,KAC1DjE;QAEJ,kEAAkE;QAClE,MAAMkE,aAAaf,SAASgB,OAAO,CAAC/D,GAAG,CAAC;QACxC,MAAMM,qBACJwD,eAAe,QAAQA,WAAWE,QAAQ,CAACC,kBAAAA,QAAQ;QAErDzB,uBACEN,OACAoB,WAAWnC,IAAI,EACfmC,WAAWlC,IAAI,EACfkC,WAAWjC,aAAa,EACxB8B,KAAKxD,GAAG,KAAK2D,WAAWY,SAAS,EACjC5D,oBACAU;QAGF,IAAI,CAACV,sBAAsBT,YAAY,MAAM;YAC3C,yEAAyE;YACzE,wEAAwE;YACxE,6DAA6D;YAC7D,+BAA+B;YAC/B,EAAE;YACF,wEAAwE;YACxE,wEAAwE;YACxE,MAAMsE,iBAA4C;gBAACvE;gBAAMC;aAAQ;YACjE,MAAMuE,gBAAgBpF,cAAcgB,GAAG,CAACmE;YACxC,IAAIC,kBAAkBlC,OAAO;gBAC3BlD,cAAcoD,MAAM,CAAC+B;gBACrB,MAAME,aAAwC;oBAACzE;iBAAK;gBACpDZ,cAAc2C,GAAG,CAAC0C,YAAYnC;gBAC9B,sEAAsE;gBACtE,qEAAqE;gBACrE,sEAAsE;gBACtEA,MAAMpC,OAAO,GAAGuE;YAClB,OAAO;YACL,qEAAqE;YACrE,0DAA0D;YAC5D;QACF;IACF,EAAE,OAAOC,OAAO;QACd,uEAAuE;QACvE,yBAAyB;QACzB1B,sBAAsBV,OAAOiB,KAAKxD,GAAG,KAAK,KAAK;IACjD;AACF;AAEA,eAAesC,6BACbL,KAA+B,EAC/Be,iBAA2C,EAC3C4B,QAAuB,EACvBC,WAAmB,EACnB3C,WAA0B;IAE1B,6EAA6E;IAC7E,yEAAyE;IACzE,qEAAqE;IACrE,EAAE;IACF,0EAA0E;IAC1E,iBAAiB;IACjB,MAAMjC,OAAO2E,SAAS3E,IAAI;IAC1B,IAAI;QACF,MAAMmD,WAAW,MAAMC,6BACrBpD,MACAiC,gBAAgB,KAAK2C,cAAiBA,cAAY,MAAG3C,aACrD0C,SAAS1E,OAAO;QAElB,IACE,CAACkD,YACD,CAACA,SAASE,EAAE,IACZF,SAAS9B,MAAM,KAAK,OAAO,aAAa;QACxC,CAAC8B,SAASG,IAAI,EACd;YACA,wEAAwE;YACxE,uDAAuD;YACvDJ,wBAAwBH,mBAAmBQ,KAAKxD,GAAG,KAAK,KAAK;YAC7D;QACF;QACA,2EAA2E;QAC3E,4DAA4D;QAC5D,MAAMyD,iBAAiBC,6BACrBN,SAASG,IAAI,EACbzD,iBACAkD;QAEF,MAAMW,aAAa,MAAOC,CAAAA,GAAAA,qBAAAA,4BAA4B,EACpDH;QAEF,IAAIE,WAAWE,OAAO,KAAKC,CAAAA,GAAAA,YAAAA,aAAa,KAAI;YAC1C,qEAAqE;YACrE,mEAAmE;YACnE,0EAA0E;YAC1E,sEAAsE;YACtE,6BAA6B;YAC7BX,wBAAwBH,mBAAmBQ,KAAKxD,GAAG,KAAK,KAAK;YAC7D;QACF;QACA+C,yBACEC,mBACAW,WAAWxB,GAAG,EACdwB,WAAWvB,OAAO,EAElB,AADA,yCACyC,6BAD6B;QAEtEH,MAAM3B,OAAO,EACbqD,WAAWtB,SAAS;IAExB,EAAE,OAAOsC,OAAO;QACd,uEAAuE;QACvE,yBAAyB;QACzBxB,wBAAwBH,mBAAmBQ,KAAKxD,GAAG,KAAK,KAAK;IAC/D;AACF;AAEA,eAAeqD,6BACbpD,IAAoB,EACpB4E,WAAmB,EACnB3E,OAAiC;IAEjC,MAAMkE,UAA0B;QAC9B,CAACU,kBAAAA,UAAU,CAAC,EAAE;QACd,CAACC,kBAAAA,2BAA2B,CAAC,EAAE;QAC/B,CAACC,kBAAAA,mCAAmC,CAAC,EAAEH;IACzC;IACA,IAAI3E,YAAY,MAAM;QACpBkE,OAAO,CAACE,kBAAAA,QAAQ,CAAC,GAAGpE;IACtB;IACA,MAAM+E,gBAAgB;IACtB,MAAMC,kBAAkBC,CAAAA,GAAAA,qBAAAA,WAAW,EAAC,IAAIC,IAAInF,OAAOmE,SAASa;IAC5DI,CAAAA,GAAAA,WAAAA,6BAA6B,EAACH;IAC9B,MAAM9B,WAAW,MAAM8B;IACvB,MAAMI,cAAclC,SAASgB,OAAO,CAAC/D,GAAG,CAAC;IACzC,MAAMkF,mBACJD,eAAeA,YAAYE,UAAU,CAACC,kBAAAA,uBAAuB;IAC/D,IAAI,CAACrC,SAASE,EAAE,IAAI,CAACiC,kBAAkB;QACrC,OAAO;IACT;IACA,OAAOnC;AACT;AAEA,SAASM,6BAGPgC,oBAAgD,EAChDC,GAAW,EACXC,QAAW;IAEX,0EAA0E;IAC1E,4EAA4E;IAC5E,uEAAuE;IACvE,0EAA0E;IAC1E,8DAA8D;IAC9D,2CAA2C;IAC3C,EAAE;IACF,2EAA2E;IAC3E,0EAA0E;IAC1E,8EAA8E;IAC9E,+BAA+B;IAC/B,EAAE;IACF,8EAA8E;IAC9E,iCAAiC;IACjC,IAAIC,kBAAkB;IACtB,MAAMC,SAASJ,qBAAqBK,SAAS;IAC7C,OAAO,IAAIC,eAAe;QACxB,MAAMC,MAAKC,UAAU;YACnB,MAAO,KAAM;gBACX,MAAM,EAAEC,IAAI,EAAEC,KAAK,EAAE,GAAG,MAAMN,OAAOO,IAAI;gBACzC,IAAI,CAACF,MAAM;oBACT,mEAAmE;oBACnE,mBAAmB;oBACnBD,WAAWI,OAAO,CAACF;oBAEnB,+DAA+D;oBAC/D,kEAAkE;oBAClE,qEAAqE;oBACrE,6CAA6C;oBAC7CP,mBAAmBO,MAAMG,UAAU;oBACnCZ,IAAIa,UAAU,CAACZ,UAAUC;oBAEzB;gBACF;gBACA,qEAAqE;gBACrE,qBAAqB;gBACrB;YACF;QACF;IACF;AACF;AAEA,SAAS3E;IACP,iDAAiD;IACjD,IAAIyB;IACJ,IAAI8D;IACJ,MAAMxF,UAAU,IAAIyF,QAAW,CAACC,KAAKC;QACnCjE,UAAUgE;QACVF,SAASG;IACX;IACA,OAAO;QAAEjE,SAASA;QAAU8D,QAAQA;QAASxF;IAAQ;AACvD","ignoreList":[0]}},
    {"offset": {"line": 2325, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2330, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/cache-key.ts"],"sourcesContent":["// TypeScript trick to simulate opaque types, like in Flow.\ntype Opaque<K, T> = T & { __brand: K }\n\n// Only functions in this module should be allowed to create CacheKeys.\nexport type NormalizedHref = Opaque<'NormalizedHref', string>\nexport type NormalizedNextUrl = Opaque<'NormalizedNextUrl', string>\n\nexport type RouteCacheKey = Opaque<\n  'RouteCacheKey',\n  {\n    href: NormalizedHref\n    nextUrl: NormalizedNextUrl | null\n  }\n>\n\nexport function createCacheKey(\n  originalHref: string,\n  nextUrl: string | null\n): RouteCacheKey {\n  const originalUrl = new URL(originalHref)\n\n  // TODO: As of now, we never include search params in the cache key because\n  // per-segment prefetch requests are always static, and cannot contain search\n  // params. But to support <Link prefetch={true}>, we will sometimes populate\n  // the cache with dynamic data, so this will have to change.\n  originalUrl.search = ''\n\n  const normalizedHref = originalUrl.href as NormalizedHref\n  const normalizedNextUrl = nextUrl as NormalizedNextUrl | null\n\n  const cacheKey = {\n    href: normalizedHref,\n    nextUrl: normalizedNextUrl,\n  } as RouteCacheKey\n\n  return cacheKey\n}\n"],"names":["createCacheKey","originalHref","nextUrl","originalUrl","URL","search","normalizedHref","href","normalizedNextUrl","cacheKey"],"mappings":"AAAA,2DAA2D;;;;;+BAe3CA,kBAAAA;;;eAAAA;;;AAAT,SAASA,eACdC,YAAoB,EACpBC,OAAsB;IAEtB,MAAMC,cAAc,IAAIC,IAAIH;IAE5B,2EAA2E;IAC3E,6EAA6E;IAC7E,4EAA4E;IAC5E,4DAA4D;IAC5DE,YAAYE,MAAM,GAAG;IAErB,MAAMC,iBAAiBH,YAAYI,IAAI;IACvC,MAAMC,oBAAoBN;IAE1B,MAAMO,WAAW;QACfF,MAAMD;QACNJ,SAASM;IACX;IAEA,OAAOC;AACT","ignoreList":[0]}},
    {"offset": {"line": 2363, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2368, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/ephig/Documents/GitHub/Bee_Design_Studio/bee_design_studio/node_modules/next/src/client/components/segment-cache/navigation.ts"],"sourcesContent":["import type {\n  CacheNodeSeedData,\n  FlightRouterState,\n  FlightSegmentPath,\n} from '../../../server/app-render/types'\nimport type {\n  CacheNode,\n  LoadingModuleData,\n} from '../../../shared/lib/app-router-context.shared-runtime'\nimport type { NormalizedFlightData } from '../../flight-data-helpers'\nimport { fetchServerResponse } from '../router-reducer/fetch-server-response'\nimport {\n  updateCacheNodeOnNavigation,\n  listenForDynamicRequest,\n  type Task as PPRNavigationTask,\n} from '../router-reducer/ppr-navigations'\nimport { createHrefFromUrl as createCanonicalUrl } from '../router-reducer/create-href-from-url'\nimport {\n  EntryStatus,\n  readRouteCacheEntry,\n  readSegmentCacheEntry,\n  waitForSegmentCacheEntry,\n} from './cache'\nimport type { TreePrefetch } from '../../../server/app-render/collect-segment-data'\nimport { createCacheKey } from './cache-key'\n\nexport const enum NavigationResultTag {\n  MPA,\n  Success,\n  NoOp,\n  Async,\n}\n\ntype MPANavigationResult = {\n  tag: NavigationResultTag.MPA\n  data: string\n}\n\ntype NoOpNavigationResult = {\n  tag: NavigationResultTag.NoOp\n  data: null\n}\n\ntype SuccessfulNavigationResult = {\n  tag: NavigationResultTag.Success\n  data: {\n    flightRouterState: FlightRouterState\n    cacheNode: CacheNode\n    canonicalUrl: string\n  }\n}\n\ntype AsyncNavigationResult = {\n  tag: NavigationResultTag.Async\n  data: Promise<\n    MPANavigationResult | NoOpNavigationResult | SuccessfulNavigationResult\n  >\n}\n\nexport type NavigationResult =\n  | MPANavigationResult\n  | SuccessfulNavigationResult\n  | NoOpNavigationResult\n  | AsyncNavigationResult\n\nconst noOpNavigationResult: NoOpNavigationResult = {\n  tag: NavigationResultTag.NoOp,\n  data: null,\n}\n\n/**\n * Navigate to a new URL, using the Segment Cache to construct a response.\n *\n * To allow for synchronous navigations whenever possible, this is not an async\n * function. It returns a promise only if there's no matching prefetch in\n * the cache. Otherwise it returns an immediate result and uses Suspense/RSC to\n * stream in any missing data.\n */\nexport function navigate(\n  url: URL,\n  currentCacheNode: CacheNode,\n  currentFlightRouterState: FlightRouterState,\n  nextUrl: string | null\n): AsyncNavigationResult | SuccessfulNavigationResult | NoOpNavigationResult {\n  const now = Date.now()\n\n  const cacheKey = createCacheKey(url.href, nextUrl)\n  const route = readRouteCacheEntry(now, cacheKey)\n  if (route !== null && route.status === EntryStatus.Fulfilled) {\n    // We have a matching prefetch.\n    const snapshot = readRenderSnapshotFromCache(now, route.tree)\n    const prefetchFlightRouterState = snapshot.flightRouterState\n    const prefetchSeedData = snapshot.seedData\n    const prefetchHead = route.head\n    const isPrefetchHeadPartial = route.isHeadPartial\n    const canonicalUrl = route.canonicalUrl\n    return navigateUsingPrefetchedRouteTree(\n      url,\n      nextUrl,\n      currentCacheNode,\n      currentFlightRouterState,\n      prefetchFlightRouterState,\n      prefetchSeedData,\n      prefetchHead,\n      isPrefetchHeadPartial,\n      canonicalUrl\n    )\n  }\n  // There's no matching prefetch for this route in the cache.\n  return {\n    tag: NavigationResultTag.Async,\n    data: navigateDynamicallyWithNoPrefetch(\n      url,\n      nextUrl,\n      currentCacheNode,\n      currentFlightRouterState\n    ),\n  }\n}\n\nfunction navigateUsingPrefetchedRouteTree(\n  url: URL,\n  nextUrl: string | null,\n  currentCacheNode: CacheNode,\n  currentFlightRouterState: FlightRouterState,\n  prefetchFlightRouterState: FlightRouterState,\n  prefetchSeedData: CacheNodeSeedData | null,\n  prefetchHead: React.ReactNode | null,\n  isPrefetchHeadPartial: boolean,\n  canonicalUrl: string\n): SuccessfulNavigationResult | NoOpNavigationResult {\n  // Recursively construct a prefetch tree by reading from the Segment Cache. To\n  // maintain compatibility, we output the same data structures as the old\n  // prefetching implementation: FlightRouterState and CacheNodeSeedData.\n  // TODO: Eventually updateCacheNodeOnNavigation (or the equivalent) should\n  // read from the Segment Cache directly. It's only structured this way for now\n  // so we can share code with the old prefetching implementation.\n  const task = updateCacheNodeOnNavigation(\n    currentCacheNode,\n    currentFlightRouterState,\n    prefetchFlightRouterState,\n    prefetchSeedData,\n    prefetchHead,\n    isPrefetchHeadPartial\n  )\n  if (task !== null) {\n    if (task.needsDynamicRequest) {\n      const promiseForDynamicServerResponse = fetchServerResponse(url, {\n        flightRouterState: currentFlightRouterState,\n        nextUrl,\n      })\n      listenForDynamicRequest(task, promiseForDynamicServerResponse)\n    } else {\n      // The prefetched tree does not contain dynamic holes â it's\n      // fully static. We can skip the dynamic request.\n    }\n    return navigationTaskToResult(task, currentCacheNode, canonicalUrl)\n  }\n  // The server sent back an empty tree patch. There's nothing to update.\n  return noOpNavigationResult\n}\n\nfunction navigationTaskToResult(\n  task: PPRNavigationTask,\n  currentCacheNode: CacheNode,\n  canonicalUrl: string\n): SuccessfulNavigationResult {\n  const newCacheNode = task.node\n  return {\n    tag: NavigationResultTag.Success,\n    data: {\n      flightRouterState: task.route,\n      cacheNode: newCacheNode !== null ? newCacheNode : currentCacheNode,\n      canonicalUrl,\n    },\n  }\n}\n\nfunction readRenderSnapshotFromCache(\n  now: number,\n  tree: TreePrefetch\n): { flightRouterState: FlightRouterState; seedData: CacheNodeSeedData } {\n  let childRouterStates: { [parallelRouteKey: string]: FlightRouterState } = {}\n  let childSeedDatas: {\n    [parallelRouteKey: string]: CacheNodeSeedData | null\n  } = {}\n  const slots = tree.slots\n  if (slots !== null) {\n    for (const parallelRouteKey in slots) {\n      const childTree = slots[parallelRouteKey]\n      const childResult = readRenderSnapshotFromCache(now, childTree)\n      childRouterStates[parallelRouteKey] = childResult.flightRouterState\n      childSeedDatas[parallelRouteKey] = childResult.seedData\n    }\n  }\n\n  let rsc: React.ReactNode | null = null\n  let loading: LoadingModuleData | Promise<LoadingModuleData> = null\n  let isPartial: boolean = true\n\n  const segmentEntry = readSegmentCacheEntry(now, tree.path)\n  if (segmentEntry !== null) {\n    switch (segmentEntry.status) {\n      case EntryStatus.Fulfilled: {\n        // Happy path: a cache hit\n        rsc = segmentEntry.rsc\n        loading = segmentEntry.loading\n        isPartial = segmentEntry.isPartial\n        break\n      }\n      case EntryStatus.Pending: {\n        // We haven't received data for this segment yet, but there's already\n        // an in-progress request. Since it's extremely likely to arrive\n        // before the dynamic data response, we might as well use it.\n        const promiseForFulfilledEntry = waitForSegmentCacheEntry(segmentEntry)\n        rsc = promiseForFulfilledEntry.then((entry) =>\n          entry !== null ? entry.rsc : null\n        )\n        loading = promiseForFulfilledEntry.then((entry) =>\n          entry !== null ? entry.loading : null\n        )\n        // Since we don't know yet whether the segment is partial or fully\n        // static, we must assume it's partial; we can't skip the\n        // dynamic request.\n        isPartial = true\n        break\n      }\n      case EntryStatus.Rejected:\n        break\n      default: {\n        const _exhaustiveCheck: never = segmentEntry\n        break\n      }\n    }\n  }\n\n  const extra = tree.extra\n  const flightRouterStateSegment = extra[0]\n  const isRootLayout = extra[1]\n\n  return {\n    flightRouterState: [\n      flightRouterStateSegment,\n      childRouterStates,\n      null,\n      null,\n      isRootLayout,\n    ],\n    seedData: [\n      flightRouterStateSegment,\n      rsc,\n      childSeedDatas,\n      loading,\n      isPartial,\n    ],\n  }\n}\n\nasync function navigateDynamicallyWithNoPrefetch(\n  url: URL,\n  nextUrl: string | null,\n  currentCacheNode: CacheNode,\n  currentFlightRouterState: FlightRouterState\n): Promise<\n  MPANavigationResult | SuccessfulNavigationResult | NoOpNavigationResult\n> {\n  // Runs when a navigation happens but there's no cached prefetch we can use.\n  // Don't bother to wait for a prefetch response; go straight to a full\n  // navigation that contains both static and dynamic data in a single stream.\n  // (This is unlike the old navigation implementation, which instead blocks\n  // the dynamic request until a prefetch request is received.)\n  //\n  // To avoid duplication of logic, we're going to pretend that the tree\n  // returned by the dynamic request is, in fact, a prefetch tree. Then we can\n  // use the same server response to write the actual data into the CacheNode\n  // tree. So it's the same flow as the \"happy path\" (prefetch, then\n  // navigation), except we use a single server response for both stages.\n\n  const promiseForDynamicServerResponse = fetchServerResponse(url, {\n    flightRouterState: currentFlightRouterState,\n    nextUrl,\n  })\n  const { flightData, canonicalUrl: canonicalUrlOverride } =\n    await promiseForDynamicServerResponse\n\n  // TODO: Detect if the only thing that changed was the hash, like we do in\n  // in navigateReducer\n\n  if (typeof flightData === 'string') {\n    // This is an MPA navigation.\n    const newUrl = flightData\n    return {\n      tag: NavigationResultTag.MPA,\n      data: newUrl,\n    }\n  }\n\n  // Since the response format of dynamic requests and prefetches is slightly\n  // different, we'll need to massage the data a bit. Create FlightRouterState\n  // tree that simulates what we'd receive as the result of a prefetch.\n  const prefetchFlightRouterState = simulatePrefetchTreeUsingDynamicTreePatch(\n    currentFlightRouterState,\n    flightData\n  )\n\n  // In our simulated prefetch payload, we pretend that there's no seed data\n  // nor a prefetch head.\n  const prefetchSeedData = null\n  const prefetchHead = null\n  const isPrefetchHeadPartial = true\n\n  const canonicalUrl = createCanonicalUrl(\n    canonicalUrlOverride ? canonicalUrlOverride : url\n  )\n\n  // Now we proceed exactly as we would for normal navigation.\n  const task = updateCacheNodeOnNavigation(\n    currentCacheNode,\n    currentFlightRouterState,\n    prefetchFlightRouterState,\n    prefetchSeedData,\n    prefetchHead,\n    isPrefetchHeadPartial\n  )\n  if (task !== null) {\n    if (task.needsDynamicRequest) {\n      listenForDynamicRequest(task, promiseForDynamicServerResponse)\n    } else {\n      // The prefetched tree does not contain dynamic holes â it's\n      // fully static. We can skip the dynamic request.\n    }\n    return navigationTaskToResult(task, currentCacheNode, canonicalUrl)\n  }\n  // The server sent back an empty tree patch. There's nothing to update.\n  return noOpNavigationResult\n}\n\nfunction simulatePrefetchTreeUsingDynamicTreePatch(\n  currentTree: FlightRouterState,\n  flightData: Array<NormalizedFlightData>\n): FlightRouterState {\n  // Takes the current FlightRouterState and applies the router state patch\n  // received from the server, to create a full FlightRouterState tree that we\n  // can pretend was returned by a prefetch.\n  //\n  // (It sounds similar to what applyRouterStatePatch does, but it doesn't need\n  // to handle stuff like interception routes or diffing since that will be\n  // handled later.)\n  let baseTree = currentTree\n  for (const { segmentPath, tree: treePatch } of flightData) {\n    // If the server sends us multiple tree patches, we only need to clone the\n    // base tree when applying the first patch. After the first patch, we can\n    // apply the remaining patches in place without copying.\n    const canMutateInPlace = baseTree !== currentTree\n    baseTree = simulatePrefetchTreeUsingDynamicTreePatchImpl(\n      baseTree,\n      treePatch,\n      segmentPath,\n      canMutateInPlace,\n      0\n    )\n  }\n\n  return baseTree\n}\n\nfunction simulatePrefetchTreeUsingDynamicTreePatchImpl(\n  baseRouterState: FlightRouterState,\n  patch: FlightRouterState,\n  segmentPath: FlightSegmentPath,\n  canMutateInPlace: boolean,\n  index: number\n) {\n  if (index === segmentPath.length) {\n    // We reached the part of the tree that we need to patch.\n    return patch\n  }\n\n  // segmentPath represents the parent path of subtree. It's a repeating\n  // pattern of parallel route key and segment:\n  //\n  //   [string, Segment, string, Segment, string, Segment, ...]\n  //\n  // This path tells us which part of the base tree to apply the tree patch.\n  //\n  // NOTE: In the case of a fully dynamic request with no prefetch, we receive\n  // the FlightRouterState patch in the same request as the dynamic data.\n  // Therefore we don't need to worry about diffing the segment values; we can\n  // assume the server sent us a correct result.\n  const updatedParallelRouteKey: string = segmentPath[index]\n  // const segment: Segment = segmentPath[index + 1] <-- Not used, see note above\n\n  const baseChildren = baseRouterState[1]\n  const newChildren: { [parallelRouteKey: string]: FlightRouterState } = {}\n  for (const parallelRouteKey in baseChildren) {\n    if (parallelRouteKey === updatedParallelRouteKey) {\n      const childBaseRouterState = baseChildren[parallelRouteKey]\n      newChildren[parallelRouteKey] =\n        simulatePrefetchTreeUsingDynamicTreePatchImpl(\n          childBaseRouterState,\n          patch,\n          segmentPath,\n          canMutateInPlace,\n          // Advance the index by two and keep cloning until we reach\n          // the end of the segment path.\n          index + 2\n        )\n    } else {\n      // This child is not being patched. Copy it over as-is.\n      newChildren[parallelRouteKey] = baseChildren[parallelRouteKey]\n    }\n  }\n\n  if (canMutateInPlace) {\n    // We can mutate the base tree in place, because the base tree is already\n    // a clone.\n    baseRouterState[1] = newChildren\n    return baseRouterState\n  }\n\n  // Clone all the fields except the children.\n  //\n  // Based on equivalent logic in apply-router-state-patch-to-tree, but should\n  // confirm whether we need to copy all of these fields. Not sure the server\n  // ever sends, e.g. the refetch marker.\n  const clone: FlightRouterState = [baseRouterState[0], newChildren]\n  if (2 in baseRouterState) {\n    clone[2] = baseRouterState[2]\n  }\n  if (3 in baseRouterState) {\n    clone[3] = baseRouterState[3]\n  }\n  if (4 in baseRouterState) {\n    clone[4] = baseRouterState[4]\n  }\n  return clone\n}\n"],"names":["NavigationResultTag","navigate","noOpNavigationResult","tag","data","url","currentCacheNode","currentFlightRouterState","nextUrl","now","Date","cacheKey","createCacheKey","href","route","readRouteCacheEntry","status","EntryStatus","Fulfilled","snapshot","readRenderSnapshotFromCache","tree","prefetchFlightRouterState","flightRouterState","prefetchSeedData","seedData","prefetchHead","head","isPrefetchHeadPartial","isHeadPartial","canonicalUrl","navigateUsingPrefetchedRouteTree","navigateDynamicallyWithNoPrefetch","task","updateCacheNodeOnNavigation","needsDynamicRequest","promiseForDynamicServerResponse","fetchServerResponse","listenForDynamicRequest","navigationTaskToResult","newCacheNode","node","cacheNode","childRouterStates","childSeedDatas","slots","parallelRouteKey","childTree","childResult","rsc","loading","isPartial","segmentEntry","readSegmentCacheEntry","path","Pending","promiseForFulfilledEntry","waitForSegmentCacheEntry","then","entry","Rejected","_exhaustiveCheck","extra","flightRouterStateSegment","isRootLayout","flightData","canonicalUrlOverride","newUrl","simulatePrefetchTreeUsingDynamicTreePatch","createCanonicalUrl","currentTree","baseTree","segmentPath","treePatch","canMutateInPlace","simulatePrefetchTreeUsingDynamicTreePatchImpl","baseRouterState","patch","index","length","updatedParallelRouteKey","baseChildren","newChildren","childBaseRouterState","clone"],"mappings":";;;;;;;;;;;;;;;IA0BkBA,mBAAmB,EAAA;eAAnBA;;IAoDFC,QAAQ,EAAA;eAARA;;;qCApEoB;gCAK7B;mCACiD;uBAMjD;0BAEwB;AAExB,IAAWD,sBAAAA,WAAAA,GAAAA,SAAAA,mBAAAA;;;;;WAAAA;;AAuClB,MAAME,uBAA6C;IACjDC,GAAG,EAAA;IACHC,MAAM;AACR;AAUO,SAASH,SACdI,GAAQ,EACRC,gBAA2B,EAC3BC,wBAA2C,EAC3CC,OAAsB;IAEtB,MAAMC,MAAMC,KAAKD,GAAG;IAEpB,MAAME,WAAWC,CAAAA,GAAAA,UAAAA,cAAc,EAACP,IAAIQ,IAAI,EAAEL;IAC1C,MAAMM,QAAQC,CAAAA,GAAAA,OAAAA,mBAAmB,EAACN,KAAKE;IACvC,IAAIG,UAAU,QAAQA,MAAME,MAAM,KAAKC,OAAAA,WAAW,CAACC,SAAS,EAAE;QAC5D,+BAA+B;QAC/B,MAAMC,WAAWC,4BAA4BX,KAAKK,MAAMO,IAAI;QAC5D,MAAMC,4BAA4BH,SAASI,iBAAiB;QAC5D,MAAMC,mBAAmBL,SAASM,QAAQ;QAC1C,MAAMC,eAAeZ,MAAMa,IAAI;QAC/B,MAAMC,wBAAwBd,MAAMe,aAAa;QACjD,MAAMC,eAAehB,MAAMgB,YAAY;QACvC,OAAOC,iCACL1B,KACAG,SACAF,kBACAC,0BACAe,2BACAE,kBACAE,cACAE,uBACAE;IAEJ;IACA,4DAA4D;IAC5D,OAAO;QACL3B,GAAG,EAAA;QACHC,MAAM4B,kCACJ3B,KACAG,SACAF,kBACAC;IAEJ;AACF;AAEA,SAASwB,iCACP1B,GAAQ,EACRG,OAAsB,EACtBF,gBAA2B,EAC3BC,wBAA2C,EAC3Ce,yBAA4C,EAC5CE,gBAA0C,EAC1CE,YAAoC,EACpCE,qBAA8B,EAC9BE,YAAoB;IAEpB,8EAA8E;IAC9E,wEAAwE;IACxE,uEAAuE;IACvE,0EAA0E;IAC1E,8EAA8E;IAC9E,gEAAgE;IAChE,MAAMG,OAAOC,CAAAA,GAAAA,gBAAAA,2BAA2B,EACtC5B,kBACAC,0BACAe,2BACAE,kBACAE,cACAE;IAEF,IAAIK,SAAS,MAAM;QACjB,IAAIA,KAAKE,mBAAmB,EAAE;YAC5B,MAAMC,kCAAkCC,CAAAA,GAAAA,qBAAAA,mBAAmB,EAAChC,KAAK;gBAC/DkB,mBAAmBhB;gBACnBC;YACF;YACA8B,CAAAA,GAAAA,gBAAAA,uBAAuB,EAACL,MAAMG;QAChC,OAAO;QACL,4DAA4D;QAC5D,iDAAiD;QACnD;QACA,OAAOG,uBAAuBN,MAAM3B,kBAAkBwB;IACxD;IACA,uEAAuE;IACvE,OAAO5B;AACT;AAEA,SAASqC,uBACPN,IAAuB,EACvB3B,gBAA2B,EAC3BwB,YAAoB;IAEpB,MAAMU,eAAeP,KAAKQ,IAAI;IAC9B,OAAO;QACLtC,GAAG,EAAA;QACHC,MAAM;YACJmB,mBAAmBU,KAAKnB,KAAK;YAC7B4B,WAAWF,iBAAiB,OAAOA,eAAelC;YAClDwB;QACF;IACF;AACF;AAEA,SAASV,4BACPX,GAAW,EACXY,IAAkB;IAElB,IAAIsB,oBAAuE,CAAC;IAC5E,IAAIC,iBAEA,CAAC;IACL,MAAMC,QAAQxB,KAAKwB,KAAK;IACxB,IAAIA,UAAU,MAAM;QAClB,IAAK,MAAMC,oBAAoBD,MAAO;YACpC,MAAME,YAAYF,KAAK,CAACC,iBAAiB;YACzC,MAAME,cAAc5B,4BAA4BX,KAAKsC;YACrDJ,iBAAiB,CAACG,iBAAiB,GAAGE,YAAYzB,iBAAiB;YACnEqB,cAAc,CAACE,iBAAiB,GAAGE,YAAYvB,QAAQ;QACzD;IACF;IAEA,IAAIwB,MAA8B;IAClC,IAAIC,UAA0D;IAC9D,IAAIC,YAAqB;IAEzB,MAAMC,eAAeC,CAAAA,GAAAA,OAAAA,qBAAqB,EAAC5C,KAAKY,KAAKiC,IAAI;IACzD,IAAIF,iBAAiB,MAAM;QACzB,OAAQA,aAAapC,MAAM;YACzB,KAAKC,OAAAA,WAAW,CAACC,SAAS;gBAAE;oBAC1B,0BAA0B;oBAC1B+B,MAAMG,aAAaH,GAAG;oBACtBC,UAAUE,aAAaF,OAAO;oBAC9BC,YAAYC,aAAaD,SAAS;oBAClC;gBACF;YACA,KAAKlC,OAAAA,WAAW,CAACsC,OAAO;gBAAE;oBACxB,qEAAqE;oBACrE,gEAAgE;oBAChE,6DAA6D;oBAC7D,MAAMC,2BAA2BC,CAAAA,GAAAA,OAAAA,wBAAwB,EAACL;oBAC1DH,MAAMO,yBAAyBE,IAAI,CAAC,CAACC,QACnCA,UAAU,OAAOA,MAAMV,GAAG,GAAG;oBAE/BC,UAAUM,yBAAyBE,IAAI,CAAC,CAACC,QACvCA,UAAU,OAAOA,MAAMT,OAAO,GAAG;oBAEnC,kEAAkE;oBAClE,yDAAyD;oBACzD,mBAAmB;oBACnBC,YAAY;oBACZ;gBACF;YACA,KAAKlC,OAAAA,WAAW,CAAC2C,QAAQ;gBACvB;YACF;gBAAS;oBACP,MAAMC,mBAA0BT;oBAChC;gBACF;QACF;IACF;IAEA,MAAMU,QAAQzC,KAAKyC,KAAK;IACxB,MAAMC,2BAA2BD,KAAK,CAAC,EAAE;IACzC,MAAME,eAAeF,KAAK,CAAC,EAAE;IAE7B,OAAO;QACLvC,mBAAmB;YACjBwC;YACApB;YACA;YACA;YACAqB;SACD;QACDvC,UAAU;YACRsC;YACAd;YACAL;YACAM;YACAC;SACD;IACH;AACF;AAEA,eAAenB,kCACb3B,GAAQ,EACRG,OAAsB,EACtBF,gBAA2B,EAC3BC,wBAA2C;IAI3C,4EAA4E;IAC5E,sEAAsE;IACtE,4EAA4E;IAC5E,0EAA0E;IAC1E,6DAA6D;IAC7D,EAAE;IACF,sEAAsE;IACtE,4EAA4E;IAC5E,2EAA2E;IAC3E,kEAAkE;IAClE,uEAAuE;IAEvE,MAAM6B,kCAAkCC,CAAAA,GAAAA,qBAAAA,mBAAmB,EAAChC,KAAK;QAC/DkB,mBAAmBhB;QACnBC;IACF;IACA,MAAM,EAAEyD,UAAU,EAAEnC,cAAcoC,oBAAoB,EAAE,GACtD,MAAM9B;IAER,0EAA0E;IAC1E,qBAAqB;IAErB,IAAI,OAAO6B,eAAe,UAAU;QAClC,6BAA6B;QAC7B,MAAME,SAASF;QACf,OAAO;YACL9D,GAAG,EAAA;YACHC,MAAM+D;QACR;IACF;IAEA,2EAA2E;IAC3E,4EAA4E;IAC5E,qEAAqE;IACrE,MAAM7C,4BAA4B8C,0CAChC7D,0BACA0D;IAGF,0EAA0E;IAC1E,uBAAuB;IACvB,MAAMzC,mBAAmB;IACzB,MAAME,eAAe;IACrB,MAAME,wBAAwB;IAE9B,MAAME,eAAeuC,CAAAA,GAAAA,mBAAAA,iBAAkB,EACrCH,uBAAuBA,uBAAuB7D;IAGhD,4DAA4D;IAC5D,MAAM4B,OAAOC,CAAAA,GAAAA,gBAAAA,2BAA2B,EACtC5B,kBACAC,0BACAe,2BACAE,kBACAE,cACAE;IAEF,IAAIK,SAAS,MAAM;QACjB,IAAIA,KAAKE,mBAAmB,EAAE;YAC5BG,CAAAA,GAAAA,gBAAAA,uBAAuB,EAACL,MAAMG;QAChC,OAAO;QACL,4DAA4D;QAC5D,iDAAiD;QACnD;QACA,OAAOG,uBAAuBN,MAAM3B,kBAAkBwB;IACxD;IACA,uEAAuE;IACvE,OAAO5B;AACT;AAEA,SAASkE,0CACPE,WAA8B,EAC9BL,UAAuC;IAEvC,yEAAyE;IACzE,4EAA4E;IAC5E,0CAA0C;IAC1C,EAAE;IACF,6EAA6E;IAC7E,yEAAyE;IACzE,kBAAkB;IAClB,IAAIM,WAAWD;IACf,KAAK,MAAM,EAAEE,WAAW,EAAEnD,MAAMoD,SAAS,EAAE,IAAIR,WAAY;QACzD,0EAA0E;QAC1E,yEAAyE;QACzE,wDAAwD;QACxD,MAAMS,mBAAmBH,aAAaD;QACtCC,WAAWI,8CACTJ,UACAE,WACAD,aACAE,kBACA;IAEJ;IAEA,OAAOH;AACT;AAEA,SAASI,8CACPC,eAAkC,EAClCC,KAAwB,EACxBL,WAA8B,EAC9BE,gBAAyB,EACzBI,KAAa;IAEb,IAAIA,UAAUN,YAAYO,MAAM,EAAE;QAChC,yDAAyD;QACzD,OAAOF;IACT;IAEA,sEAAsE;IACtE,6CAA6C;IAC7C,EAAE;IACF,6DAA6D;IAC7D,EAAE;IACF,0EAA0E;IAC1E,EAAE;IACF,4EAA4E;IAC5E,uEAAuE;IACvE,4EAA4E;IAC5E,8CAA8C;IAC9C,MAAMG,0BAAkCR,WAAW,CAACM,MAAM;IAC1D,+EAA+E;IAE/E,MAAMG,eAAeL,eAAe,CAAC,EAAE;IACvC,MAAMM,cAAiE,CAAC;IACxE,IAAK,MAAMpC,oBAAoBmC,aAAc;QAC3C,IAAInC,qBAAqBkC,yBAAyB;YAChD,MAAMG,uBAAuBF,YAAY,CAACnC,iBAAiB;YAC3DoC,WAAW,CAACpC,iBAAiB,GAC3B6B,8CACEQ,sBACAN,OACAL,aACAE,kBACA,AACA,+BAA+B,4BAD4B;YAE3DI,QAAQ;QAEd,OAAO;YACL,uDAAuD;YACvDI,WAAW,CAACpC,iBAAiB,GAAGmC,YAAY,CAACnC,iBAAiB;QAChE;IACF;IAEA,IAAI4B,kBAAkB;QACpB,yEAAyE;QACzE,WAAW;QACXE,eAAe,CAAC,EAAE,GAAGM;QACrB,OAAON;IACT;IAEA,4CAA4C;IAC5C,EAAE;IACF,4EAA4E;IAC5E,2EAA2E;IAC3E,uCAAuC;IACvC,MAAMQ,QAA2B;QAACR,eAAe,CAAC,EAAE;QAAEM;KAAY;IAClE,IAAI,KAAKN,iBAAiB;QACxBQ,KAAK,CAAC,EAAE,GAAGR,eAAe,CAAC,EAAE;IAC/B;IACA,IAAI,KAAKA,iBAAiB;QACxBQ,KAAK,CAAC,EAAE,GAAGR,eAAe,CAAC,EAAE;IAC/B;IACA,IAAI,KAAKA,iBAAiB;QACxBQ,KAAK,CAAC,EAAE,GAAGR,eAAe,CAAC,EAAE;IAC/B;IACA,OAAOQ;AACT","ignoreList":[0]}},
    {"offset": {"line": 2662, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}